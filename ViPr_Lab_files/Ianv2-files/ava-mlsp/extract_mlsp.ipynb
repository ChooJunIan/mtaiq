{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Ian_env (Python 3.10.8)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import kuti\n",
    "from kuti import applications as apps\n",
    "from kuti import model_helper as mh\n",
    "from kuti import image_utils\n",
    "from kuti import generic\n",
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/workstation/0832621B32620DCE/Ian\n",
      "/media/workstation/0832621B32620DCE/Ian\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(os.getcwd())\n",
    "# os.chdir(\"/media/workstation/0832621B32620DCE/Ian\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ORIGINAL PATH FOR AVA-MLSP\n",
    "\n",
    "# root_path = '/media/workstation/0832621B32620DCE/Ian/ava-mlsp/'\n",
    "# ids_ava_mlsp = pd.read_csv(root_path + 'metadata/AVA_data_official_test.csv')\n",
    "\n",
    "# ids_ava_mlsp\n",
    "# input_shape = (None, None, 3)\n",
    "# features_root = root_path + 'features/'\n",
    "# images_path = root_path + 'images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features for GET2 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/media/workstation/0832621B32620DCE/Ian/'\n",
    "ids = pd.read_csv(root_path + 'mtaiq/PARA_MTAIQ_GET2_official_dataset.csv')\n",
    "\n",
    "input_shape = (None, None, 3)\n",
    "features_root = root_path + 'features_get2/'\n",
    "images_path = '/media/workstation/0832621B32620DCE/PARA_Dataset/PARA/PARA_resized/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose and load pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3 MLSP narrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = apps.model_inception_multigap(input_shape)\n",
    "pre = apps.process_input[apps.InceptionV3]\n",
    "model_name = 'iv3_mlsp_narrow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### InceptionV3 MLSP wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = apps.model_inception_pooled(input_shape)\n",
    "pre   = apps.process_input[apps.InceptionV3]\n",
    "model_name = 'iv3_mlsp_wide'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionResNetV2 MLSP narrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = apps.model_inceptionresnet_multigap(input_shape)\n",
    "pre = apps.process_input[apps.InceptionResNetV2]\n",
    "model_name = 'irnv2_mlsp_narrow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionResNetV2 MLSP wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading InceptionResNetV2 multi-pooled with input_shape: (None, None, 3)\n",
      "Creating multi-pooled model\n"
     ]
    }
   ],
   "source": [
    "model, pool_size = apps.model_inceptionresnet_pooled(input_shape, return_sizes=True)\n",
    "pre   = apps.process_input[apps.InceptionResNetV2]\n",
    "model_name = 'irnv2_mlsp_wide'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10637767124019153042\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10500833280\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7782482734074538775\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 17:09:17.370303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-30 17:09:17.370710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-30 17:09:17.370837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-30 17:09:17.371001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-30 17:09:17.371149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-30 17:09:17.371241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 10014 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original sized images, no augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.99215686\n",
      "Saving features\n",
      "31220\n"
     ]
    }
   ],
   "source": [
    "gen_params = dict(batch_size  = 1,\n",
    "                  data_path   = images_path,\n",
    "                  input_shape = ('orig',),\n",
    "                  inputs = ['sessionId_imageName'],\n",
    "                  outputs = [['aestheticScore'], ['qualityScore']],\n",
    "                  process_fn  = pre,\n",
    "                  fixed_batches = False)\n",
    "\n",
    "helper = mh.ModelHelper(model, model_name + '_orig', ids,\n",
    "                    features_root = features_root,\n",
    "                    gen_params    = gen_params)\n",
    "\n",
    "generator = helper.make_generator(ids)\n",
    "# print(generator[0][0][0][0][0][0][0])\n",
    "\n",
    "print('Saving features')\n",
    "batch_size = 512\n",
    "numel = len(ids)\n",
    "\n",
    "for i in range(0,numel,batch_size):\n",
    "    istop = min(i+batch_size, numel)\n",
    "    # print('Processing images',i,':',istop)\n",
    "    ids_batch = ids[i:istop].reset_index(drop=True)\n",
    "    # print(ids_batch)\n",
    "    # helper.save_activations(ids=ids_batch, verbose=True,\\\n",
    "    #                         groups=1,\n",
    "    #                         save_as_type=np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### originals, augmented with flip and crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = [(i,j) for i in (1,0) for j in (1,0)]\n",
    "flips = (0,1)\n",
    "\n",
    "for i, crop_pos in enumerate(crops):\n",
    "    for doflip in flips:\n",
    "        print('crop', crop_pos, 'flip' if doflip else '')\n",
    "        process_fn = lambda im: pre(image_utils.ImageAugmenter(im, verbose=False, remap=False).\\\n",
    "                                    crop(0.875, crop_pos).fliplr(doflip).result)\n",
    "        gen_params = dict(batch_size  = 1,\n",
    "                          data_path   = images_path,\n",
    "                          input_shape = ('orig',),\n",
    "                          inputs = ['sessionId_imageName'],\n",
    "                          outputs = [['aestheticScore'], ['qualityScore']],\n",
    "                          process_fn  = process_fn,\n",
    "                          fixed_batches = False)\n",
    "\n",
    "        helper = mh.ModelHelper(model, model_name + '_fc8_orig', ids,\n",
    "                            features_root = features_root,\n",
    "                            gen_params    = gen_params)\n",
    "        \n",
    "        # generator = helper.make_generator(ids)\n",
    "        # print(generator[0])\n",
    "\n",
    "        print('Saving features')\n",
    "        batch_size = 1024\n",
    "        numel = len(ids)\n",
    "        flag = False\n",
    "        for i in range(0,numel,batch_size):\n",
    "            \n",
    "            istop = min(i+batch_size, numel)\n",
    "            print('Processing images',i,':',istop)\n",
    "            ids_batch = ids[i:istop].reset_index(drop=True)\n",
    "            helper.save_activations(ids=ids_batch, verbose=True,\\\n",
    "                                    groups=['%g_%g_%d' %(crop_pos+(doflip,))], \n",
    "                                    save_as_type=np.float16, overwrite=False)\n",
    "        #     if i == 5:\n",
    "        #         flag = True\n",
    "        #         break\n",
    "        # if flag:\n",
    "        #     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 24.622 GB\n",
      "Groups:\n",
      "* session100_iaa_pub6931_.jpg/\n",
      "* session100_iaa_pub6932_.jpg/\n",
      "* session100_iaa_pub6933_.jpg/\n",
      "* session100_iaa_pub6934_.jpg/\n",
      "* session100_iaa_pub6935_.jpg/\n",
      "* session100_iaa_pub6936_.jpg/\n",
      "* session100_iaa_pub6937_.jpg/\n",
      "* session100_iaa_pub6938_.jpg/\n",
      "* session100_iaa_pub6939_.jpg/\n",
      "* session100_iaa_pub6940_.jpg/\n",
      "* session100_iaa_pub6941_.jpg/\n",
      "* session100_iaa_pub6942_.jpg/\n",
      "* session100_iaa_pub6943_.jpg/\n",
      "* session100_iaa_pub6944_.jpg/\n",
      "* session100_iaa_pub6945_.jpg/\n",
      "* session100_iaa_pub6946_.jpg/\n",
      "* session100_iaa_pub6947_.jpg/\n",
      "* session100_iaa_pub6948_.jpg/\n",
      "* session100_iaa_pub6949_.jpg/\n",
      "* session100_iaa_pub6950_.jpg/\n",
      "* session100_iaa_pub6951_.jpg/\n",
      "* session100_iaa_pub6952_.jpg/\n",
      "* session100_iaa_pub6953_.jpg/\n",
      "* session100_iaa_pub6954_.jpg/\n",
      "* session100_iaa_pub6955_.jpg/\n",
      "* session100_iaa_pub6956_.jpg/\n",
      "* session100_iaa_pub6957_.jpg/\n",
      "* session100_iaa_pub6958_.jpg/\n",
      "* session100_iaa_pub6959_.jpg/\n",
      "* session100_iaa_pub6960_.jpg/\n",
      "* session100_iaa_pub6961_.jpg/\n",
      "* session100_iaa_pub6962_.jpg/\n",
      "* session100_iaa_pub6963_.jpg/\n",
      "* session100_iaa_pub6964_.jpg/\n",
      "* session100_iaa_pub6965_.jpg/\n",
      "* session100_iaa_pub6966_.jpg/\n",
      "* session100_iaa_pub6967_.jpg/\n",
      "* session100_iaa_pub6968_.jpg/\n",
      "* session100_iaa_pub6969_.jpg/\n",
      "* session100_iaa_pub6970_.jpg/\n",
      "* session100_iaa_pub6971_.jpg/\n",
      "* session100_iaa_pub6972_.jpg/\n",
      "* session100_iaa_pub6973_.jpg/\n",
      "* session100_iaa_pub6974_.jpg/\n",
      "* session100_iaa_pub6975_.jpg/\n",
      "* session100_iaa_pub6976_.jpg/\n",
      "* session100_iaa_pub6977_.jpg/\n",
      "* session100_iaa_pub6978_.jpg/\n",
      "* session100_iaa_pub6979_.jpg/\n",
      "* session100_iaa_pub6980_.jpg/\n",
      "* session100_iaa_pub6981_.jpg/\n",
      "* session100_iaa_pub6982_.jpg/\n",
      "* session100_iaa_pub6983_.jpg/\n",
      "* session100_iaa_pub6984_.jpg/\n",
      "* session100_iaa_pub6985_.jpg/\n",
      "* session100_iaa_pub6986_.jpg/\n",
      "* session100_iaa_pub6987_.jpg/\n",
      "* session100_iaa_pub6988_.jpg/\n",
      "* session100_iaa_pub6989_.jpg/\n",
      "* session100_iaa_pub6990_.jpg/\n",
      "* session100_iaa_pub6991_.jpg/\n",
      "* session100_iaa_pub6992_.jpg/\n",
      "* session100_iaa_pub6993_.jpg/\n",
      "* session100_iaa_pub6994_.jpg/\n",
      "* session100_iaa_pub6995_.jpg/\n",
      "* session100_iaa_pub6996_.jpg/\n",
      "* session100_iaa_pub6997_.jpg/\n",
      "* session100_iaa_pub6998_.jpg/\n",
      "* session100_iaa_pub6999_.jpg/\n",
      "* session100_iaa_pub7000_.jpg/\n",
      "* session101_iaa_pub7001_.jpg/\n",
      "* session101_iaa_pub7002_.jpg/\n",
      "* session101_iaa_pub7003_.jpg/\n",
      "* session101_iaa_pub7004_.jpg/\n",
      "* session101_iaa_pub7005_.jpg/\n",
      "* session101_iaa_pub7006_.jpg/\n",
      "* session101_iaa_pub7007_.jpg/\n",
      "* session101_iaa_pub7008_.jpg/\n",
      "* session101_iaa_pub7009_.jpg/\n",
      "* session101_iaa_pub7010_.jpg/\n",
      "* session101_iaa_pub7011_.jpg/\n",
      "* session101_iaa_pub7012_.jpg/\n",
      "* session101_iaa_pub7013_.jpg/\n",
      "* session101_iaa_pub7014_.jpg/\n",
      "* session101_iaa_pub7015_.jpg/\n",
      "* session101_iaa_pub7016_.jpg/\n",
      "* session101_iaa_pub7017_.jpg/\n",
      "* session101_iaa_pub7018_.jpg/\n",
      "* session101_iaa_pub7019_.jpg/\n",
      "* session101_iaa_pub7020_.jpg/\n",
      "* session101_iaa_pub7021_.jpg/\n",
      "* session101_iaa_pub7022_.jpg/\n",
      "* session101_iaa_pub7023_.jpg/\n",
      "* session101_iaa_pub7024_.jpg/\n",
      "* session101_iaa_pub7025_.jpg/\n",
      "* session101_iaa_pub7026_.jpg/\n",
      "* session101_iaa_pub7027_.jpg/\n",
      "* session101_iaa_pub7028_.jpg/\n",
      "* session101_iaa_pub7029_.jpg/\n",
      "* session101_iaa_pub7030_.jpg/\n",
      "* session101_iaa_pub7031_.jpg/\n",
      "[...] showing 100 of 31220\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# check contents of saved file\n",
    "with generic.H5Helper(features_root + 'irnv2_mlsp_wide_orig/grp:1 i:1[orig] lay:final o:1[5,5,16928].h5','r') as h:\n",
    "    print(h.summary())\n",
    "    # print((list(h.hf.keys())))\n",
    "    # print(h.hf.get('session1_iaa_pub1_.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features for GET3 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/media/workstation/0832621B32620DCE/Ian/'\n",
    "ids = pd.read_csv(root_path + 'mtaiq/PARA_MTAIQ_GET3_official_dataset.csv')\n",
    "\n",
    "input_shape = (None, None, 3)\n",
    "features_root = root_path + 'features_get3/'\n",
    "images_path = '/media/workstation/0832621B32620DCE/PARA_Dataset/PARA/PARA_resized/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose and load pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionResNetV2 MLSP wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading InceptionResNetV2 multi-pooled with input_shape: (None, None, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 02:04:25.115863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:25.144789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:25.145024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:25.145587: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-26 02:04:25.146030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:25.146226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:25.146345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:25.708717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:25.709010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:25.709267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:25.709381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9905 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating multi-pooled model\n"
     ]
    }
   ],
   "source": [
    "model = apps.model_inceptionresnet_pooled(input_shape)\n",
    "pre   = apps.process_input[apps.InceptionResNetV2]\n",
    "model_name = 'irnv2_mlsp_wide'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15703890552849797949\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10386800640\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4458143984700764472\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 02:04:34.849796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:34.850029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:34.850153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:34.850319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:34.850467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:04:34.850558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 9905 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original sized images, no augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving features\n",
      "31220\n",
      "Processing images 0 : 512\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 512 : 1024\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 1024 : 1536\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 1536 : 2048\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 2048 : 2560\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 2560 : 3072\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 3072 : 3584\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 3584 : 4096\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 4096 : 4608\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 4608 : 5120\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 5120 : 5632\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 5632 : 6144\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 6144 : 6656\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 6656 : 7168\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 7168 : 7680\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 7680 : 8192\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 8192 : 8704\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 8704 : 9216\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 9216 : 9728\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 9728 : 10240\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 10240 : 10752\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 10752 : 11264\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 11264 : 11776\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 11776 : 12288\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 12288 : 12800\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 12800 : 13312\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 13312 : 13824\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 13824 : 14336\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 14336 : 14848\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 14848 : 15360\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 15360 : 15872\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 15872 : 16384\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 16384 : 16896\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 16896 : 17408\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 17408 : 17920\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 17920 : 18432\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 18432 : 18944\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 18944 : 19456\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 19456 : 19968\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 19968 : 20480\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 20480 : 20992\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 20992 : 21504\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 21504 : 22016\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 22016 : 22528\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 22528 : 23040\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 23040 : 23552\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 23552 : 24064\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 24064 : 24576\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 24576 : 25088\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 25088 : 25600\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 25600 : 26112\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 26112 : 26624\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 26624 : 27136\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 27136 : 27648\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 27648 : 28160\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 28160 : 28672\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 28672 : 29184\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 29184 : 29696\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 29696 : 30208\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 30208 : 30720\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 30720 : 31220\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n"
     ]
    }
   ],
   "source": [
    "gen_params = dict(batch_size  = 1,\n",
    "                  data_path   = images_path,\n",
    "                  input_shape = ('orig',),\n",
    "                  inputs = ['sessionId_imageName'],\n",
    "                  outputs = [['aestheticScore'], ['qualityScore']],\n",
    "                  process_fn  = pre,\n",
    "                  fixed_batches = False)\n",
    "\n",
    "helper = mh.ModelHelper(model, model_name + '_orig', ids,\n",
    "                    features_root = features_root,\n",
    "                    gen_params    = gen_params)\n",
    "\n",
    "generator = helper.make_generator(ids)\n",
    "print(generator[0])\n",
    "\n",
    "print('Saving features')\n",
    "batch_size = 512\n",
    "numel = len(ids)\n",
    "print(numel)\n",
    "\n",
    "for i in range(0,numel,batch_size):\n",
    "    istop = min(i+batch_size, numel)\n",
    "    print('Processing images',i,':',istop)\n",
    "    ids_batch = ids[i:istop].reset_index(drop=True)\n",
    "    # print(ids_batch)\n",
    "    # helper.save_activations(ids=ids_batch, verbose=True,\\\n",
    "    #                         groups=1,\n",
    "    #                         save_as_type=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 24.622 GB\n",
      "Groups:\n",
      "* session100_iaa_pub6931_.jpg/\n",
      "* session100_iaa_pub6932_.jpg/\n",
      "* session100_iaa_pub6933_.jpg/\n",
      "* session100_iaa_pub6934_.jpg/\n",
      "* session100_iaa_pub6935_.jpg/\n",
      "* session100_iaa_pub6936_.jpg/\n",
      "* session100_iaa_pub6937_.jpg/\n",
      "* session100_iaa_pub6938_.jpg/\n",
      "* session100_iaa_pub6939_.jpg/\n",
      "* session100_iaa_pub6940_.jpg/\n",
      "* session100_iaa_pub6941_.jpg/\n",
      "* session100_iaa_pub6942_.jpg/\n",
      "* session100_iaa_pub6943_.jpg/\n",
      "* session100_iaa_pub6944_.jpg/\n",
      "* session100_iaa_pub6945_.jpg/\n",
      "* session100_iaa_pub6946_.jpg/\n",
      "* session100_iaa_pub6947_.jpg/\n",
      "* session100_iaa_pub6948_.jpg/\n",
      "* session100_iaa_pub6949_.jpg/\n",
      "* session100_iaa_pub6950_.jpg/\n",
      "* session100_iaa_pub6951_.jpg/\n",
      "* session100_iaa_pub6952_.jpg/\n",
      "* session100_iaa_pub6953_.jpg/\n",
      "* session100_iaa_pub6954_.jpg/\n",
      "* session100_iaa_pub6955_.jpg/\n",
      "* session100_iaa_pub6956_.jpg/\n",
      "* session100_iaa_pub6957_.jpg/\n",
      "* session100_iaa_pub6958_.jpg/\n",
      "* session100_iaa_pub6959_.jpg/\n",
      "* session100_iaa_pub6960_.jpg/\n",
      "* session100_iaa_pub6961_.jpg/\n",
      "* session100_iaa_pub6962_.jpg/\n",
      "* session100_iaa_pub6963_.jpg/\n",
      "* session100_iaa_pub6964_.jpg/\n",
      "* session100_iaa_pub6965_.jpg/\n",
      "* session100_iaa_pub6966_.jpg/\n",
      "* session100_iaa_pub6967_.jpg/\n",
      "* session100_iaa_pub6968_.jpg/\n",
      "* session100_iaa_pub6969_.jpg/\n",
      "* session100_iaa_pub6970_.jpg/\n",
      "* session100_iaa_pub6971_.jpg/\n",
      "* session100_iaa_pub6972_.jpg/\n",
      "* session100_iaa_pub6973_.jpg/\n",
      "* session100_iaa_pub6974_.jpg/\n",
      "* session100_iaa_pub6975_.jpg/\n",
      "* session100_iaa_pub6976_.jpg/\n",
      "* session100_iaa_pub6977_.jpg/\n",
      "* session100_iaa_pub6978_.jpg/\n",
      "* session100_iaa_pub6979_.jpg/\n",
      "* session100_iaa_pub6980_.jpg/\n",
      "* session100_iaa_pub6981_.jpg/\n",
      "* session100_iaa_pub6982_.jpg/\n",
      "* session100_iaa_pub6983_.jpg/\n",
      "* session100_iaa_pub6984_.jpg/\n",
      "* session100_iaa_pub6985_.jpg/\n",
      "* session100_iaa_pub6986_.jpg/\n",
      "* session100_iaa_pub6987_.jpg/\n",
      "* session100_iaa_pub6988_.jpg/\n",
      "* session100_iaa_pub6989_.jpg/\n",
      "* session100_iaa_pub6990_.jpg/\n",
      "* session100_iaa_pub6991_.jpg/\n",
      "* session100_iaa_pub6992_.jpg/\n",
      "* session100_iaa_pub6993_.jpg/\n",
      "* session100_iaa_pub6994_.jpg/\n",
      "* session100_iaa_pub6995_.jpg/\n",
      "* session100_iaa_pub6996_.jpg/\n",
      "* session100_iaa_pub6997_.jpg/\n",
      "* session100_iaa_pub6998_.jpg/\n",
      "* session100_iaa_pub6999_.jpg/\n",
      "* session100_iaa_pub7000_.jpg/\n",
      "* session101_iaa_pub7001_.jpg/\n",
      "* session101_iaa_pub7002_.jpg/\n",
      "* session101_iaa_pub7003_.jpg/\n",
      "* session101_iaa_pub7004_.jpg/\n",
      "* session101_iaa_pub7005_.jpg/\n",
      "* session101_iaa_pub7006_.jpg/\n",
      "* session101_iaa_pub7007_.jpg/\n",
      "* session101_iaa_pub7008_.jpg/\n",
      "* session101_iaa_pub7009_.jpg/\n",
      "* session101_iaa_pub7010_.jpg/\n",
      "* session101_iaa_pub7011_.jpg/\n",
      "* session101_iaa_pub7012_.jpg/\n",
      "* session101_iaa_pub7013_.jpg/\n",
      "* session101_iaa_pub7014_.jpg/\n",
      "* session101_iaa_pub7015_.jpg/\n",
      "* session101_iaa_pub7016_.jpg/\n",
      "* session101_iaa_pub7017_.jpg/\n",
      "* session101_iaa_pub7018_.jpg/\n",
      "* session101_iaa_pub7019_.jpg/\n",
      "* session101_iaa_pub7020_.jpg/\n",
      "* session101_iaa_pub7021_.jpg/\n",
      "* session101_iaa_pub7022_.jpg/\n",
      "* session101_iaa_pub7023_.jpg/\n",
      "* session101_iaa_pub7024_.jpg/\n",
      "* session101_iaa_pub7025_.jpg/\n",
      "* session101_iaa_pub7026_.jpg/\n",
      "* session101_iaa_pub7027_.jpg/\n",
      "* session101_iaa_pub7028_.jpg/\n",
      "* session101_iaa_pub7029_.jpg/\n",
      "* session101_iaa_pub7030_.jpg/\n",
      "* session101_iaa_pub7031_.jpg/\n",
      "[...] showing 100 of 31220\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# check contents of saved file\n",
    "with generic.H5Helper(features_root + 'irnv2_mlsp_wide_orig/grp:1 i:1[orig] lay:final o:1[5,5,16928].h5','r') as h:\n",
    "    print(h.summary())\n",
    "    # print((list(h.hf.keys())))\n",
    "    # print(h.hf.get('session1_iaa_pub1_.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features get all Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/media/workstation/0832621B32620DCE/Ian/'\n",
    "ids = pd.read_csv(root_path + 'mtaiq/PARA_MTAIQ_All_User_official_dataset.csv')\n",
    "\n",
    "input_shape = (None, None, 3)\n",
    "features_root = root_path + 'features_all_user/'\n",
    "images_path = '/media/workstation/0832621B32620DCE/PARA_Dataset/PARA/PARA_resized/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose and load pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionResNetV2 MLSP Wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading InceptionResNetV2 multi-pooled with input_shape: (None, None, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 15:58:56.013244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-04 15:58:56.677059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-04 15:58:56.677256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-04 15:58:56.697106: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-04 15:58:56.697588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-04 15:58:56.697785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-04 15:58:56.697901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-04 15:59:03.660147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-04 15:59:03.660320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-04 15:59:03.660445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-04 15:59:03.672562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9995 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating multi-pooled model\n"
     ]
    }
   ],
   "source": [
    "model = apps.model_inceptionresnet_pooled(input_shape)\n",
    "pre   = apps.process_input[apps.InceptionResNetV2]\n",
    "model_name = 'irnv2_mlsp_wide'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original sized images, no augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving features\n",
      "31220\n",
      "Processing images 0 : 512\n",
      "Generating batches |--------------------------------------------------| 0% \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 15:59:44.369028: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n",
      "2023-02-04 15:59:51.392125: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 512 : 1024\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 1024 : 1536\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 1536 : 2048\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 2048 : 2560\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 2560 : 3072\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 3072 : 3584\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 3584 : 4096\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 4096 : 4608\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 4608 : 5120\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 5120 : 5632\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 5632 : 6144\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 6144 : 6656\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 6656 : 7168\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 7168 : 7680\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 7680 : 8192\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 8192 : 8704\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 8704 : 9216\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 9216 : 9728\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 9728 : 10240\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 10240 : 10752\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 10752 : 11264\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 11264 : 11776\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 11776 : 12288\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 12288 : 12800\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 12800 : 13312\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 13312 : 13824\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 13824 : 14336\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 14336 : 14848\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 14848 : 15360\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 15360 : 15872\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 15872 : 16384\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 16384 : 16896\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 16896 : 17408\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 17408 : 17920\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 17920 : 18432\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 18432 : 18944\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 18944 : 19456\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 19456 : 19968\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 19968 : 20480\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 20480 : 20992\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 20992 : 21504\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 21504 : 22016\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 22016 : 22528\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 22528 : 23040\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 23040 : 23552\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 23552 : 24064\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 24064 : 24576\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 24576 : 25088\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 25088 : 25600\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 25600 : 26112\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 26112 : 26624\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 26624 : 27136\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 27136 : 27648\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 27648 : 28160\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 28160 : 28672\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 28672 : 29184\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 29184 : 29696\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 29696 : 30208\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 30208 : 30720\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n",
      "Processing images 30720 : 31220\n",
      "Generating batches |==================================================| 100% \n",
      "Writing datasets |==================================================| 100% \n"
     ]
    }
   ],
   "source": [
    "gen_params = dict(batch_size  = 1,\n",
    "                  data_path   = images_path,\n",
    "                  input_shape = ('orig',),\n",
    "                  inputs = ['sessionId_imageName'],\n",
    "                  outputs = [['aestheticScore'], ['qualityScore']],\n",
    "                  process_fn  = pre,\n",
    "                  fixed_batches = False)\n",
    "\n",
    "helper = mh.ModelHelper(model, model_name + '_orig', ids,\n",
    "                    features_root = features_root,\n",
    "                    gen_params    = gen_params)\n",
    "\n",
    "# generator = helper.make_generator(ids)\n",
    "# print(generator[0])\n",
    "\n",
    "print('Saving features')\n",
    "batch_size = 512\n",
    "numel = len(ids)\n",
    "print(numel)\n",
    "\n",
    "for i in range(0,numel,batch_size):\n",
    "    istop = min(i+batch_size, numel)\n",
    "    print('Processing images',i,':',istop)\n",
    "    ids_batch = ids[i:istop].reset_index(drop=True)\n",
    "    # print(ids_batch)\n",
    "    helper.save_activations(ids=ids_batch, verbose=True,\\\n",
    "                            groups=1,\n",
    "                            save_as_type=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 24.622 GB\n",
      "Groups:\n",
      "* session100_iaa_pub6931_.jpg/\n",
      "* session100_iaa_pub6932_.jpg/\n",
      "* session100_iaa_pub6933_.jpg/\n",
      "* session100_iaa_pub6934_.jpg/\n",
      "* session100_iaa_pub6935_.jpg/\n",
      "* session100_iaa_pub6936_.jpg/\n",
      "* session100_iaa_pub6937_.jpg/\n",
      "* session100_iaa_pub6938_.jpg/\n",
      "* session100_iaa_pub6939_.jpg/\n",
      "* session100_iaa_pub6940_.jpg/\n",
      "* session100_iaa_pub6941_.jpg/\n",
      "* session100_iaa_pub6942_.jpg/\n",
      "* session100_iaa_pub6943_.jpg/\n",
      "* session100_iaa_pub6944_.jpg/\n",
      "* session100_iaa_pub6945_.jpg/\n",
      "* session100_iaa_pub6946_.jpg/\n",
      "* session100_iaa_pub6947_.jpg/\n",
      "* session100_iaa_pub6948_.jpg/\n",
      "* session100_iaa_pub6949_.jpg/\n",
      "* session100_iaa_pub6950_.jpg/\n",
      "* session100_iaa_pub6951_.jpg/\n",
      "* session100_iaa_pub6952_.jpg/\n",
      "* session100_iaa_pub6953_.jpg/\n",
      "* session100_iaa_pub6954_.jpg/\n",
      "* session100_iaa_pub6955_.jpg/\n",
      "* session100_iaa_pub6956_.jpg/\n",
      "* session100_iaa_pub6957_.jpg/\n",
      "* session100_iaa_pub6958_.jpg/\n",
      "* session100_iaa_pub6959_.jpg/\n",
      "* session100_iaa_pub6960_.jpg/\n",
      "* session100_iaa_pub6961_.jpg/\n",
      "* session100_iaa_pub6962_.jpg/\n",
      "* session100_iaa_pub6963_.jpg/\n",
      "* session100_iaa_pub6964_.jpg/\n",
      "* session100_iaa_pub6965_.jpg/\n",
      "* session100_iaa_pub6966_.jpg/\n",
      "* session100_iaa_pub6967_.jpg/\n",
      "* session100_iaa_pub6968_.jpg/\n",
      "* session100_iaa_pub6969_.jpg/\n",
      "* session100_iaa_pub6970_.jpg/\n",
      "* session100_iaa_pub6971_.jpg/\n",
      "* session100_iaa_pub6972_.jpg/\n",
      "* session100_iaa_pub6973_.jpg/\n",
      "* session100_iaa_pub6974_.jpg/\n",
      "* session100_iaa_pub6975_.jpg/\n",
      "* session100_iaa_pub6976_.jpg/\n",
      "* session100_iaa_pub6977_.jpg/\n",
      "* session100_iaa_pub6978_.jpg/\n",
      "* session100_iaa_pub6979_.jpg/\n",
      "* session100_iaa_pub6980_.jpg/\n",
      "* session100_iaa_pub6981_.jpg/\n",
      "* session100_iaa_pub6982_.jpg/\n",
      "* session100_iaa_pub6983_.jpg/\n",
      "* session100_iaa_pub6984_.jpg/\n",
      "* session100_iaa_pub6985_.jpg/\n",
      "* session100_iaa_pub6986_.jpg/\n",
      "* session100_iaa_pub6987_.jpg/\n",
      "* session100_iaa_pub6988_.jpg/\n",
      "* session100_iaa_pub6989_.jpg/\n",
      "* session100_iaa_pub6990_.jpg/\n",
      "* session100_iaa_pub6991_.jpg/\n",
      "* session100_iaa_pub6992_.jpg/\n",
      "* session100_iaa_pub6993_.jpg/\n",
      "* session100_iaa_pub6994_.jpg/\n",
      "* session100_iaa_pub6995_.jpg/\n",
      "* session100_iaa_pub6996_.jpg/\n",
      "* session100_iaa_pub6997_.jpg/\n",
      "* session100_iaa_pub6998_.jpg/\n",
      "* session100_iaa_pub6999_.jpg/\n",
      "* session100_iaa_pub7000_.jpg/\n",
      "* session101_iaa_pub7001_.jpg/\n",
      "* session101_iaa_pub7002_.jpg/\n",
      "* session101_iaa_pub7003_.jpg/\n",
      "* session101_iaa_pub7004_.jpg/\n",
      "* session101_iaa_pub7005_.jpg/\n",
      "* session101_iaa_pub7006_.jpg/\n",
      "* session101_iaa_pub7007_.jpg/\n",
      "* session101_iaa_pub7008_.jpg/\n",
      "* session101_iaa_pub7009_.jpg/\n",
      "* session101_iaa_pub7010_.jpg/\n",
      "* session101_iaa_pub7011_.jpg/\n",
      "* session101_iaa_pub7012_.jpg/\n",
      "* session101_iaa_pub7013_.jpg/\n",
      "* session101_iaa_pub7014_.jpg/\n",
      "* session101_iaa_pub7015_.jpg/\n",
      "* session101_iaa_pub7016_.jpg/\n",
      "* session101_iaa_pub7017_.jpg/\n",
      "* session101_iaa_pub7018_.jpg/\n",
      "* session101_iaa_pub7019_.jpg/\n",
      "* session101_iaa_pub7020_.jpg/\n",
      "* session101_iaa_pub7021_.jpg/\n",
      "* session101_iaa_pub7022_.jpg/\n",
      "* session101_iaa_pub7023_.jpg/\n",
      "* session101_iaa_pub7024_.jpg/\n",
      "* session101_iaa_pub7025_.jpg/\n",
      "* session101_iaa_pub7026_.jpg/\n",
      "* session101_iaa_pub7027_.jpg/\n",
      "* session101_iaa_pub7028_.jpg/\n",
      "* session101_iaa_pub7029_.jpg/\n",
      "* session101_iaa_pub7030_.jpg/\n",
      "* session101_iaa_pub7031_.jpg/\n",
      "[...] showing 100 of 31220\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# check contents of saved file\n",
    "with generic.H5Helper(features_root + 'irnv2_mlsp_wide_orig/grp:1 i:1[orig] lay:final o:1[5,5,16928].h5','r') as h:\n",
    "    print(h.summary())\n",
    "    # print((list(h.hf.keys())))\n",
    "    # print(h.hf.get('session1_iaa_pub1_.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f336c55dc04d10e265d1690e1fac509afec4a033c9a262091c183b4c57cacd85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
