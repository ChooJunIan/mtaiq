{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Kuti\n"
     ]
    }
   ],
   "source": [
    "import kuti\n",
    "from kuti import model_helper as mh\n",
    "from kuti import applications as apps\n",
    "from kuti import tensor_ops as ops\n",
    "from kuti import generic as gen\n",
    "import pandas as pd, numpy as np, os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET2 Files training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network on GET2 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID for PARA Dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionId</th>\n",
       "      <th>imageName</th>\n",
       "      <th>aestheticScore</th>\n",
       "      <th>qualityScore</th>\n",
       "      <th>sessionId_imageName</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>session1</td>\n",
       "      <td>iaa_pub1_.jpg</td>\n",
       "      <td>3.809524</td>\n",
       "      <td>3.923810</td>\n",
       "      <td>session1_iaa_pub1_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>session1</td>\n",
       "      <td>iaa_pub2_.jpg</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>3.385714</td>\n",
       "      <td>session1_iaa_pub2_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>session1</td>\n",
       "      <td>iaa_pub3_.jpg</td>\n",
       "      <td>2.928571</td>\n",
       "      <td>3.128571</td>\n",
       "      <td>session1_iaa_pub3_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>session1</td>\n",
       "      <td>iaa_pub4_.jpg</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.752381</td>\n",
       "      <td>session1_iaa_pub4_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>session1</td>\n",
       "      <td>iaa_pub5_.jpg</td>\n",
       "      <td>3.214286</td>\n",
       "      <td>3.538095</td>\n",
       "      <td>session1_iaa_pub5_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31215</th>\n",
       "      <td>session340</td>\n",
       "      <td>iaa_pub23744_.jpg</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.608333</td>\n",
       "      <td>session340_iaa_pub23744_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31216</th>\n",
       "      <td>session137</td>\n",
       "      <td>iaa_pub9552_.jpg</td>\n",
       "      <td>3.425000</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>session137_iaa_pub9552_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31217</th>\n",
       "      <td>session256</td>\n",
       "      <td>iaa_pub17866_.jpg</td>\n",
       "      <td>3.023810</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>session256_iaa_pub17866_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31218</th>\n",
       "      <td>session134</td>\n",
       "      <td>iaa_pub9349_.jpg</td>\n",
       "      <td>4.022727</td>\n",
       "      <td>4.154545</td>\n",
       "      <td>session134_iaa_pub9349_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31219</th>\n",
       "      <td>session216</td>\n",
       "      <td>iaa_pub15076_.jpg</td>\n",
       "      <td>2.239130</td>\n",
       "      <td>2.421739</td>\n",
       "      <td>session216_iaa_pub15076_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31220 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sessionId          imageName  aestheticScore  qualityScore  \\\n",
       "0        session1      iaa_pub1_.jpg        3.809524      3.923810   \n",
       "1        session1      iaa_pub2_.jpg        3.142857      3.385714   \n",
       "2        session1      iaa_pub3_.jpg        2.928571      3.128571   \n",
       "3        session1      iaa_pub4_.jpg        3.428571      3.752381   \n",
       "4        session1      iaa_pub5_.jpg        3.214286      3.538095   \n",
       "...           ...                ...             ...           ...   \n",
       "31215  session340  iaa_pub23744_.jpg        3.500000      3.608333   \n",
       "31216  session137   iaa_pub9552_.jpg        3.425000      3.720000   \n",
       "31217  session256  iaa_pub17866_.jpg        3.023810      3.233333   \n",
       "31218  session134   iaa_pub9349_.jpg        4.022727      4.154545   \n",
       "31219  session216  iaa_pub15076_.jpg        2.239130      2.421739   \n",
       "\n",
       "                sessionId_imageName         set  \n",
       "0            session1_iaa_pub1_.jpg    training  \n",
       "1            session1_iaa_pub2_.jpg    training  \n",
       "2            session1_iaa_pub3_.jpg    training  \n",
       "3            session1_iaa_pub4_.jpg    training  \n",
       "4            session1_iaa_pub5_.jpg    training  \n",
       "...                             ...         ...  \n",
       "31215  session340_iaa_pub23744_.jpg  validation  \n",
       "31216   session137_iaa_pub9552_.jpg  validation  \n",
       "31217  session256_iaa_pub17866_.jpg  validation  \n",
       "31218   session134_iaa_pub9349_.jpg  validation  \n",
       "31219  session216_iaa_pub15076_.jpg  validation  \n",
       "\n",
       "[31220 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = '/media/workstation/0832621B32620DCE/Ian/'\n",
    "dataset = root_path + 'mtaiq/PARA_MTAIQ_GET2_official_dataset.csv'\n",
    "ids = pd.read_csv(dataset)\n",
    "\n",
    "print('ID for PARA Dataset')\n",
    "ids\n",
    "\n",
    "# input_shape = (None, None, 3)\n",
    "# features_root = root_path + 'features_get2/'\n",
    "# images_path = '/media/workstation/0832621B32620DCE/PARA_Dataset/PARA'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on MLSP wide features (aestheticScore only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n"
     ]
    }
   ],
   "source": [
    "# features_file = root_path + 'features/irnv2_mlsp_wide_orig/i1[orig]_lfinal_o1[5,5,16928]_r1.h5'\n",
    "features_file = root_path + 'features_get2_baseline_aestheticScore/irnv2_mlsp_wide_orig/grp:1 i:1[orig] lay:final o:1[5,5,16928].h5'\n",
    "\n",
    "fc1_size = 2048\n",
    "image_size = '[orig]'\n",
    "input_size = (5,5,16928)\n",
    "model_name = features_file.split('/')[-2]\n",
    "\n",
    "# loss         = dict(head_aesthetic_out = 'MSE', head_quality_out = 'MSE')\n",
    "# loss_weights = dict(head_aesthetic_out = 1.0,   head_quality_out = 1.0)\n",
    "# metrics      = dict(head_aesthetic_out = ['MAE', ops.plcc_tf], head_quality_out = ['MAE', ops.plcc_tf])\n",
    "\n",
    "loss         = dict(head_aesthetic_out = 'MSE')\n",
    "loss_weights = dict(head_aesthetic_out = 1.0)\n",
    "metrics      = dict(head_aesthetic_out = ['MAE', ops.plcc_tf])\n",
    "\n",
    "bn = 2\n",
    "fc_sizes = [fc1_size, fc1_size/2, fc1_size/8,  1]\n",
    "dropout_rates = [0.25, 0.25, 0.5, 0]\n",
    "\n",
    "monitor_mode = 'max'\n",
    "monitor_metric = 'val_plcc_tf'\n",
    "outputs = ['aestheticScore']\n",
    "\n",
    "# MODEL DEF\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "input_feats = Input(shape=input_size, dtype='float32')\n",
    "\n",
    "# SINGLE-block\n",
    "x = apps.inception_block(input_feats, size=1024)\n",
    "x = GlobalAveragePooling2D(name='final_GAP')(x)\n",
    "\n",
    "pred_aesthetic = apps.fc_layers(x, name       = 'head_aesthetic',\n",
    "                                fc_sizes      = fc_sizes,\n",
    "                                dropout_rates = dropout_rates,\n",
    "                                batch_norm    = bn)\n",
    "\n",
    "# pred_quality = apps.fc_layers(x, name       = 'head_quality',\n",
    "#                               fc_sizes      = fc_sizes,\n",
    "#                               dropout_rates = dropout_rates,\n",
    "#                               batch_norm    = bn)                 \n",
    "\n",
    "model = Model(inputs=input_feats, outputs=pred_aesthetic) #\n",
    "\n",
    "gen_params = dict(batch_size    = 128,\n",
    "                  data_path     = features_file,                  \n",
    "                  input_shape   = input_size,\n",
    "                  inputs        = ['sessionId_imageName'],\n",
    "                  outputs       = outputs, \n",
    "                  random_group  = False,\n",
    "                  fixed_batches = True)\n",
    "\n",
    "helper = mh.ModelHelper(model, model_name, ids, \n",
    "                     max_queue_size = 128,\n",
    "                     loss           = loss,\n",
    "                     metrics        = metrics,\n",
    "                     monitor_metric = monitor_metric, \n",
    "                     monitor_mode   = monitor_mode,\n",
    "                     multiproc      = False, workers = 1,\n",
    "#                      multiproc      = True, workers = 3,\n",
    "                     early_stop_patience = 5,\n",
    "                     logs_root      = root_path + 'logs_get2_aestheticScore_baseline',\n",
    "                     models_root    = root_path + 'models_get2_aestheticScore_baseline',\n",
    "                     gen_params     = gen_params)\n",
    "\n",
    "helper.model_name.update(fc1 = '[%d]' % fc1_size,\n",
    "                         im  = image_size,\n",
    "                         bn  = bn,\n",
    "                         do  = str(dropout_rates).replace(' ',''),\n",
    "                         mon = '[%s]' % monitor_metric,\n",
    "                         ds  = '[%s]' % os.path.split(dataset)[1])\n",
    "\n",
    "print(helper.model_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NOT loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5 does not exist\n",
      "Training model: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 15:57:08.417639: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n",
      "2023-02-01 15:57:14.124277: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 720s 4s/step - loss: 11.8891 - MAE: 3.0640 - plcc_tf: 0.2202 - val_loss: 8.0581 - val_MAE: 2.8010 - val_plcc_tf: 0.5643\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 645s 4s/step - loss: 9.6040 - MAE: 2.7635 - plcc_tf: 0.2574 - val_loss: 6.1734 - val_MAE: 2.4395 - val_plcc_tf: 0.6311\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 508s 3s/step - loss: 7.9656 - MAE: 2.4932 - plcc_tf: 0.2734 - val_loss: 4.9948 - val_MAE: 2.1947 - val_plcc_tf: 0.7057\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 371s 2s/step - loss: 6.5641 - MAE: 2.2317 - plcc_tf: 0.2755 - val_loss: 4.0959 - val_MAE: 1.9710 - val_plcc_tf: 0.6895\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 412s 2s/step - loss: 5.2981 - MAE: 1.9564 - plcc_tf: 0.2805 - val_loss: 2.8016 - val_MAE: 1.6147 - val_plcc_tf: 0.6729\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 360s 2s/step - loss: 4.2814 - MAE: 1.7155 - plcc_tf: 0.2629 - val_loss: 1.7735 - val_MAE: 1.2782 - val_plcc_tf: 0.7878\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 326s 2s/step - loss: 3.4066 - MAE: 1.4895 - plcc_tf: 0.2791 - val_loss: 1.0755 - val_MAE: 0.9742 - val_plcc_tf: 0.7640\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 336s 2s/step - loss: 2.8255 - MAE: 1.3255 - plcc_tf: 0.2873 - val_loss: 0.7708 - val_MAE: 0.8011 - val_plcc_tf: 0.8008\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 296s 2s/step - loss: 2.4464 - MAE: 1.2049 - plcc_tf: 0.2887 - val_loss: 0.5693 - val_MAE: 0.6591 - val_plcc_tf: 0.7496\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 234s 1s/step - loss: 2.1705 - MAE: 1.1285 - plcc_tf: 0.3004 - val_loss: 0.4079 - val_MAE: 0.5431 - val_plcc_tf: 0.7476\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 225s 1s/step - loss: 1.9892 - MAE: 1.0717 - plcc_tf: 0.2994 - val_loss: 0.3821 - val_MAE: 0.5191 - val_plcc_tf: 0.7580\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 248s 1s/step - loss: 1.8366 - MAE: 1.0272 - plcc_tf: 0.3159 - val_loss: 0.2088 - val_MAE: 0.3675 - val_plcc_tf: 0.8011\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 249s 1s/step - loss: 1.6368 - MAE: 0.9677 - plcc_tf: 0.3226 - val_loss: 0.1632 - val_MAE: 0.3281 - val_plcc_tf: 0.8238\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 307s 2s/step - loss: 1.5453 - MAE: 0.9330 - plcc_tf: 0.3370 - val_loss: 0.1423 - val_MAE: 0.3032 - val_plcc_tf: 0.8469\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 254s 1s/step - loss: 1.4348 - MAE: 0.9000 - plcc_tf: 0.3407 - val_loss: 0.1681 - val_MAE: 0.3414 - val_plcc_tf: 0.8374\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 241s 1s/step - loss: 1.3534 - MAE: 0.8661 - plcc_tf: 0.3642 - val_loss: 0.1658 - val_MAE: 0.3287 - val_plcc_tf: 0.8119\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 249s 1s/step - loss: 1.2756 - MAE: 0.8477 - plcc_tf: 0.3653 - val_loss: 0.1383 - val_MAE: 0.3051 - val_plcc_tf: 0.8544\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 245s 1s/step - loss: 1.1874 - MAE: 0.8192 - plcc_tf: 0.3842 - val_loss: 0.1413 - val_MAE: 0.3018 - val_plcc_tf: 0.8535\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 294s 2s/step - loss: 1.0829 - MAE: 0.7785 - plcc_tf: 0.4018 - val_loss: 0.1328 - val_MAE: 0.2921 - val_plcc_tf: 0.8501\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 308s 2s/step - loss: 1.0188 - MAE: 0.7546 - plcc_tf: 0.4085 - val_loss: 0.1197 - val_MAE: 0.2809 - val_plcc_tf: 0.8712\n",
      "Model weights loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5\n",
      "Training model: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n",
      "Epoch 1/20\n",
      "170/170 [==============================] - 308s 2s/step - loss: 0.9969 - MAE: 0.7423 - plcc_tf: 0.4165 - val_loss: 0.0918 - val_MAE: 0.2416 - val_plcc_tf: 0.8836\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 330s 2s/step - loss: 0.9729 - MAE: 0.7346 - plcc_tf: 0.4266 - val_loss: 0.0967 - val_MAE: 0.2486 - val_plcc_tf: 0.8875\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 258s 2s/step - loss: 0.9440 - MAE: 0.7224 - plcc_tf: 0.4336 - val_loss: 0.0883 - val_MAE: 0.2374 - val_plcc_tf: 0.8887\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 257s 2s/step - loss: 0.9379 - MAE: 0.7178 - plcc_tf: 0.4280 - val_loss: 0.0811 - val_MAE: 0.2240 - val_plcc_tf: 0.8881\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 256s 2s/step - loss: 0.9330 - MAE: 0.7184 - plcc_tf: 0.4347 - val_loss: 0.0780 - val_MAE: 0.2195 - val_plcc_tf: 0.8894\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 240s 1s/step - loss: 0.8891 - MAE: 0.7023 - plcc_tf: 0.4406 - val_loss: 0.0774 - val_MAE: 0.2207 - val_plcc_tf: 0.8938\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 251s 1s/step - loss: 0.9009 - MAE: 0.7060 - plcc_tf: 0.4460 - val_loss: 0.0770 - val_MAE: 0.2184 - val_plcc_tf: 0.8948\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 232s 1s/step - loss: 0.9125 - MAE: 0.7065 - plcc_tf: 0.4325 - val_loss: 0.0736 - val_MAE: 0.2123 - val_plcc_tf: 0.8959\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 248s 1s/step - loss: 0.8794 - MAE: 0.6920 - plcc_tf: 0.4514 - val_loss: 0.0755 - val_MAE: 0.2165 - val_plcc_tf: 0.8948\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 264s 2s/step - loss: 0.8772 - MAE: 0.6922 - plcc_tf: 0.4448 - val_loss: 0.0795 - val_MAE: 0.2222 - val_plcc_tf: 0.8938\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 244s 1s/step - loss: 0.8645 - MAE: 0.6899 - plcc_tf: 0.4541 - val_loss: 0.0733 - val_MAE: 0.2124 - val_plcc_tf: 0.8951\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 265s 2s/step - loss: 0.8410 - MAE: 0.6825 - plcc_tf: 0.4604 - val_loss: 0.0721 - val_MAE: 0.2116 - val_plcc_tf: 0.8985\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 256s 2s/step - loss: 0.8266 - MAE: 0.6743 - plcc_tf: 0.4623 - val_loss: 0.0725 - val_MAE: 0.2113 - val_plcc_tf: 0.8993\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 244s 1s/step - loss: 0.8450 - MAE: 0.6792 - plcc_tf: 0.4575 - val_loss: 0.0702 - val_MAE: 0.2066 - val_plcc_tf: 0.8998\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 269s 2s/step - loss: 0.8393 - MAE: 0.6747 - plcc_tf: 0.4620 - val_loss: 0.0755 - val_MAE: 0.2150 - val_plcc_tf: 0.8975\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 256s 2s/step - loss: 0.8120 - MAE: 0.6681 - plcc_tf: 0.4715 - val_loss: 0.0718 - val_MAE: 0.2100 - val_plcc_tf: 0.8990\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 263s 2s/step - loss: 0.8020 - MAE: 0.6656 - plcc_tf: 0.4687 - val_loss: 0.0665 - val_MAE: 0.2020 - val_plcc_tf: 0.9008\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 270s 2s/step - loss: 0.7909 - MAE: 0.6612 - plcc_tf: 0.4746 - val_loss: 0.0653 - val_MAE: 0.2007 - val_plcc_tf: 0.9029\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 237s 1s/step - loss: 0.7861 - MAE: 0.6608 - plcc_tf: 0.4766 - val_loss: 0.0713 - val_MAE: 0.2111 - val_plcc_tf: 0.8991\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 300s 2s/step - loss: 0.7798 - MAE: 0.6535 - plcc_tf: 0.4793 - val_loss: 0.0650 - val_MAE: 0.1978 - val_plcc_tf: 0.9017\n",
      "Model weights loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5\n",
      "Training model: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n",
      "Epoch 1/20\n",
      "170/170 [==============================] - 279s 2s/step - loss: 0.7723 - MAE: 0.6560 - plcc_tf: 0.4764 - val_loss: 0.0649 - val_MAE: 0.1997 - val_plcc_tf: 0.9036\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 257s 2s/step - loss: 0.8004 - MAE: 0.6598 - plcc_tf: 0.4743 - val_loss: 0.0654 - val_MAE: 0.2005 - val_plcc_tf: 0.9045\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 246s 1s/step - loss: 0.7918 - MAE: 0.6582 - plcc_tf: 0.4755 - val_loss: 0.0660 - val_MAE: 0.2015 - val_plcc_tf: 0.9046\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 235s 1s/step - loss: 0.7968 - MAE: 0.6587 - plcc_tf: 0.4741 - val_loss: 0.0655 - val_MAE: 0.2004 - val_plcc_tf: 0.9047\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 264s 2s/step - loss: 0.7785 - MAE: 0.6546 - plcc_tf: 0.4774 - val_loss: 0.0653 - val_MAE: 0.2001 - val_plcc_tf: 0.9047\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 244s 1s/step - loss: 0.7762 - MAE: 0.6579 - plcc_tf: 0.4773 - val_loss: 0.0642 - val_MAE: 0.1984 - val_plcc_tf: 0.9054\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 241s 1s/step - loss: 0.7706 - MAE: 0.6515 - plcc_tf: 0.4871 - val_loss: 0.0647 - val_MAE: 0.1994 - val_plcc_tf: 0.9055\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 238s 1s/step - loss: 0.7885 - MAE: 0.6565 - plcc_tf: 0.4787 - val_loss: 0.0642 - val_MAE: 0.1984 - val_plcc_tf: 0.9059\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 245s 1s/step - loss: 0.7840 - MAE: 0.6592 - plcc_tf: 0.4736 - val_loss: 0.0646 - val_MAE: 0.1993 - val_plcc_tf: 0.9059\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 282s 2s/step - loss: 0.7756 - MAE: 0.6502 - plcc_tf: 0.4730 - val_loss: 0.0639 - val_MAE: 0.1978 - val_plcc_tf: 0.9059\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 275s 2s/step - loss: 0.7837 - MAE: 0.6538 - plcc_tf: 0.4806 - val_loss: 0.0645 - val_MAE: 0.1991 - val_plcc_tf: 0.9060\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 267s 2s/step - loss: 0.7693 - MAE: 0.6495 - plcc_tf: 0.4819 - val_loss: 0.0633 - val_MAE: 0.1969 - val_plcc_tf: 0.9062\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 234s 1s/step - loss: 0.7769 - MAE: 0.6548 - plcc_tf: 0.4759 - val_loss: 0.0640 - val_MAE: 0.1981 - val_plcc_tf: 0.9062\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 268s 2s/step - loss: 0.7766 - MAE: 0.6531 - plcc_tf: 0.4727 - val_loss: 0.0633 - val_MAE: 0.1970 - val_plcc_tf: 0.9064\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 278s 2s/step - loss: 0.7845 - MAE: 0.6567 - plcc_tf: 0.4778 - val_loss: 0.0638 - val_MAE: 0.1978 - val_plcc_tf: 0.9064\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 259s 2s/step - loss: 0.7727 - MAE: 0.6494 - plcc_tf: 0.4847 - val_loss: 0.0631 - val_MAE: 0.1964 - val_plcc_tf: 0.9066\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 264s 2s/step - loss: 0.7556 - MAE: 0.6458 - plcc_tf: 0.4850 - val_loss: 0.0629 - val_MAE: 0.1961 - val_plcc_tf: 0.9067\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 242s 1s/step - loss: 0.7779 - MAE: 0.6529 - plcc_tf: 0.4803 - val_loss: 0.0629 - val_MAE: 0.1963 - val_plcc_tf: 0.9070\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 254s 1s/step - loss: 0.7714 - MAE: 0.6524 - plcc_tf: 0.4714 - val_loss: 0.0633 - val_MAE: 0.1968 - val_plcc_tf: 0.9065\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 299s 2s/step - loss: 0.7792 - MAE: 0.6547 - plcc_tf: 0.4788 - val_loss: 0.0636 - val_MAE: 0.1975 - val_plcc_tf: 0.9071\n"
     ]
    }
   ],
   "source": [
    "for lr in [1e-4,1e-5,1e-6]:\n",
    "    helper.load_model()\n",
    "    helper.train(lr=lr, epochs=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training\n",
      "Model weights loaded: /media/workstation/0832621B32620DCE/Ian/models/irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE,MSE] mon:[val_head_aesthetic_out_plcc_tf] o:2[1]_best_weights.h5\n",
      "Validating performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 13:50:06.698276: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n",
      "2023-01-31 13:50:14.044455: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 180s - loss: 0.1228 - head_aesthetic_out_loss: 0.0621 - head_quality_out_loss: 0.0607 - head_aesthetic_out_MAE: 0.1966 - head_aesthetic_out_plcc_tf: 0.9137 - head_quality_out_MAE: 0.1931 - head_quality_out_plcc_tf: 0.9188 - 180s/epoch - 5s/step\n",
      "head_aesthetic_out_MAE:     0.19663752615451813\n",
      "head_aesthetic_out_loss:    0.062127988785505295\n",
      "head_aesthetic_out_plcc_tf: 0.9137099385261536\n",
      "head_quality_out_MAE:       0.19310589134693146\n",
      "head_quality_out_loss:      0.060700468719005585\n",
      "head_quality_out_plcc_tf:   0.9187530875205994\n",
      "loss:                       0.12282846868038177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.12282846868038177,\n",
       " 'head_aesthetic_out_loss': 0.062127988785505295,\n",
       " 'head_quality_out_loss': 0.060700468719005585,\n",
       " 'head_aesthetic_out_MAE': 0.19663752615451813,\n",
       " 'head_aesthetic_out_plcc_tf': 0.9137099385261536,\n",
       " 'head_quality_out_MAE': 0.19310589134693146,\n",
       " 'head_quality_out_plcc_tf': 0.9187530875205994}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('After training')\n",
    "\n",
    "helper.load_model(root_path + 'models/irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE,MSE] mon:[val_head_aesthetic_out_plcc_tf] o:2[1]')\n",
    "test_gen = helper.make_generator(ids[ids.set=='test'])\n",
    "helper.validate(test_gen, verbose=2)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on MLSP wide features (qualityScore only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 20:45:53.274957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 20:45:53.926657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 20:45:53.926864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 20:45:53.927350: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-05 20:45:53.981531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 20:45:53.981833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 20:45:53.981973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 20:46:01.164121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 20:46:01.164316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 20:46:01.164456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 20:46:01.164831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9943 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n"
     ]
    }
   ],
   "source": [
    "# features_file = root_path + 'features/irnv2_mlsp_wide_orig/i1[orig]_lfinal_o1[5,5,16928]_r1.h5'\n",
    "features_file = root_path + 'features_get2_baseline_qualityScore/irnv2_mlsp_wide_orig/grp:1 i:1[orig] lay:final o:1[5,5,16928].h5'\n",
    "\n",
    "fc1_size = 2048\n",
    "image_size = '[orig]'\n",
    "input_size = (5,5,16928)\n",
    "model_name = features_file.split('/')[-2]\n",
    "\n",
    "# loss         = dict(head_aesthetic_out = 'MSE', head_quality_out = 'MSE')\n",
    "# loss_weights = dict(head_aesthetic_out = 1.0,   head_quality_out = 1.0)\n",
    "# metrics      = dict(head_aesthetic_out = ['MAE', ops.plcc_tf], head_quality_out = ['MAE', ops.plcc_tf])\n",
    "\n",
    "loss         = dict(head_quality_out = 'MSE')\n",
    "loss_weights = dict(head_quality_out = 1.0)\n",
    "metrics      = dict(head_quality_out = ['MAE', ops.plcc_tf])\n",
    "\n",
    "bn = 2\n",
    "fc_sizes = [fc1_size, fc1_size/2, fc1_size/8,  1]\n",
    "dropout_rates = [0.25, 0.25, 0.5, 0]\n",
    "\n",
    "monitor_mode = 'max'\n",
    "monitor_metric = 'val_plcc_tf'\n",
    "outputs = ['qualityScore']\n",
    "\n",
    "# MODEL DEF\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "input_feats = Input(shape=input_size, dtype='float32')\n",
    "\n",
    "# SINGLE-block\n",
    "x = apps.inception_block(input_feats, size=1024)\n",
    "x = GlobalAveragePooling2D(name='final_GAP')(x)\n",
    "\n",
    "# pred_aesthetic = apps.fc_layers(x, name       = 'head_aesthetic',\n",
    "#                                 fc_sizes      = fc_sizes,\n",
    "#                                 dropout_rates = dropout_rates,\n",
    "#                                 batch_norm    = bn)\n",
    "\n",
    "pred_quality = apps.fc_layers(x, name       = 'head_quality',\n",
    "                              fc_sizes      = fc_sizes,\n",
    "                              dropout_rates = dropout_rates,\n",
    "                              batch_norm    = bn)                 \n",
    "\n",
    "model = Model(inputs=input_feats, outputs=pred_quality) #\n",
    "\n",
    "gen_params = dict(batch_size    = 128,\n",
    "                  data_path     = features_file,                  \n",
    "                  input_shape   = input_size,\n",
    "                  inputs        = ['sessionId_imageName'],\n",
    "                  outputs       = outputs, \n",
    "                  random_group  = False,\n",
    "                  fixed_batches = True)\n",
    "\n",
    "helper = mh.ModelHelper(model, model_name, ids, \n",
    "                     max_queue_size = 128,\n",
    "                     loss           = loss,\n",
    "                     metrics        = metrics,\n",
    "                     monitor_metric = monitor_metric, \n",
    "                     monitor_mode   = monitor_mode,\n",
    "                     multiproc      = False, workers = 1,\n",
    "#                      multiproc      = True, workers = 3,\n",
    "                     early_stop_patience = 5,\n",
    "                     logs_root      = root_path + 'logs_get2_qualityScore_retrain_baseline',\n",
    "                     models_root    = root_path + 'models_get2_qualityScore_baseline',\n",
    "                     gen_params     = gen_params)\n",
    "\n",
    "helper.model_name.update(fc1 = '[%d]' % fc1_size,\n",
    "                         im  = image_size,\n",
    "                         bn  = bn,\n",
    "                         do  = str(dropout_rates).replace(' ',''),\n",
    "                         mon = '[%s]' % monitor_metric,\n",
    "                         ds  = '[%s]' % os.path.split(dataset)[1])\n",
    "\n",
    "print(helper.model_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NOT loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5 does not exist\n",
      "Training model: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 20:46:10.753156: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n",
      "2023-02-05 20:46:17.520056: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 317s 2s/step - loss: 12.8811 - MAE: 3.2265 - plcc_tf: 0.2302 - val_loss: 8.8822 - val_MAE: 2.9303 - val_plcc_tf: 0.4034\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 333s 2s/step - loss: 10.5955 - MAE: 2.9462 - plcc_tf: 0.2629 - val_loss: 6.7568 - val_MAE: 2.5644 - val_plcc_tf: 0.6987\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 354s 2s/step - loss: 8.7738 - MAE: 2.6531 - plcc_tf: 0.2770 - val_loss: 6.0636 - val_MAE: 2.4210 - val_plcc_tf: 0.6973\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 335s 2s/step - loss: 7.2233 - MAE: 2.3696 - plcc_tf: 0.2757 - val_loss: 5.1662 - val_MAE: 2.2360 - val_plcc_tf: 0.7345\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 372s 2s/step - loss: 5.8981 - MAE: 2.0927 - plcc_tf: 0.2827 - val_loss: 4.0653 - val_MAE: 1.9753 - val_plcc_tf: 0.7683\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 451s 3s/step - loss: 4.6163 - MAE: 1.8057 - plcc_tf: 0.2838 - val_loss: 2.5257 - val_MAE: 1.5361 - val_plcc_tf: 0.7422\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 451s 3s/step - loss: 3.7706 - MAE: 1.5757 - plcc_tf: 0.2758 - val_loss: 1.6886 - val_MAE: 1.2354 - val_plcc_tf: 0.7383\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 302s 2s/step - loss: 3.1486 - MAE: 1.4014 - plcc_tf: 0.2762 - val_loss: 0.9162 - val_MAE: 0.8918 - val_plcc_tf: 0.7743\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 278s 2s/step - loss: 2.6179 - MAE: 1.2617 - plcc_tf: 0.2847 - val_loss: 0.5496 - val_MAE: 0.6662 - val_plcc_tf: 0.7360\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 312s 2s/step - loss: 2.3185 - MAE: 1.1739 - plcc_tf: 0.2880 - val_loss: 0.5295 - val_MAE: 0.6502 - val_plcc_tf: 0.7924\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 336s 2s/step - loss: 2.1596 - MAE: 1.1248 - plcc_tf: 0.2956 - val_loss: 0.3172 - val_MAE: 0.4738 - val_plcc_tf: 0.7952\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 380s 2s/step - loss: 1.9581 - MAE: 1.0663 - plcc_tf: 0.3089 - val_loss: 0.2155 - val_MAE: 0.3918 - val_plcc_tf: 0.8264\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 319s 2s/step - loss: 1.8048 - MAE: 1.0235 - plcc_tf: 0.3092 - val_loss: 0.1964 - val_MAE: 0.3692 - val_plcc_tf: 0.8279\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 286s 2s/step - loss: 1.6929 - MAE: 0.9830 - plcc_tf: 0.3193 - val_loss: 0.1780 - val_MAE: 0.3503 - val_plcc_tf: 0.8401\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 298s 2s/step - loss: 1.5289 - MAE: 0.9415 - plcc_tf: 0.3429 - val_loss: 0.1807 - val_MAE: 0.3588 - val_plcc_tf: 0.8504\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 284s 2s/step - loss: 1.4585 - MAE: 0.9110 - plcc_tf: 0.3483 - val_loss: 0.2148 - val_MAE: 0.3735 - val_plcc_tf: 0.8184\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 320s 2s/step - loss: 1.3319 - MAE: 0.8744 - plcc_tf: 0.3619 - val_loss: 0.1330 - val_MAE: 0.2976 - val_plcc_tf: 0.8711\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 288s 2s/step - loss: 1.2666 - MAE: 0.8497 - plcc_tf: 0.3734 - val_loss: 0.1619 - val_MAE: 0.3360 - val_plcc_tf: 0.8365\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 227s 1s/step - loss: 1.1787 - MAE: 0.8187 - plcc_tf: 0.3850 - val_loss: 0.1086 - val_MAE: 0.2659 - val_plcc_tf: 0.8584\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 230s 1s/step - loss: 1.1038 - MAE: 0.7932 - plcc_tf: 0.3957 - val_loss: 0.1286 - val_MAE: 0.2940 - val_plcc_tf: 0.8606\n",
      "Model weights loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5\n",
      "Training model: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n",
      "Epoch 1/20\n",
      "170/170 [==============================] - 221s 1s/step - loss: 1.2984 - MAE: 0.8582 - plcc_tf: 0.3719 - val_loss: 0.1327 - val_MAE: 0.3032 - val_plcc_tf: 0.8741\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 250s 1s/step - loss: 1.2590 - MAE: 0.8432 - plcc_tf: 0.3854 - val_loss: 0.1219 - val_MAE: 0.2871 - val_plcc_tf: 0.8775\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 296s 2s/step - loss: 1.2574 - MAE: 0.8414 - plcc_tf: 0.3813 - val_loss: 0.1158 - val_MAE: 0.2790 - val_plcc_tf: 0.8845\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 286s 2s/step - loss: 1.2481 - MAE: 0.8401 - plcc_tf: 0.3845 - val_loss: 0.1063 - val_MAE: 0.2648 - val_plcc_tf: 0.8881\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 321s 2s/step - loss: 1.2224 - MAE: 0.8272 - plcc_tf: 0.3835 - val_loss: 0.1032 - val_MAE: 0.2603 - val_plcc_tf: 0.8912\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 303s 2s/step - loss: 1.1964 - MAE: 0.8241 - plcc_tf: 0.3867 - val_loss: 0.0971 - val_MAE: 0.2524 - val_plcc_tf: 0.8915\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 328s 2s/step - loss: 1.1759 - MAE: 0.8129 - plcc_tf: 0.3974 - val_loss: 0.1009 - val_MAE: 0.2584 - val_plcc_tf: 0.8912\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 286s 2s/step - loss: 1.1855 - MAE: 0.8181 - plcc_tf: 0.3967 - val_loss: 0.0972 - val_MAE: 0.2516 - val_plcc_tf: 0.8924\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 317s 2s/step - loss: 1.1437 - MAE: 0.8026 - plcc_tf: 0.3952 - val_loss: 0.0886 - val_MAE: 0.2355 - val_plcc_tf: 0.8924\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 282s 2s/step - loss: 1.1455 - MAE: 0.8010 - plcc_tf: 0.3976 - val_loss: 0.0983 - val_MAE: 0.2524 - val_plcc_tf: 0.8907\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 312s 2s/step - loss: 1.1090 - MAE: 0.7920 - plcc_tf: 0.4070 - val_loss: 0.0913 - val_MAE: 0.2424 - val_plcc_tf: 0.8928\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 262s 2s/step - loss: 1.1200 - MAE: 0.7962 - plcc_tf: 0.4050 - val_loss: 0.0888 - val_MAE: 0.2382 - val_plcc_tf: 0.8908\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 276s 2s/step - loss: 1.1078 - MAE: 0.7900 - plcc_tf: 0.4018 - val_loss: 0.0863 - val_MAE: 0.2343 - val_plcc_tf: 0.8903\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 300s 2s/step - loss: 1.1122 - MAE: 0.7901 - plcc_tf: 0.4017 - val_loss: 0.0875 - val_MAE: 0.2345 - val_plcc_tf: 0.8938\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 274s 2s/step - loss: 1.0979 - MAE: 0.7810 - plcc_tf: 0.4127 - val_loss: 0.0824 - val_MAE: 0.2275 - val_plcc_tf: 0.8958\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 267s 2s/step - loss: 1.0460 - MAE: 0.7720 - plcc_tf: 0.4158 - val_loss: 0.0854 - val_MAE: 0.2345 - val_plcc_tf: 0.8994\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 248s 1s/step - loss: 1.0525 - MAE: 0.7725 - plcc_tf: 0.4169 - val_loss: 0.0811 - val_MAE: 0.2251 - val_plcc_tf: 0.8941\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 267s 2s/step - loss: 1.0404 - MAE: 0.7653 - plcc_tf: 0.4094 - val_loss: 0.0794 - val_MAE: 0.2237 - val_plcc_tf: 0.8978\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 273s 2s/step - loss: 1.0270 - MAE: 0.7620 - plcc_tf: 0.4209 - val_loss: 0.0803 - val_MAE: 0.2269 - val_plcc_tf: 0.8999\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 261s 2s/step - loss: 0.9978 - MAE: 0.7499 - plcc_tf: 0.4287 - val_loss: 0.0782 - val_MAE: 0.2221 - val_plcc_tf: 0.9009\n",
      "Model weights loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5\n",
      "Training model: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n",
      "Epoch 1/20\n",
      "170/170 [==============================] - 340s 2s/step - loss: 1.0243 - MAE: 0.7539 - plcc_tf: 0.4258 - val_loss: 0.0775 - val_MAE: 0.2212 - val_plcc_tf: 0.9023\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 335s 2s/step - loss: 0.9899 - MAE: 0.7430 - plcc_tf: 0.4273 - val_loss: 0.0762 - val_MAE: 0.2196 - val_plcc_tf: 0.9031\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 387s 2s/step - loss: 0.9985 - MAE: 0.7484 - plcc_tf: 0.4393 - val_loss: 0.0746 - val_MAE: 0.2171 - val_plcc_tf: 0.9036\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 340s 2s/step - loss: 1.0074 - MAE: 0.7538 - plcc_tf: 0.4237 - val_loss: 0.0752 - val_MAE: 0.2181 - val_plcc_tf: 0.9037\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 308s 2s/step - loss: 0.9996 - MAE: 0.7477 - plcc_tf: 0.4220 - val_loss: 0.0743 - val_MAE: 0.2162 - val_plcc_tf: 0.9041\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 262s 2s/step - loss: 1.0080 - MAE: 0.7528 - plcc_tf: 0.4263 - val_loss: 0.0743 - val_MAE: 0.2165 - val_plcc_tf: 0.9042\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 260s 2s/step - loss: 0.9806 - MAE: 0.7449 - plcc_tf: 0.4297 - val_loss: 0.0742 - val_MAE: 0.2163 - val_plcc_tf: 0.9046\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 311s 2s/step - loss: 0.9933 - MAE: 0.7482 - plcc_tf: 0.4334 - val_loss: 0.0748 - val_MAE: 0.2174 - val_plcc_tf: 0.9046\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 279s 2s/step - loss: 0.9963 - MAE: 0.7485 - plcc_tf: 0.4353 - val_loss: 0.0751 - val_MAE: 0.2181 - val_plcc_tf: 0.9048\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 254s 1s/step - loss: 0.9902 - MAE: 0.7473 - plcc_tf: 0.4316 - val_loss: 0.0754 - val_MAE: 0.2186 - val_plcc_tf: 0.9053\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 236s 1s/step - loss: 1.0089 - MAE: 0.7504 - plcc_tf: 0.4241 - val_loss: 0.0749 - val_MAE: 0.2177 - val_plcc_tf: 0.9051\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 257s 2s/step - loss: 0.9871 - MAE: 0.7434 - plcc_tf: 0.4308 - val_loss: 0.0745 - val_MAE: 0.2169 - val_plcc_tf: 0.9053\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 284s 2s/step - loss: 1.0001 - MAE: 0.7488 - plcc_tf: 0.4262 - val_loss: 0.0744 - val_MAE: 0.2167 - val_plcc_tf: 0.9053\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 263s 2s/step - loss: 1.0019 - MAE: 0.7447 - plcc_tf: 0.4229 - val_loss: 0.0745 - val_MAE: 0.2163 - val_plcc_tf: 0.9053\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 307s 2s/step - loss: 0.9920 - MAE: 0.7475 - plcc_tf: 0.4341 - val_loss: 0.0745 - val_MAE: 0.2166 - val_plcc_tf: 0.9056\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 239s 1s/step - loss: 0.9786 - MAE: 0.7438 - plcc_tf: 0.4397 - val_loss: 0.0739 - val_MAE: 0.2162 - val_plcc_tf: 0.9058\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 268s 2s/step - loss: 0.9805 - MAE: 0.7416 - plcc_tf: 0.4343 - val_loss: 0.0733 - val_MAE: 0.2150 - val_plcc_tf: 0.9057\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 248s 1s/step - loss: 0.9688 - MAE: 0.7378 - plcc_tf: 0.4271 - val_loss: 0.0738 - val_MAE: 0.2158 - val_plcc_tf: 0.9058\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 289s 2s/step - loss: 0.9794 - MAE: 0.7415 - plcc_tf: 0.4328 - val_loss: 0.0740 - val_MAE: 0.2165 - val_plcc_tf: 0.9063\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 251s 1s/step - loss: 0.9746 - MAE: 0.7426 - plcc_tf: 0.4357 - val_loss: 0.0736 - val_MAE: 0.2163 - val_plcc_tf: 0.9059\n"
     ]
    }
   ],
   "source": [
    "for lr in [1e-4,1e-5,1e-6]:\n",
    "    helper.load_model()\n",
    "    helper.train(lr=lr, epochs=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training\n",
      "Model weights loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET2_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5\n",
      "Validating performance\n",
      "36/36 - 124s - loss: 0.0687 - MAE: 0.2075 - plcc_tf: 0.9129 - 124s/epoch - 3s/step\n",
      "MAE:     0.20753511786460876\n",
      "loss:    0.06866291910409927\n",
      "plcc_tf: 0.9129168391227722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.06866291910409927,\n",
       " 'MAE': 0.20753511786460876,\n",
       " 'plcc_tf': 0.9129168391227722}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('After training')\n",
    "\n",
    "helper.load_model()\n",
    "test_gen = helper.make_generator(ids[ids.set=='test'])\n",
    "helper.validate(test_gen, verbose=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET3 Files training\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network on GET3 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID for PARA Dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionId</th>\n",
       "      <th>imageName</th>\n",
       "      <th>aestheticScore</th>\n",
       "      <th>qualityScore</th>\n",
       "      <th>sessionId_imageName</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>session1</td>\n",
       "      <td>iaa_pub2_.jpg</td>\n",
       "      <td>3.104167</td>\n",
       "      <td>3.341667</td>\n",
       "      <td>session1_iaa_pub2_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>session1</td>\n",
       "      <td>iaa_pub5_.jpg</td>\n",
       "      <td>3.187500</td>\n",
       "      <td>3.491667</td>\n",
       "      <td>session1_iaa_pub5_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>session1</td>\n",
       "      <td>iaa_pub6_.jpg</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>session1_iaa_pub6_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>session1</td>\n",
       "      <td>iaa_pub9_.jpg</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>2.904167</td>\n",
       "      <td>session1_iaa_pub9_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>session1</td>\n",
       "      <td>iaa_pub10_.jpg</td>\n",
       "      <td>2.895833</td>\n",
       "      <td>3.158333</td>\n",
       "      <td>session1_iaa_pub10_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31215</th>\n",
       "      <td>session5</td>\n",
       "      <td>iaa_pub296_.jpg</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>3.952000</td>\n",
       "      <td>session5_iaa_pub296_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31216</th>\n",
       "      <td>session14</td>\n",
       "      <td>iaa_pub922_.jpg</td>\n",
       "      <td>4.152174</td>\n",
       "      <td>4.226087</td>\n",
       "      <td>session14_iaa_pub922_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31217</th>\n",
       "      <td>session331</td>\n",
       "      <td>iaa_pub23123_.jpg</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>3.848000</td>\n",
       "      <td>session331_iaa_pub23123_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31218</th>\n",
       "      <td>session225</td>\n",
       "      <td>iaa_pub15749_.jpg</td>\n",
       "      <td>3.041667</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>session225_iaa_pub15749_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31219</th>\n",
       "      <td>session93</td>\n",
       "      <td>iaa_pub6488_.jpg</td>\n",
       "      <td>3.134615</td>\n",
       "      <td>3.311538</td>\n",
       "      <td>session93_iaa_pub6488_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31220 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sessionId          imageName  aestheticScore  qualityScore  \\\n",
       "0        session1      iaa_pub2_.jpg        3.104167      3.341667   \n",
       "1        session1      iaa_pub5_.jpg        3.187500      3.491667   \n",
       "2        session1      iaa_pub6_.jpg        3.562500      3.866667   \n",
       "3        session1      iaa_pub9_.jpg        2.625000      2.904167   \n",
       "4        session1     iaa_pub10_.jpg        2.895833      3.158333   \n",
       "...           ...                ...             ...           ...   \n",
       "31215    session5    iaa_pub296_.jpg        3.840000      3.952000   \n",
       "31216   session14    iaa_pub922_.jpg        4.152174      4.226087   \n",
       "31217  session331  iaa_pub23123_.jpg        3.820000      3.848000   \n",
       "31218  session225  iaa_pub15749_.jpg        3.041667      3.150000   \n",
       "31219   session93   iaa_pub6488_.jpg        3.134615      3.311538   \n",
       "\n",
       "                sessionId_imageName         set  \n",
       "0            session1_iaa_pub2_.jpg    training  \n",
       "1            session1_iaa_pub5_.jpg    training  \n",
       "2            session1_iaa_pub6_.jpg    training  \n",
       "3            session1_iaa_pub9_.jpg    training  \n",
       "4           session1_iaa_pub10_.jpg    training  \n",
       "...                             ...         ...  \n",
       "31215      session5_iaa_pub296_.jpg  validation  \n",
       "31216     session14_iaa_pub922_.jpg  validation  \n",
       "31217  session331_iaa_pub23123_.jpg  validation  \n",
       "31218  session225_iaa_pub15749_.jpg  validation  \n",
       "31219    session93_iaa_pub6488_.jpg  validation  \n",
       "\n",
       "[31220 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "root_path = '/media/workstation/0832621B32620DCE/Ian/'\n",
    "dataset = root_path + 'mtaiq/PARA_MTAIQ_GET3_official_dataset.csv'\n",
    "ids = pd.read_csv(dataset)\n",
    "\n",
    "print('ID for PARA Dataset')\n",
    "ids\n",
    "\n",
    "# input_shape = (None, None, 3)\n",
    "# features_root = root_path + 'features_get3/'\n",
    "# images_path = '/media/workstation/0832621B32620DCE/PARA_Dataset/PARA'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on MLSP wide features (aestheticScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET3_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n"
     ]
    }
   ],
   "source": [
    "# features_file = root_path + 'features/irnv2_mlsp_wide_orig/i1[orig]_lfinal_o1[5,5,16928]_r1.h5'\n",
    "features_file = root_path + 'features_get3_baseline_aestheticsScore/irnv2_mlsp_wide_orig/grp:1 i:1[orig] lay:final o:1[5,5,16928].h5'\n",
    "\n",
    "fc1_size = 2048\n",
    "image_size = '[orig]'\n",
    "input_size = (5,5,16928)\n",
    "model_name = features_file.split('/')[-2]\n",
    "\n",
    "# loss         = dict(head_aesthetic_out = 'MSE', head_quality_out = 'MSE')\n",
    "# loss_weights = dict(head_aesthetic_out = 1.0,   head_quality_out = 1.0)\n",
    "# metrics      = dict(head_aesthetic_out = ['MAE', ops.plcc_tf], head_quality_out = ['MAE', ops.plcc_tf])\n",
    "\n",
    "loss         = dict(head_aesthetic_out = 'MSE')\n",
    "loss_weights = dict(head_aesthetic_out = 1.0)\n",
    "metrics      = dict(head_aesthetic_out = ['MAE', ops.plcc_tf])\n",
    "\n",
    "bn = 2\n",
    "fc_sizes = [fc1_size, fc1_size/2, fc1_size/8,  1]\n",
    "dropout_rates = [0.25, 0.25, 0.5, 0]\n",
    "\n",
    "# monitor_metric = 'val_plcc_tf'; \n",
    "monitor_mode = 'max'\n",
    "monitor_metric = 'val_plcc_tf'\n",
    "outputs = ['aestheticScore']\n",
    "\n",
    "# MODEL DEF\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "input_feats = Input(shape=input_size, dtype='float32')\n",
    "\n",
    "# SINGLE-block\n",
    "x = apps.inception_block(input_feats, size=1024)\n",
    "x = GlobalAveragePooling2D(name='final_GAP')(x)\n",
    "\n",
    "pred_aesthetic = apps.fc_layers(x, name       = 'head_aesthetic',\n",
    "                                fc_sizes      = fc_sizes,\n",
    "                                dropout_rates = dropout_rates,\n",
    "                                batch_norm    = bn)\n",
    "\n",
    "# pred_quality = apps.fc_layers(x, name       = 'head_quality',\n",
    "#                               fc_sizes      = fc_sizes,\n",
    "#                               dropout_rates = dropout_rates,\n",
    "#                               batch_norm    = bn)                 \n",
    "\n",
    "model = Model(inputs=input_feats, outputs=pred_aesthetic) #\n",
    "\n",
    "gen_params = dict(batch_size    = 128,\n",
    "                  data_path     = features_file,                  \n",
    "                  input_shape   = input_size,\n",
    "                  inputs        = ['sessionId_imageName'],\n",
    "                  outputs       = outputs, \n",
    "                  random_group  = False,\n",
    "                  fixed_batches = True)\n",
    "\n",
    "helper = mh.ModelHelper(model, model_name, ids, \n",
    "                     max_queue_size = 128,\n",
    "                     loss           = loss,\n",
    "                     metrics        = metrics,\n",
    "                     monitor_metric = monitor_metric, \n",
    "                     monitor_mode   = monitor_mode,\n",
    "                     multiproc      = False, workers = 1,\n",
    "#                      multiproc      = True, workers = 3,\n",
    "                     early_stop_patience = 5,\n",
    "                     logs_root      = root_path + 'logs_get3_aestheticScore_baseline',\n",
    "                     models_root    = root_path + 'models_get3_aestheticScore_baseline',\n",
    "                     gen_params     = gen_params)\n",
    "\n",
    "helper.model_name.update(fc1 = '[%d]' % fc1_size,\n",
    "                         im  = image_size,\n",
    "                         bn  = bn,\n",
    "                         do  = str(dropout_rates).replace(' ',''),\n",
    "                         mon = '[%s]' % monitor_metric,\n",
    "                         ds  = '[%s]' % os.path.split(dataset)[1])\n",
    "\n",
    "print(helper.model_name())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on MLSP wide features (qualityScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 07:17:06.159372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET3_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 07:17:06.197251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 07:17:06.197406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 07:17:06.198394: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-01 07:17:06.198883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 07:17:06.199103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 07:17:06.199232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 07:17:06.652170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 07:17:06.652372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 07:17:06.652504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 07:17:06.652619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9959 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# features_file = root_path + 'features/irnv2_mlsp_wide_orig/i1[orig]_lfinal_o1[5,5,16928]_r1.h5'\n",
    "features_file = root_path + 'features_get3_baseline_qualityScore/irnv2_mlsp_wide_orig/grp:1 i:1[orig] lay:final o:1[5,5,16928].h5'\n",
    "\n",
    "fc1_size = 2048\n",
    "image_size = '[orig]'\n",
    "input_size = (5,5,16928)\n",
    "model_name = features_file.split('/')[-2]\n",
    "\n",
    "# loss         = dict(head_aesthetic_out = 'MSE', head_quality_out = 'MSE')\n",
    "# loss_weights = dict(head_aesthetic_out = 1.0,   head_quality_out = 1.0)\n",
    "# metrics      = dict(head_aesthetic_out = ['MAE', ops.plcc_tf], head_quality_out = ['MAE', ops.plcc_tf])\n",
    "\n",
    "loss         = dict(head_quality_out = 'MSE')\n",
    "loss_weights = dict(head_quality_out = 1.0)\n",
    "metrics      = dict(head_quality_out = ['MAE', ops.plcc_tf])\n",
    "\n",
    "bn = 2\n",
    "fc_sizes = [fc1_size, fc1_size/2, fc1_size/8,  1]\n",
    "dropout_rates = [0.25, 0.25, 0.5, 0]\n",
    "\n",
    "monitor_mode = 'max'\n",
    "monitor_metric = 'val_plcc_tf'\n",
    "outputs = ['qualityScore']\n",
    "\n",
    "# MODEL DEF\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "input_feats = Input(shape=input_size, dtype='float32')\n",
    "\n",
    "# SINGLE-block\n",
    "x = apps.inception_block(input_feats, size=1024)\n",
    "x = GlobalAveragePooling2D(name='final_GAP')(x)\n",
    "\n",
    "# pred_aesthetic = apps.fc_layers(x, name       = 'head_aesthetic',\n",
    "#                                 fc_sizes      = fc_sizes,\n",
    "#                                 dropout_rates = dropout_rates,\n",
    "#                                 batch_norm    = bn)\n",
    "\n",
    "pred_quality = apps.fc_layers(x, name       = 'head_quality',\n",
    "                              fc_sizes      = fc_sizes,\n",
    "                              dropout_rates = dropout_rates,\n",
    "                              batch_norm    = bn)                 \n",
    "\n",
    "model = Model(inputs=input_feats, outputs=pred_quality) #\n",
    "\n",
    "gen_params = dict(batch_size    = 128,\n",
    "                  data_path     = features_file,                  \n",
    "                  input_shape   = input_size,\n",
    "                  inputs        = ['sessionId_imageName'],\n",
    "                  outputs       = outputs, \n",
    "                  random_group  = False,\n",
    "                  fixed_batches = True)\n",
    "\n",
    "helper = mh.ModelHelper(model, model_name, ids, \n",
    "                     max_queue_size = 128,\n",
    "                     loss           = loss,\n",
    "                     metrics        = metrics,\n",
    "                     monitor_metric = monitor_metric, \n",
    "                     monitor_mode   = monitor_mode,\n",
    "                     multiproc      = False, workers = 1,\n",
    "#                      multiproc      = True, workers = 3,\n",
    "                     early_stop_patience = 5,\n",
    "                     logs_root      = root_path + 'logs_get3_qualityScore_baseline',\n",
    "                     models_root    = root_path + 'models_get3_aestheticScore_baseline',\n",
    "                     gen_params     = gen_params)\n",
    "\n",
    "helper.model_name.update(fc1 = '[%d]' % fc1_size,\n",
    "                         im  = image_size,\n",
    "                         bn  = bn,\n",
    "                         do  = str(dropout_rates).replace(' ',''),\n",
    "                         mon = '[%s]' % monitor_metric,\n",
    "                         ds  = '[%s]' % os.path.split(dataset)[1])\n",
    "\n",
    "print(helper.model_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NOT loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET3_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5 does not exist\n",
      "Training model: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET3_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 07:17:49.217855: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n",
      "2023-02-01 07:17:49.609646: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 789s 5s/step - loss: 12.6764 - MAE: 3.2077 - plcc_tf: 0.2337 - val_loss: 8.4352 - val_MAE: 2.8468 - val_plcc_tf: 0.3229\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 713s 4s/step - loss: 10.2765 - MAE: 2.9030 - plcc_tf: 0.2687 - val_loss: 7.0993 - val_MAE: 2.6254 - val_plcc_tf: 0.6558\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 459s 3s/step - loss: 8.6412 - MAE: 2.6383 - plcc_tf: 0.2752 - val_loss: 5.5962 - val_MAE: 2.3135 - val_plcc_tf: 0.6507\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 413s 2s/step - loss: 7.1204 - MAE: 2.3579 - plcc_tf: 0.2827 - val_loss: 4.2475 - val_MAE: 2.0194 - val_plcc_tf: 0.7652\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 339s 2s/step - loss: 5.7935 - MAE: 2.0798 - plcc_tf: 0.2877 - val_loss: 3.3531 - val_MAE: 1.7955 - val_plcc_tf: 0.7799\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 342s 2s/step - loss: 4.6548 - MAE: 1.8129 - plcc_tf: 0.2877 - val_loss: 2.1647 - val_MAE: 1.4243 - val_plcc_tf: 0.7682\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 422s 2s/step - loss: 3.7635 - MAE: 1.5790 - plcc_tf: 0.2746 - val_loss: 1.5691 - val_MAE: 1.1920 - val_plcc_tf: 0.7142\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 365s 2s/step - loss: 3.0763 - MAE: 1.3820 - plcc_tf: 0.2792 - val_loss: 0.9374 - val_MAE: 0.9006 - val_plcc_tf: 0.7829\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 421s 2s/step - loss: 2.5497 - MAE: 1.2340 - plcc_tf: 0.2970 - val_loss: 0.6890 - val_MAE: 0.7544 - val_plcc_tf: 0.7205\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 378s 2s/step - loss: 2.3308 - MAE: 1.1612 - plcc_tf: 0.2873 - val_loss: 0.3387 - val_MAE: 0.5100 - val_plcc_tf: 0.8074\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 330s 2s/step - loss: 2.1469 - MAE: 1.0950 - plcc_tf: 0.2885 - val_loss: 0.2306 - val_MAE: 0.3908 - val_plcc_tf: 0.7433\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 354s 2s/step - loss: 1.9142 - MAE: 1.0391 - plcc_tf: 0.3080 - val_loss: 0.3224 - val_MAE: 0.4565 - val_plcc_tf: 0.7549\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 361s 2s/step - loss: 1.8214 - MAE: 0.9984 - plcc_tf: 0.3125 - val_loss: 0.1807 - val_MAE: 0.3537 - val_plcc_tf: 0.8302\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 316s 2s/step - loss: 1.6835 - MAE: 0.9613 - plcc_tf: 0.3261 - val_loss: 0.1897 - val_MAE: 0.3515 - val_plcc_tf: 0.8294\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 323s 2s/step - loss: 1.5261 - MAE: 0.9170 - plcc_tf: 0.3403 - val_loss: 0.1416 - val_MAE: 0.3010 - val_plcc_tf: 0.8157\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 386s 2s/step - loss: 1.4576 - MAE: 0.8942 - plcc_tf: 0.3448 - val_loss: 0.1223 - val_MAE: 0.2843 - val_plcc_tf: 0.8631\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 377s 2s/step - loss: 1.3674 - MAE: 0.8588 - plcc_tf: 0.3512 - val_loss: 0.1413 - val_MAE: 0.3080 - val_plcc_tf: 0.8621\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 373s 2s/step - loss: 1.2860 - MAE: 0.8326 - plcc_tf: 0.3649 - val_loss: 0.1091 - val_MAE: 0.2622 - val_plcc_tf: 0.8693\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 364s 2s/step - loss: 1.1985 - MAE: 0.8019 - plcc_tf: 0.3801 - val_loss: 0.1371 - val_MAE: 0.2949 - val_plcc_tf: 0.8627\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 416s 2s/step - loss: 1.1452 - MAE: 0.7813 - plcc_tf: 0.3954 - val_loss: 0.1061 - val_MAE: 0.2610 - val_plcc_tf: 0.8648\n",
      "Model weights loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET3_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5\n",
      "Training model: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET3_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n",
      "Epoch 1/20\n",
      "170/170 [==============================] - 324s 2s/step - loss: 1.2247 - MAE: 0.8130 - plcc_tf: 0.3783 - val_loss: 0.1047 - val_MAE: 0.2617 - val_plcc_tf: 0.8778\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 240s 1s/step - loss: 1.1837 - MAE: 0.7974 - plcc_tf: 0.3889 - val_loss: 0.1027 - val_MAE: 0.2564 - val_plcc_tf: 0.8768\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 213s 1s/step - loss: 1.2054 - MAE: 0.8000 - plcc_tf: 0.3877 - val_loss: 0.0893 - val_MAE: 0.2378 - val_plcc_tf: 0.8852\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 172s 1s/step - loss: 1.2114 - MAE: 0.7982 - plcc_tf: 0.3869 - val_loss: 0.0825 - val_MAE: 0.2293 - val_plcc_tf: 0.8927\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 246s 1s/step - loss: 1.1846 - MAE: 0.7909 - plcc_tf: 0.3862 - val_loss: 0.0833 - val_MAE: 0.2298 - val_plcc_tf: 0.8896\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 192s 1s/step - loss: 1.1264 - MAE: 0.7799 - plcc_tf: 0.3974 - val_loss: 0.0823 - val_MAE: 0.2284 - val_plcc_tf: 0.8903\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 245s 1s/step - loss: 1.1188 - MAE: 0.7724 - plcc_tf: 0.3975 - val_loss: 0.0823 - val_MAE: 0.2271 - val_plcc_tf: 0.8874\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 224s 1s/step - loss: 1.1504 - MAE: 0.7780 - plcc_tf: 0.3966 - val_loss: 0.0695 - val_MAE: 0.2079 - val_plcc_tf: 0.8962\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 200s 1s/step - loss: 1.1239 - MAE: 0.7678 - plcc_tf: 0.4045 - val_loss: 0.0727 - val_MAE: 0.2121 - val_plcc_tf: 0.8936\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 184s 1s/step - loss: 1.0805 - MAE: 0.7602 - plcc_tf: 0.4077 - val_loss: 0.0718 - val_MAE: 0.2107 - val_plcc_tf: 0.8970\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 206s 1s/step - loss: 1.0900 - MAE: 0.7565 - plcc_tf: 0.4166 - val_loss: 0.0761 - val_MAE: 0.2170 - val_plcc_tf: 0.8930\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 201s 1s/step - loss: 1.1001 - MAE: 0.7567 - plcc_tf: 0.4016 - val_loss: 0.0755 - val_MAE: 0.2160 - val_plcc_tf: 0.8868\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 219s 1s/step - loss: 1.0488 - MAE: 0.7486 - plcc_tf: 0.4090 - val_loss: 0.0698 - val_MAE: 0.2077 - val_plcc_tf: 0.8987\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 203s 1s/step - loss: 1.0067 - MAE: 0.7339 - plcc_tf: 0.4233 - val_loss: 0.0672 - val_MAE: 0.2038 - val_plcc_tf: 0.9006\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 206s 1s/step - loss: 1.0484 - MAE: 0.7421 - plcc_tf: 0.4184 - val_loss: 0.0694 - val_MAE: 0.2073 - val_plcc_tf: 0.8977\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 206s 1s/step - loss: 1.0176 - MAE: 0.7381 - plcc_tf: 0.4223 - val_loss: 0.0658 - val_MAE: 0.2013 - val_plcc_tf: 0.8983\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 232s 1s/step - loss: 1.0171 - MAE: 0.7292 - plcc_tf: 0.4245 - val_loss: 0.0625 - val_MAE: 0.1947 - val_plcc_tf: 0.9027\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 249s 1s/step - loss: 0.9866 - MAE: 0.7258 - plcc_tf: 0.4261 - val_loss: 0.0649 - val_MAE: 0.1983 - val_plcc_tf: 0.8988\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 232s 1s/step - loss: 1.0039 - MAE: 0.7281 - plcc_tf: 0.4256 - val_loss: 0.0713 - val_MAE: 0.2076 - val_plcc_tf: 0.9001\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 250s 1s/step - loss: 0.9973 - MAE: 0.7245 - plcc_tf: 0.4275 - val_loss: 0.0632 - val_MAE: 0.1966 - val_plcc_tf: 0.9021\n",
      "Model weights loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET3_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5\n",
      "Training model: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET3_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n",
      "Epoch 1/20\n",
      "170/170 [==============================] - 245s 1s/step - loss: 0.9896 - MAE: 0.7239 - plcc_tf: 0.4205 - val_loss: 0.0625 - val_MAE: 0.1949 - val_plcc_tf: 0.9047\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 265s 2s/step - loss: 0.9925 - MAE: 0.7266 - plcc_tf: 0.4317 - val_loss: 0.0630 - val_MAE: 0.1957 - val_plcc_tf: 0.9049\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 303s 2s/step - loss: 0.9864 - MAE: 0.7237 - plcc_tf: 0.4354 - val_loss: 0.0633 - val_MAE: 0.1962 - val_plcc_tf: 0.9054\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 270s 2s/step - loss: 1.0050 - MAE: 0.7262 - plcc_tf: 0.4239 - val_loss: 0.0626 - val_MAE: 0.1951 - val_plcc_tf: 0.9061\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 237s 1s/step - loss: 1.0094 - MAE: 0.7330 - plcc_tf: 0.4201 - val_loss: 0.0623 - val_MAE: 0.1947 - val_plcc_tf: 0.9066\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 238s 1s/step - loss: 1.0067 - MAE: 0.7247 - plcc_tf: 0.4209 - val_loss: 0.0623 - val_MAE: 0.1948 - val_plcc_tf: 0.9063\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 228s 1s/step - loss: 0.9905 - MAE: 0.7252 - plcc_tf: 0.4303 - val_loss: 0.0617 - val_MAE: 0.1937 - val_plcc_tf: 0.9067\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 215s 1s/step - loss: 0.9749 - MAE: 0.7203 - plcc_tf: 0.4294 - val_loss: 0.0623 - val_MAE: 0.1948 - val_plcc_tf: 0.9071\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 221s 1s/step - loss: 0.9946 - MAE: 0.7217 - plcc_tf: 0.4288 - val_loss: 0.0621 - val_MAE: 0.1947 - val_plcc_tf: 0.9063\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 261s 2s/step - loss: 0.9818 - MAE: 0.7217 - plcc_tf: 0.4328 - val_loss: 0.0618 - val_MAE: 0.1941 - val_plcc_tf: 0.9070\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 255s 2s/step - loss: 0.9683 - MAE: 0.7173 - plcc_tf: 0.4380 - val_loss: 0.0615 - val_MAE: 0.1935 - val_plcc_tf: 0.9069\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 209s 1s/step - loss: 1.0011 - MAE: 0.7194 - plcc_tf: 0.4267 - val_loss: 0.0608 - val_MAE: 0.1923 - val_plcc_tf: 0.9076\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 234s 1s/step - loss: 0.9821 - MAE: 0.7200 - plcc_tf: 0.4297 - val_loss: 0.0620 - val_MAE: 0.1946 - val_plcc_tf: 0.9074\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 205s 1s/step - loss: 0.9731 - MAE: 0.7190 - plcc_tf: 0.4353 - val_loss: 0.0607 - val_MAE: 0.1922 - val_plcc_tf: 0.9078\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 245s 1s/step - loss: 0.9832 - MAE: 0.7199 - plcc_tf: 0.4345 - val_loss: 0.0608 - val_MAE: 0.1925 - val_plcc_tf: 0.9080\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 242s 1s/step - loss: 0.9675 - MAE: 0.7117 - plcc_tf: 0.4285 - val_loss: 0.0608 - val_MAE: 0.1924 - val_plcc_tf: 0.9082\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 244s 1s/step - loss: 1.0015 - MAE: 0.7283 - plcc_tf: 0.4327 - val_loss: 0.0610 - val_MAE: 0.1926 - val_plcc_tf: 0.9076\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 267s 2s/step - loss: 0.9588 - MAE: 0.7110 - plcc_tf: 0.4380 - val_loss: 0.0612 - val_MAE: 0.1930 - val_plcc_tf: 0.9080\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 301s 2s/step - loss: 0.9534 - MAE: 0.7115 - plcc_tf: 0.4342 - val_loss: 0.0622 - val_MAE: 0.1950 - val_plcc_tf: 0.9082\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 220s 1s/step - loss: 0.9779 - MAE: 0.7163 - plcc_tf: 0.4361 - val_loss: 0.0611 - val_MAE: 0.1930 - val_plcc_tf: 0.9083\n"
     ]
    }
   ],
   "source": [
    "for lr in [1e-4,1e-5,1e-6]:\n",
    "    helper.load_model()\n",
    "    helper.train(lr=lr, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training\n",
      "Model weights loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_GET3_official_datase fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5\n",
      "Validating performance\n",
      "36/36 - 155s - loss: 0.0578 - MAE: 0.1886 - plcc_tf: 0.9144 - 155s/epoch - 4s/step\n",
      "MAE:     0.18862153589725494\n",
      "loss:    0.057820480316877365\n",
      "plcc_tf: 0.9144100546836853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.057820480316877365,\n",
       " 'MAE': 0.18862153589725494,\n",
       " 'plcc_tf': 0.9144100546836853}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('After training')\n",
    "\n",
    "helper.load_model()\n",
    "test_gen = helper.make_generator(ids[ids.set=='test'])\n",
    "helper.validate(test_gen, verbose=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All User Files training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID for PARA Dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionId</th>\n",
       "      <th>imageName</th>\n",
       "      <th>aestheticScore</th>\n",
       "      <th>qualityScore</th>\n",
       "      <th>sessionId_imageName</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>session328</td>\n",
       "      <td>iaa_pub22893_.jpg</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>2.084000</td>\n",
       "      <td>session328_iaa_pub22893_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>session232</td>\n",
       "      <td>iaa_pub16180_.jpg</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>session232_iaa_pub16180_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>session125</td>\n",
       "      <td>iaa_pub8721_.jpg</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>3.052000</td>\n",
       "      <td>session125_iaa_pub8721_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>session139</td>\n",
       "      <td>iaa_pub9725_.jpg</td>\n",
       "      <td>3.120000</td>\n",
       "      <td>3.356000</td>\n",
       "      <td>session139_iaa_pub9725_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>session79</td>\n",
       "      <td>iaa_pub5474_.jpg</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>3.932000</td>\n",
       "      <td>session79_iaa_pub5474_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31215</th>\n",
       "      <td>session7</td>\n",
       "      <td>iaa_pub484_.jpg</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>3.664000</td>\n",
       "      <td>session7_iaa_pub484_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31216</th>\n",
       "      <td>session68</td>\n",
       "      <td>iaa_pub4700_.jpg</td>\n",
       "      <td>2.640000</td>\n",
       "      <td>2.984000</td>\n",
       "      <td>session68_iaa_pub4700_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31217</th>\n",
       "      <td>session20</td>\n",
       "      <td>iaa_pub1377_.jpg</td>\n",
       "      <td>3.340000</td>\n",
       "      <td>3.428000</td>\n",
       "      <td>session20_iaa_pub1377_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31218</th>\n",
       "      <td>session64</td>\n",
       "      <td>iaa_pub4477_.jpg</td>\n",
       "      <td>3.464286</td>\n",
       "      <td>3.607143</td>\n",
       "      <td>session64_iaa_pub4477_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31219</th>\n",
       "      <td>session414</td>\n",
       "      <td>iaa_pub28925_.jpg</td>\n",
       "      <td>3.270833</td>\n",
       "      <td>3.495833</td>\n",
       "      <td>session414_iaa_pub28925_.jpg</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31220 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sessionId          imageName  aestheticScore  qualityScore  \\\n",
       "0      session328  iaa_pub22893_.jpg        1.980000      2.084000   \n",
       "1      session232  iaa_pub16180_.jpg        3.720000      3.840000   \n",
       "2      session125   iaa_pub8721_.jpg        2.900000      3.052000   \n",
       "3      session139   iaa_pub9725_.jpg        3.120000      3.356000   \n",
       "4       session79   iaa_pub5474_.jpg        3.840000      3.932000   \n",
       "...           ...                ...             ...           ...   \n",
       "31215    session7    iaa_pub484_.jpg        3.540000      3.664000   \n",
       "31216   session68   iaa_pub4700_.jpg        2.640000      2.984000   \n",
       "31217   session20   iaa_pub1377_.jpg        3.340000      3.428000   \n",
       "31218   session64   iaa_pub4477_.jpg        3.464286      3.607143   \n",
       "31219  session414  iaa_pub28925_.jpg        3.270833      3.495833   \n",
       "\n",
       "                sessionId_imageName         set  \n",
       "0      session328_iaa_pub22893_.jpg    training  \n",
       "1      session232_iaa_pub16180_.jpg    training  \n",
       "2       session125_iaa_pub8721_.jpg    training  \n",
       "3       session139_iaa_pub9725_.jpg    training  \n",
       "4        session79_iaa_pub5474_.jpg    training  \n",
       "...                             ...         ...  \n",
       "31215      session7_iaa_pub484_.jpg  validation  \n",
       "31216    session68_iaa_pub4700_.jpg  validation  \n",
       "31217    session20_iaa_pub1377_.jpg  validation  \n",
       "31218    session64_iaa_pub4477_.jpg  validation  \n",
       "31219  session414_iaa_pub28925_.jpg  validation  \n",
       "\n",
       "[31220 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "root_path = '/media/workstation/0832621B32620DCE/Ian/'\n",
    "dataset = root_path + 'mtaiq/PARA_MTAIQ_All_User_official_dataset.csv'\n",
    "ids = pd.read_csv(dataset)\n",
    "\n",
    "print('ID for PARA Dataset')\n",
    "ids\n",
    "\n",
    "# input_shape = (None, None, 3)\n",
    "# features_root = root_path + 'features_get3/'\n",
    "# images_path = '/media/workstation/0832621B32620DCE/PARA_Dataset/PARA'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on MLSP Wide Features (aestheticScore only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_All_User_official_da fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 02:51:25.307787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 02:51:25.502751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 02:51:25.502924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 02:51:25.503405: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-05 02:51:25.503670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 02:51:25.503801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 02:51:25.503914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 02:51:26.016642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 02:51:26.016835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 02:51:26.017033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 02:51:26.017162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9963 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# features_file = root_path + 'features/irnv2_mlsp_wide_orig/i1[orig]_lfinal_o1[5,5,16928]_r1.h5'\n",
    "features_file = root_path + 'features_all_user_baseline_aestheticsScore/irnv2_mlsp_wide_orig/grp:1 i:1[orig] lay:final o:1[5,5,16928].h5'\n",
    "\n",
    "fc1_size = 2048\n",
    "image_size = '[orig]'\n",
    "input_size = (5,5,16928)\n",
    "model_name = features_file.split('/')[-2]\n",
    "\n",
    "# loss         = dict(head_aesthetic_out = 'MSE', head_quality_out = 'MSE')\n",
    "# loss_weights = dict(head_aesthetic_out = 1.0,   head_quality_out = 1.0)\n",
    "# metrics      = dict(head_aesthetic_out = ['MAE', ops.plcc_tf], head_quality_out = ['MAE', ops.plcc_tf])\n",
    "\n",
    "loss         = dict(head_aesthetic_out = 'MSE')\n",
    "loss_weights = dict(head_aesthetic_out = 1.0)\n",
    "metrics      = dict(head_aesthetic_out = ['MAE', ops.plcc_tf])\n",
    "\n",
    "bn = 2\n",
    "fc_sizes = [fc1_size, fc1_size/2, fc1_size/8,  1]\n",
    "dropout_rates = [0.25, 0.25, 0.5, 0]\n",
    "\n",
    "# monitor_metric = 'val_plcc_tf'; \n",
    "monitor_mode = 'max'\n",
    "monitor_metric = 'val_plcc_tf'\n",
    "outputs = ['aestheticScore']\n",
    "\n",
    "# MODEL DEF\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "input_feats = Input(shape=input_size, dtype='float32')\n",
    "\n",
    "# SINGLE-block\n",
    "x = apps.inception_block(input_feats, size=1024)\n",
    "x = GlobalAveragePooling2D(name='final_GAP')(x)\n",
    "\n",
    "pred_aesthetic = apps.fc_layers(x, name       = 'head_aesthetic',\n",
    "                                fc_sizes      = fc_sizes,\n",
    "                                dropout_rates = dropout_rates,\n",
    "                                batch_norm    = bn)\n",
    "\n",
    "# pred_quality = apps.fc_layers(x, name       = 'head_quality',\n",
    "#                               fc_sizes      = fc_sizes,\n",
    "#                               dropout_rates = dropout_rates,\n",
    "#                               batch_norm    = bn)                 \n",
    "\n",
    "model = Model(inputs=input_feats, outputs=pred_aesthetic) #\n",
    "\n",
    "gen_params = dict(batch_size    = 128,\n",
    "                  data_path     = features_file,                  \n",
    "                  input_shape   = input_size,\n",
    "                  inputs        = ['sessionId_imageName'],\n",
    "                  outputs       = outputs, \n",
    "                  random_group  = False,\n",
    "                  fixed_batches = True)\n",
    "\n",
    "helper = mh.ModelHelper(model, model_name, ids, \n",
    "                     max_queue_size = 128,\n",
    "                     loss           = loss,\n",
    "                     metrics        = metrics,\n",
    "                     monitor_metric = monitor_metric, \n",
    "                     monitor_mode   = monitor_mode,\n",
    "                     multiproc      = False, workers = 1,\n",
    "#                      multiproc      = True, workers = 3,\n",
    "                     early_stop_patience = 5,\n",
    "                     logs_root      = root_path + 'logs_all_user_aestheticScore_baseline',\n",
    "                     models_root    = root_path + 'models_all_user_aestheticScore_baseline',\n",
    "                     gen_params     = gen_params)\n",
    "\n",
    "helper.model_name.update(fc1 = '[%d]' % fc1_size,\n",
    "                         im  = image_size,\n",
    "                         bn  = bn,\n",
    "                         do  = str(dropout_rates).replace(' ',''),\n",
    "                         mon = '[%s]' % monitor_metric,\n",
    "                         ds  = '[%s]' % os.path.split(dataset)[1])\n",
    "\n",
    "print(helper.model_name())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on MLSP Wide Features (qualityScore only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 09:04:21.064882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 09:04:21.808639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 09:04:21.808829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 09:04:21.809336: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-05 09:04:21.818815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 09:04:21.819052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 09:04:21.819185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 09:04:28.758181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 09:04:28.758357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 09:04:28.758483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-05 09:04:28.758607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9984 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_All_User_official_da fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n"
     ]
    }
   ],
   "source": [
    "# features_file = root_path + 'features/irnv2_mlsp_wide_orig/i1[orig]_lfinal_o1[5,5,16928]_r1.h5'\n",
    "features_file = root_path + 'features_all_user_baseline_qualityScore/irnv2_mlsp_wide_orig/grp:1 i:1[orig] lay:final o:1[5,5,16928].h5'\n",
    "\n",
    "fc1_size = 2048\n",
    "image_size = '[orig]'\n",
    "input_size = (5,5,16928)\n",
    "model_name = features_file.split('/')[-2]\n",
    "\n",
    "# loss         = dict(head_aesthetic_out = 'MSE', head_quality_out = 'MSE')\n",
    "# loss_weights = dict(head_aesthetic_out = 1.0,   head_quality_out = 1.0)\n",
    "# metrics      = dict(head_aesthetic_out = ['MAE', ops.plcc_tf], head_quality_out = ['MAE', ops.plcc_tf])\n",
    "\n",
    "loss         = dict(head_quality_out = 'MSE')\n",
    "loss_weights = dict(head_quality_out = 1.0)\n",
    "metrics      = dict(head_quality_out = ['MAE', ops.plcc_tf])\n",
    "\n",
    "bn = 2\n",
    "fc_sizes = [fc1_size, fc1_size/2, fc1_size/8,  1]\n",
    "dropout_rates = [0.25, 0.25, 0.5, 0]\n",
    "\n",
    "monitor_mode = 'max'\n",
    "monitor_metric = 'val_plcc_tf'\n",
    "outputs = ['qualityScore']\n",
    "\n",
    "# MODEL DEF\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "input_feats = Input(shape=input_size, dtype='float32')\n",
    "\n",
    "# SINGLE-block\n",
    "x = apps.inception_block(input_feats, size=1024)\n",
    "x = GlobalAveragePooling2D(name='final_GAP')(x)\n",
    "\n",
    "# pred_aesthetic = apps.fc_layers(x, name       = 'head_aesthetic',\n",
    "#                                 fc_sizes      = fc_sizes,\n",
    "#                                 dropout_rates = dropout_rates,\n",
    "#                                 batch_norm    = bn)\n",
    "\n",
    "pred_quality = apps.fc_layers(x, name       = 'head_quality',\n",
    "                              fc_sizes      = fc_sizes,\n",
    "                              dropout_rates = dropout_rates,\n",
    "                              batch_norm    = bn)                 \n",
    "\n",
    "model = Model(inputs=input_feats, outputs=pred_quality) #\n",
    "\n",
    "gen_params = dict(batch_size    = 128,\n",
    "                  data_path     = features_file,                  \n",
    "                  input_shape   = input_size,\n",
    "                  inputs        = ['sessionId_imageName'],\n",
    "                  outputs       = outputs, \n",
    "                  random_group  = False,\n",
    "                  fixed_batches = True)\n",
    "\n",
    "helper = mh.ModelHelper(model, model_name, ids, \n",
    "                     max_queue_size = 128,\n",
    "                     loss           = loss,\n",
    "                     metrics        = metrics,\n",
    "                     monitor_metric = monitor_metric, \n",
    "                     monitor_mode   = monitor_mode,\n",
    "                     multiproc      = False, workers = 1,\n",
    "#                      multiproc      = True, workers = 3,\n",
    "                     early_stop_patience = 5,\n",
    "                     logs_root      = root_path + 'logs_all_user_qualityScore_baseline',\n",
    "                     models_root    = root_path + 'models_all_user_qualityScore_baseline',\n",
    "                     gen_params     = gen_params)\n",
    "\n",
    "helper.model_name.update(fc1 = '[%d]' % fc1_size,\n",
    "                         im  = image_size,\n",
    "                         bn  = bn,\n",
    "                         do  = str(dropout_rates).replace(' ',''),\n",
    "                         mon = '[%s]' % monitor_metric,\n",
    "                         ds  = '[%s]' % os.path.split(dataset)[1])\n",
    "\n",
    "print(helper.model_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NOT loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_All_User_official_da fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5 does not exist\n",
      "Training model: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_All_User_official_da fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 09:05:24.743915: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n",
      "2023-02-05 09:05:31.706430: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 787s 4s/step - loss: 12.9360 - MAE: 3.2269 - plcc_tf: 0.2275 - val_loss: 9.4967 - val_MAE: 3.0506 - val_plcc_tf: 0.6079\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 693s 4s/step - loss: 10.4674 - MAE: 2.9163 - plcc_tf: 0.2625 - val_loss: 7.3148 - val_MAE: 2.6711 - val_plcc_tf: 0.6793\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 423s 2s/step - loss: 8.6932 - MAE: 2.6306 - plcc_tf: 0.2673 - val_loss: 6.1956 - val_MAE: 2.4498 - val_plcc_tf: 0.7354\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 301s 2s/step - loss: 7.2067 - MAE: 2.3610 - plcc_tf: 0.2781 - val_loss: 4.6191 - val_MAE: 2.1074 - val_plcc_tf: 0.7278\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 318s 2s/step - loss: 5.8305 - MAE: 2.0791 - plcc_tf: 0.2787 - val_loss: 3.6450 - val_MAE: 1.8607 - val_plcc_tf: 0.7294\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 425s 3s/step - loss: 4.7073 - MAE: 1.8131 - plcc_tf: 0.2652 - val_loss: 2.5417 - val_MAE: 1.5481 - val_plcc_tf: 0.7913\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 437s 3s/step - loss: 3.7762 - MAE: 1.5789 - plcc_tf: 0.2665 - val_loss: 1.4412 - val_MAE: 1.1492 - val_plcc_tf: 0.7951\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 380s 2s/step - loss: 3.0229 - MAE: 1.3808 - plcc_tf: 0.2793 - val_loss: 0.9913 - val_MAE: 0.9093 - val_plcc_tf: 0.7641\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 382s 2s/step - loss: 2.6377 - MAE: 1.2691 - plcc_tf: 0.2788 - val_loss: 0.5295 - val_MAE: 0.6459 - val_plcc_tf: 0.7725\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 476s 3s/step - loss: 2.3511 - MAE: 1.1825 - plcc_tf: 0.2800 - val_loss: 0.4020 - val_MAE: 0.5441 - val_plcc_tf: 0.8153\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 400s 2s/step - loss: 2.1013 - MAE: 1.1098 - plcc_tf: 0.2952 - val_loss: 0.3340 - val_MAE: 0.4714 - val_plcc_tf: 0.8020\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 427s 3s/step - loss: 1.9219 - MAE: 1.0554 - plcc_tf: 0.2970 - val_loss: 0.2458 - val_MAE: 0.4179 - val_plcc_tf: 0.8411\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 474s 3s/step - loss: 1.7746 - MAE: 1.0090 - plcc_tf: 0.3111 - val_loss: 0.1896 - val_MAE: 0.3545 - val_plcc_tf: 0.8309\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 433s 3s/step - loss: 1.7033 - MAE: 0.9929 - plcc_tf: 0.3111 - val_loss: 0.1806 - val_MAE: 0.3539 - val_plcc_tf: 0.8488\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 515s 3s/step - loss: 1.5460 - MAE: 0.9448 - plcc_tf: 0.3267 - val_loss: 0.1700 - val_MAE: 0.3372 - val_plcc_tf: 0.8372\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 410s 2s/step - loss: 1.4388 - MAE: 0.9122 - plcc_tf: 0.3468 - val_loss: 0.1684 - val_MAE: 0.3447 - val_plcc_tf: 0.8640\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 416s 2s/step - loss: 1.3359 - MAE: 0.8776 - plcc_tf: 0.3588 - val_loss: 0.1495 - val_MAE: 0.3213 - val_plcc_tf: 0.8528\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 389s 2s/step - loss: 1.2510 - MAE: 0.8497 - plcc_tf: 0.3742 - val_loss: 0.1180 - val_MAE: 0.2782 - val_plcc_tf: 0.8665\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 366s 2s/step - loss: 1.1744 - MAE: 0.8238 - plcc_tf: 0.3781 - val_loss: 0.1297 - val_MAE: 0.2873 - val_plcc_tf: 0.8818\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 385s 2s/step - loss: 1.1106 - MAE: 0.7945 - plcc_tf: 0.3951 - val_loss: 0.1166 - val_MAE: 0.2728 - val_plcc_tf: 0.8709\n",
      "Model weights loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_All_User_official_da fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5\n",
      "Training model: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_All_User_official_da fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n",
      "Epoch 1/20\n",
      "170/170 [==============================] - 445s 3s/step - loss: 1.1250 - MAE: 0.7986 - plcc_tf: 0.3988 - val_loss: 0.0953 - val_MAE: 0.2485 - val_plcc_tf: 0.8917\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 459s 3s/step - loss: 1.0980 - MAE: 0.7906 - plcc_tf: 0.4039 - val_loss: 0.0997 - val_MAE: 0.2525 - val_plcc_tf: 0.8926\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 396s 2s/step - loss: 1.0884 - MAE: 0.7888 - plcc_tf: 0.3934 - val_loss: 0.0955 - val_MAE: 0.2488 - val_plcc_tf: 0.8977\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 453s 3s/step - loss: 1.0798 - MAE: 0.7860 - plcc_tf: 0.3982 - val_loss: 0.0874 - val_MAE: 0.2353 - val_plcc_tf: 0.8973\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 416s 2s/step - loss: 1.0481 - MAE: 0.7707 - plcc_tf: 0.4145 - val_loss: 0.0853 - val_MAE: 0.2332 - val_plcc_tf: 0.8991\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 356s 2s/step - loss: 1.0335 - MAE: 0.7644 - plcc_tf: 0.4031 - val_loss: 0.0861 - val_MAE: 0.2305 - val_plcc_tf: 0.8985\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 356s 2s/step - loss: 1.0326 - MAE: 0.7655 - plcc_tf: 0.4139 - val_loss: 0.0788 - val_MAE: 0.2248 - val_plcc_tf: 0.9025\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 415s 2s/step - loss: 1.0131 - MAE: 0.7574 - plcc_tf: 0.4164 - val_loss: 0.0765 - val_MAE: 0.2212 - val_plcc_tf: 0.9043\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 381s 2s/step - loss: 0.9948 - MAE: 0.7523 - plcc_tf: 0.4177 - val_loss: 0.0833 - val_MAE: 0.2298 - val_plcc_tf: 0.9021\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 367s 2s/step - loss: 0.9848 - MAE: 0.7459 - plcc_tf: 0.4253 - val_loss: 0.0763 - val_MAE: 0.2190 - val_plcc_tf: 0.9021\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 342s 2s/step - loss: 0.9783 - MAE: 0.7426 - plcc_tf: 0.4155 - val_loss: 0.0746 - val_MAE: 0.2181 - val_plcc_tf: 0.9073\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 340s 2s/step - loss: 0.9651 - MAE: 0.7400 - plcc_tf: 0.4268 - val_loss: 0.0727 - val_MAE: 0.2138 - val_plcc_tf: 0.9039\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 343s 2s/step - loss: 0.9361 - MAE: 0.7309 - plcc_tf: 0.4336 - val_loss: 0.0710 - val_MAE: 0.2113 - val_plcc_tf: 0.9071\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 370s 2s/step - loss: 0.9349 - MAE: 0.7278 - plcc_tf: 0.4320 - val_loss: 0.0733 - val_MAE: 0.2148 - val_plcc_tf: 0.9079\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 339s 2s/step - loss: 0.9286 - MAE: 0.7271 - plcc_tf: 0.4322 - val_loss: 0.0728 - val_MAE: 0.2147 - val_plcc_tf: 0.9095\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 383s 2s/step - loss: 0.9441 - MAE: 0.7242 - plcc_tf: 0.4292 - val_loss: 0.0729 - val_MAE: 0.2127 - val_plcc_tf: 0.9048\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 353s 2s/step - loss: 0.8962 - MAE: 0.7110 - plcc_tf: 0.4419 - val_loss: 0.0743 - val_MAE: 0.2158 - val_plcc_tf: 0.9074\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 398s 2s/step - loss: 0.9069 - MAE: 0.7167 - plcc_tf: 0.4391 - val_loss: 0.0710 - val_MAE: 0.2114 - val_plcc_tf: 0.9091\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 331s 2s/step - loss: 0.8846 - MAE: 0.7085 - plcc_tf: 0.4443 - val_loss: 0.0655 - val_MAE: 0.2039 - val_plcc_tf: 0.9107\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 398s 2s/step - loss: 0.8767 - MAE: 0.7065 - plcc_tf: 0.4407 - val_loss: 0.0684 - val_MAE: 0.2075 - val_plcc_tf: 0.9071\n",
      "Model weights loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_All_User_official_da fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5\n",
      "Training model: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_All_User_official_da fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]\n",
      "Epoch 1/20\n",
      "170/170 [==============================] - 443s 3s/step - loss: 0.8700 - MAE: 0.7034 - plcc_tf: 0.4372 - val_loss: 0.0657 - val_MAE: 0.2036 - val_plcc_tf: 0.9119\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 439s 3s/step - loss: 0.8817 - MAE: 0.7046 - plcc_tf: 0.4392 - val_loss: 0.0664 - val_MAE: 0.2045 - val_plcc_tf: 0.9119\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 460s 3s/step - loss: 0.8809 - MAE: 0.7036 - plcc_tf: 0.4443 - val_loss: 0.0669 - val_MAE: 0.2045 - val_plcc_tf: 0.9112\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 478s 3s/step - loss: 0.8837 - MAE: 0.7074 - plcc_tf: 0.4439 - val_loss: 0.0655 - val_MAE: 0.2025 - val_plcc_tf: 0.9119\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 469s 3s/step - loss: 0.8736 - MAE: 0.7046 - plcc_tf: 0.4439 - val_loss: 0.0660 - val_MAE: 0.2025 - val_plcc_tf: 0.9111\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 439s 3s/step - loss: 0.8688 - MAE: 0.7042 - plcc_tf: 0.4481 - val_loss: 0.0669 - val_MAE: 0.2040 - val_plcc_tf: 0.9113\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 461s 3s/step - loss: 0.8740 - MAE: 0.6996 - plcc_tf: 0.4548 - val_loss: 0.0657 - val_MAE: 0.2031 - val_plcc_tf: 0.9127\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 525s 3s/step - loss: 0.8971 - MAE: 0.7078 - plcc_tf: 0.4349 - val_loss: 0.0661 - val_MAE: 0.2036 - val_plcc_tf: 0.9130\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 436s 3s/step - loss: 0.8640 - MAE: 0.6988 - plcc_tf: 0.4421 - val_loss: 0.0649 - val_MAE: 0.2021 - val_plcc_tf: 0.9139\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 460s 3s/step - loss: 0.8755 - MAE: 0.7065 - plcc_tf: 0.4386 - val_loss: 0.0652 - val_MAE: 0.2024 - val_plcc_tf: 0.9137\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 462s 3s/step - loss: 0.8785 - MAE: 0.7055 - plcc_tf: 0.4382 - val_loss: 0.0649 - val_MAE: 0.2015 - val_plcc_tf: 0.9140\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 473s 3s/step - loss: 0.8477 - MAE: 0.6932 - plcc_tf: 0.4501 - val_loss: 0.0656 - val_MAE: 0.2023 - val_plcc_tf: 0.9141\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 445s 3s/step - loss: 0.8745 - MAE: 0.7007 - plcc_tf: 0.4462 - val_loss: 0.0660 - val_MAE: 0.2031 - val_plcc_tf: 0.9141\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 445s 3s/step - loss: 0.8673 - MAE: 0.7022 - plcc_tf: 0.4456 - val_loss: 0.0655 - val_MAE: 0.2023 - val_plcc_tf: 0.9141\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 385s 2s/step - loss: 0.8554 - MAE: 0.6951 - plcc_tf: 0.4567 - val_loss: 0.0652 - val_MAE: 0.2018 - val_plcc_tf: 0.9144\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 374s 2s/step - loss: 0.8454 - MAE: 0.6919 - plcc_tf: 0.4550 - val_loss: 0.0658 - val_MAE: 0.2034 - val_plcc_tf: 0.9146\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 390s 2s/step - loss: 0.8708 - MAE: 0.6993 - plcc_tf: 0.4504 - val_loss: 0.0655 - val_MAE: 0.2032 - val_plcc_tf: 0.9152\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 449s 3s/step - loss: 0.8434 - MAE: 0.6925 - plcc_tf: 0.4542 - val_loss: 0.0648 - val_MAE: 0.2019 - val_plcc_tf: 0.9153\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 389s 2s/step - loss: 0.8650 - MAE: 0.6976 - plcc_tf: 0.4514 - val_loss: 0.0648 - val_MAE: 0.2024 - val_plcc_tf: 0.9154\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 461s 3s/step - loss: 0.8641 - MAE: 0.6995 - plcc_tf: 0.4527 - val_loss: 0.0642 - val_MAE: 0.2011 - val_plcc_tf: 0.9157\n"
     ]
    }
   ],
   "source": [
    "for lr in [1e-4,1e-5,1e-6]:\n",
    "    helper.load_model()\n",
    "    helper.train(lr=lr, epochs=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training\n",
      "Model weights loaded: irnv2_mlsp_wide_orig/bn:2 bsz:128 do:[0.25,0.25,0.5,0] ds:[PARA_MTAIQ_All_User_official_da fc1:[2048] i:1[5,5,16928] im:[orig] l:[MSE] mon:[val_plcc_tf] o:1[1]_best_weights.h5\n",
      "Validating performance\n",
      "36/36 - 149s - loss: 0.0632 - MAE: 0.1978 - plcc_tf: 0.9168 - 149s/epoch - 4s/step\n",
      "MAE:     0.1978052407503128\n",
      "loss:    0.06322509795427322\n",
      "plcc_tf: 0.9168059825897217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.06322509795427322,\n",
       " 'MAE': 0.1978052407503128,\n",
       " 'plcc_tf': 0.9168059825897217}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('After training')\n",
    "\n",
    "helper.load_model()\n",
    "test_gen = helper.make_generator(ids[ids.set=='test'])\n",
    "helper.validate(test_gen, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f336c55dc04d10e265d1690e1fac509afec4a033c9a262091c183b4c57cacd85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
