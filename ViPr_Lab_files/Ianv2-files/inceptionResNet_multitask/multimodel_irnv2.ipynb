{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wandb.keras import WandbMetricsLogger, WandbCallback\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras import backend as K\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading all multimodel datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>sem1</th>\n",
       "      <th>sem2</th>\n",
       "      <th>challegeID</th>\n",
       "      <th>sum_score</th>\n",
       "      <th>total_scorer</th>\n",
       "      <th>MOS</th>\n",
       "      <th>scaled_MOS_aesthetic</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>ava</td>\n",
       "      <td>953777.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>53</td>\n",
       "      <td>1396</td>\n",
       "      <td>844</td>\n",
       "      <td>128</td>\n",
       "      <td>6.593750</td>\n",
       "      <td>3.818291</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>ava</td>\n",
       "      <td>953550.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1396</td>\n",
       "      <td>877</td>\n",
       "      <td>130</td>\n",
       "      <td>6.746154</td>\n",
       "      <td>3.908059</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>ava</td>\n",
       "      <td>954187.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1396</td>\n",
       "      <td>654</td>\n",
       "      <td>122</td>\n",
       "      <td>5.360656</td>\n",
       "      <td>3.091981</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83</td>\n",
       "      <td>ava</td>\n",
       "      <td>953933.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>63</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>1396</td>\n",
       "      <td>666</td>\n",
       "      <td>129</td>\n",
       "      <td>5.162791</td>\n",
       "      <td>2.975436</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>ava</td>\n",
       "      <td>953979.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>1396</td>\n",
       "      <td>872</td>\n",
       "      <td>127</td>\n",
       "      <td>6.866142</td>\n",
       "      <td>3.978733</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24426</th>\n",
       "      <td>123348</td>\n",
       "      <td>ava</td>\n",
       "      <td>263513.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>89</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>413</td>\n",
       "      <td>1333</td>\n",
       "      <td>254</td>\n",
       "      <td>5.248031</td>\n",
       "      <td>3.025644</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24427</th>\n",
       "      <td>81633</td>\n",
       "      <td>ava</td>\n",
       "      <td>577031.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>721</td>\n",
       "      <td>828</td>\n",
       "      <td>145</td>\n",
       "      <td>5.710345</td>\n",
       "      <td>3.297953</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24428</th>\n",
       "      <td>59759</td>\n",
       "      <td>ava</td>\n",
       "      <td>874523.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>46</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>1202</td>\n",
       "      <td>1154</td>\n",
       "      <td>226</td>\n",
       "      <td>5.106195</td>\n",
       "      <td>2.942100</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24429</th>\n",
       "      <td>21933</td>\n",
       "      <td>ava</td>\n",
       "      <td>932076.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1331</td>\n",
       "      <td>935</td>\n",
       "      <td>184</td>\n",
       "      <td>5.081522</td>\n",
       "      <td>2.927567</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24430</th>\n",
       "      <td>104312</td>\n",
       "      <td>ava</td>\n",
       "      <td>570377.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>727</td>\n",
       "      <td>834</td>\n",
       "      <td>163</td>\n",
       "      <td>5.116564</td>\n",
       "      <td>2.948208</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24431 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Index dataset          ID  1   2   3   4   5   6   7  ...  9  10  \\\n",
       "0          12     ava  953777.jpg  0   3   2   3  13  40  35  ...  8   3   \n",
       "1          21     ava  953550.jpg  0   0   1   3  13  45  36  ...  5   7   \n",
       "2          28     ava  954187.jpg  0   0   3  21  46  38  10  ...  1   0   \n",
       "3          83     ava  953933.jpg  0   0   9  19  63  25   9  ...  1   1   \n",
       "4         108     ava  953979.jpg  0   0   0   3  21  34  30  ...  9  10   \n",
       "...       ...     ...         ... ..  ..  ..  ..  ..  ..  ..  ... ..  ..   \n",
       "24426  123348     ava  263513.jpg  0   6  11  54  89  51  28  ...  1   2   \n",
       "24427   81633     ava  577031.jpg  0   0   2  11  56  48  19  ...  3   1   \n",
       "24428   59759     ava  874523.jpg  3  15  22  37  61  46  23  ...  9   2   \n",
       "24429   21933     ava  932076.jpg  4   4  10  42  57  42  17  ...  3   1   \n",
       "24430  104312     ava  570377.jpg  1   3   7  29  73  35   8  ...  1   1   \n",
       "\n",
       "       sem1  sem2  challegeID  sum_score  total_scorer       MOS  \\\n",
       "0        20    53        1396        844           128  6.593750   \n",
       "1        14     0        1396        877           130  6.746154   \n",
       "2        38     0        1396        654           122  5.360656   \n",
       "3        15    19        1396        666           129  5.162791   \n",
       "4         2    40        1396        872           127  6.866142   \n",
       "...     ...   ...         ...        ...           ...       ...   \n",
       "24426    14    20         413       1333           254  5.248031   \n",
       "24427    14    21         721        828           145  5.710345   \n",
       "24428    18    41        1202       1154           226  5.106195   \n",
       "24429     1     2        1331        935           184  5.081522   \n",
       "24430    20    21         727        834           163  5.116564   \n",
       "\n",
       "       scaled_MOS_aesthetic       set  \n",
       "0                  3.818291  training  \n",
       "1                  3.908059  training  \n",
       "2                  3.091981  training  \n",
       "3                  2.975436  training  \n",
       "4                  3.978733  training  \n",
       "...                     ...       ...  \n",
       "24426              3.025644      test  \n",
       "24427              3.297953      test  \n",
       "24428              2.942100      test  \n",
       "24429              2.927567      test  \n",
       "24430              2.948208      test  \n",
       "\n",
       "[24431 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>imageName</th>\n",
       "      <th>scaled_MOS_aesthetic</th>\n",
       "      <th>qualityScore</th>\n",
       "      <th>sessionId_imageName</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>para</td>\n",
       "      <td>session254</td>\n",
       "      <td>iaa_pub17770_.jpg</td>\n",
       "      <td>1.431034</td>\n",
       "      <td>1.413793</td>\n",
       "      <td>session254_iaa_pub17770_.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>para</td>\n",
       "      <td>session241</td>\n",
       "      <td>iaa_pub16811_.jpg</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.995833</td>\n",
       "      <td>session241_iaa_pub16811_.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>para</td>\n",
       "      <td>session174</td>\n",
       "      <td>iaa_pub12164_.jpg</td>\n",
       "      <td>2.923077</td>\n",
       "      <td>3.046154</td>\n",
       "      <td>session174_iaa_pub12164_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>para</td>\n",
       "      <td>session276</td>\n",
       "      <td>iaa_pub19290_.jpg</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.752000</td>\n",
       "      <td>session276_iaa_pub19290_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>para</td>\n",
       "      <td>session272</td>\n",
       "      <td>iaa_pub19007_.jpg</td>\n",
       "      <td>3.440000</td>\n",
       "      <td>3.556000</td>\n",
       "      <td>session272_iaa_pub19007_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11166</th>\n",
       "      <td>para</td>\n",
       "      <td>session403</td>\n",
       "      <td>iaa_pub28170_.jpg</td>\n",
       "      <td>3.060000</td>\n",
       "      <td>3.340000</td>\n",
       "      <td>session403_iaa_pub28170_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11167</th>\n",
       "      <td>para</td>\n",
       "      <td>session21</td>\n",
       "      <td>iaa_pub1456_.jpg</td>\n",
       "      <td>2.940000</td>\n",
       "      <td>3.232000</td>\n",
       "      <td>session21_iaa_pub1456_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11168</th>\n",
       "      <td>para</td>\n",
       "      <td>session425</td>\n",
       "      <td>iaa_pub29739_.jpg</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>2.944000</td>\n",
       "      <td>session425_iaa_pub29739_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11169</th>\n",
       "      <td>para</td>\n",
       "      <td>session90</td>\n",
       "      <td>iaa_pub6243_.jpg</td>\n",
       "      <td>3.260000</td>\n",
       "      <td>3.408000</td>\n",
       "      <td>session90_iaa_pub6243_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11170</th>\n",
       "      <td>para</td>\n",
       "      <td>session395</td>\n",
       "      <td>iaa_pub27597_.jpg</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>3.908000</td>\n",
       "      <td>session395_iaa_pub27597_.jpg</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11171 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset   sessionId          imageName  scaled_MOS_aesthetic  \\\n",
       "0        para  session254  iaa_pub17770_.jpg              1.431034   \n",
       "1        para  session241  iaa_pub16811_.jpg              3.833333   \n",
       "2        para  session174  iaa_pub12164_.jpg              2.923077   \n",
       "3        para  session276  iaa_pub19290_.jpg              3.680000   \n",
       "4        para  session272  iaa_pub19007_.jpg              3.440000   \n",
       "...       ...         ...                ...                   ...   \n",
       "11166    para  session403  iaa_pub28170_.jpg              3.060000   \n",
       "11167    para   session21   iaa_pub1456_.jpg              2.940000   \n",
       "11168    para  session425  iaa_pub29739_.jpg              2.820000   \n",
       "11169    para   session90   iaa_pub6243_.jpg              3.260000   \n",
       "11170    para  session395  iaa_pub27597_.jpg              3.940000   \n",
       "\n",
       "       qualityScore           sessionId_imageName       set  \n",
       "0          1.413793  session254_iaa_pub17770_.jpg      test  \n",
       "1          3.995833  session241_iaa_pub16811_.jpg      test  \n",
       "2          3.046154  session174_iaa_pub12164_.jpg  training  \n",
       "3          3.752000  session276_iaa_pub19290_.jpg  training  \n",
       "4          3.556000  session272_iaa_pub19007_.jpg  training  \n",
       "...             ...                           ...       ...  \n",
       "11166      3.340000  session403_iaa_pub28170_.jpg  training  \n",
       "11167      3.232000    session21_iaa_pub1456_.jpg  training  \n",
       "11168      2.944000  session425_iaa_pub29739_.jpg  training  \n",
       "11169      3.408000    session90_iaa_pub6243_.jpg  training  \n",
       "11170      3.908000  session395_iaa_pub27597_.jpg  training  \n",
       "\n",
       "[11171 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>image_name</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c_total</th>\n",
       "      <th>scaled_MOS_quality</th>\n",
       "      <th>SD</th>\n",
       "      <th>MOS_zscore</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>koniq</td>\n",
       "      <td>10004473376.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "      <td>7</td>\n",
       "      <td>105</td>\n",
       "      <td>3.828571</td>\n",
       "      <td>0.527278</td>\n",
       "      <td>77.383621</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>koniq</td>\n",
       "      <td>10007357496.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>3.479167</td>\n",
       "      <td>0.580003</td>\n",
       "      <td>68.728571</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>koniq</td>\n",
       "      <td>10007903636.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>3.781250</td>\n",
       "      <td>0.527220</td>\n",
       "      <td>78.628571</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>koniq</td>\n",
       "      <td>10009096245.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>75</td>\n",
       "      <td>13</td>\n",
       "      <td>109</td>\n",
       "      <td>3.926606</td>\n",
       "      <td>0.556218</td>\n",
       "      <td>77.243750</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>koniq</td>\n",
       "      <td>100117038.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>3.830000</td>\n",
       "      <td>0.532860</td>\n",
       "      <td>75.112500</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10068</th>\n",
       "      <td>koniq</td>\n",
       "      <td>9984535544.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>3.586538</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>70.020089</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10069</th>\n",
       "      <td>koniq</td>\n",
       "      <td>9991658304.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>104</td>\n",
       "      <td>3.923077</td>\n",
       "      <td>0.455651</td>\n",
       "      <td>79.337838</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10070</th>\n",
       "      <td>koniq</td>\n",
       "      <td>9991999836.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "      <td>101</td>\n",
       "      <td>3.920792</td>\n",
       "      <td>0.462237</td>\n",
       "      <td>78.092437</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10071</th>\n",
       "      <td>koniq</td>\n",
       "      <td>9995874256.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>3.462963</td>\n",
       "      <td>0.570717</td>\n",
       "      <td>68.095133</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10072</th>\n",
       "      <td>koniq</td>\n",
       "      <td>9996001596.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>3.417476</td>\n",
       "      <td>0.551722</td>\n",
       "      <td>67.219027</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10073 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset       image_name  c1  c2  c3  c4  c5  c_total  \\\n",
       "0       koniq  10004473376.jpg   0   0  25  73   7      105   \n",
       "1       koniq  10007357496.jpg   0   3  45  47   1       96   \n",
       "2       koniq  10007903636.jpg   1   0  20  73   2       96   \n",
       "3       koniq  10009096245.jpg   0   0  21  75  13      109   \n",
       "4       koniq    100117038.jpg   0   1  21  72   6      100   \n",
       "...       ...              ...  ..  ..  ..  ..  ..      ...   \n",
       "10068   koniq   9984535544.jpg   0   0  46  55   3      104   \n",
       "10069   koniq   9991658304.jpg   0   1  12  85   6      104   \n",
       "10070   koniq   9991999836.jpg   0   0  15  79   7      101   \n",
       "10071   koniq   9995874256.jpg   0   3  53  51   1      108   \n",
       "10072   koniq   9996001596.jpg   0   2  57  43   1      103   \n",
       "\n",
       "       scaled_MOS_quality        SD  MOS_zscore       set  \n",
       "0                3.828571  0.527278   77.383621  training  \n",
       "1                3.479167  0.580003   68.728571      test  \n",
       "2                3.781250  0.527220   78.628571  training  \n",
       "3                3.926606  0.556218   77.243750  training  \n",
       "4                3.830000  0.532860   75.112500  training  \n",
       "...                   ...       ...         ...       ...  \n",
       "10068            3.586538  0.550562   70.020089      test  \n",
       "10069            3.923077  0.455651   79.337838  training  \n",
       "10070            3.920792  0.462237   78.092437      test  \n",
       "10071            3.462963  0.570717   68.095133  training  \n",
       "10072            3.417476  0.551722   67.219027  training  \n",
       "\n",
       "[10073 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Image name</th>\n",
       "      <th>MOS</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Colorfulness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noisiness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>scaled_MOS_quality</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spaq</td>\n",
       "      <td>07976.jpg</td>\n",
       "      <td>66.67</td>\n",
       "      <td>72.50</td>\n",
       "      <td>70.17</td>\n",
       "      <td>71.33</td>\n",
       "      <td>65.17</td>\n",
       "      <td>63.67</td>\n",
       "      <td>3.751915</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spaq</td>\n",
       "      <td>07515.jpg</td>\n",
       "      <td>28.00</td>\n",
       "      <td>50.75</td>\n",
       "      <td>47.25</td>\n",
       "      <td>43.88</td>\n",
       "      <td>50.63</td>\n",
       "      <td>25.88</td>\n",
       "      <td>2.106383</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spaq</td>\n",
       "      <td>10664.jpg</td>\n",
       "      <td>31.00</td>\n",
       "      <td>51.71</td>\n",
       "      <td>38.14</td>\n",
       "      <td>44.14</td>\n",
       "      <td>33.86</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.234043</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spaq</td>\n",
       "      <td>10558.jpg</td>\n",
       "      <td>73.17</td>\n",
       "      <td>69.33</td>\n",
       "      <td>76.50</td>\n",
       "      <td>71.33</td>\n",
       "      <td>67.00</td>\n",
       "      <td>75.67</td>\n",
       "      <td>4.028511</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spaq</td>\n",
       "      <td>01972.jpg</td>\n",
       "      <td>63.40</td>\n",
       "      <td>55.70</td>\n",
       "      <td>69.50</td>\n",
       "      <td>67.80</td>\n",
       "      <td>57.09</td>\n",
       "      <td>69.40</td>\n",
       "      <td>3.612766</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11120</th>\n",
       "      <td>spaq</td>\n",
       "      <td>09138.jpg</td>\n",
       "      <td>53.40</td>\n",
       "      <td>66.60</td>\n",
       "      <td>63.60</td>\n",
       "      <td>58.20</td>\n",
       "      <td>31.20</td>\n",
       "      <td>46.60</td>\n",
       "      <td>3.187234</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11121</th>\n",
       "      <td>spaq</td>\n",
       "      <td>02544.jpg</td>\n",
       "      <td>16.09</td>\n",
       "      <td>28.36</td>\n",
       "      <td>30.45</td>\n",
       "      <td>32.09</td>\n",
       "      <td>41.30</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1.599574</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11122</th>\n",
       "      <td>spaq</td>\n",
       "      <td>06378.jpg</td>\n",
       "      <td>22.50</td>\n",
       "      <td>52.38</td>\n",
       "      <td>56.63</td>\n",
       "      <td>51.00</td>\n",
       "      <td>22.63</td>\n",
       "      <td>9.88</td>\n",
       "      <td>1.872340</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11123</th>\n",
       "      <td>spaq</td>\n",
       "      <td>09206.jpg</td>\n",
       "      <td>56.33</td>\n",
       "      <td>46.56</td>\n",
       "      <td>57.56</td>\n",
       "      <td>55.00</td>\n",
       "      <td>59.44</td>\n",
       "      <td>63.11</td>\n",
       "      <td>3.311915</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11124</th>\n",
       "      <td>spaq</td>\n",
       "      <td>08966.jpg</td>\n",
       "      <td>59.00</td>\n",
       "      <td>34.73</td>\n",
       "      <td>61.73</td>\n",
       "      <td>52.36</td>\n",
       "      <td>67.45</td>\n",
       "      <td>63.45</td>\n",
       "      <td>3.425532</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11125 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset Image name    MOS  Brightness  Colorfulness  Contrast  \\\n",
       "0        spaq  07976.jpg  66.67       72.50         70.17     71.33   \n",
       "1        spaq  07515.jpg  28.00       50.75         47.25     43.88   \n",
       "2        spaq  10664.jpg  31.00       51.71         38.14     44.14   \n",
       "3        spaq  10558.jpg  73.17       69.33         76.50     71.33   \n",
       "4        spaq  01972.jpg  63.40       55.70         69.50     67.80   \n",
       "...       ...        ...    ...         ...           ...       ...   \n",
       "11120    spaq  09138.jpg  53.40       66.60         63.60     58.20   \n",
       "11121    spaq  02544.jpg  16.09       28.36         30.45     32.09   \n",
       "11122    spaq  06378.jpg  22.50       52.38         56.63     51.00   \n",
       "11123    spaq  09206.jpg  56.33       46.56         57.56     55.00   \n",
       "11124    spaq  08966.jpg  59.00       34.73         61.73     52.36   \n",
       "\n",
       "       Noisiness  Sharpness  scaled_MOS_quality         set  \n",
       "0          65.17      63.67            3.751915  validation  \n",
       "1          50.63      25.88            2.106383    training  \n",
       "2          33.86      13.17            2.234043        test  \n",
       "3          67.00      75.67            4.028511    training  \n",
       "4          57.09      69.40            3.612766    training  \n",
       "...          ...        ...                 ...         ...  \n",
       "11120      31.20      46.60            3.187234    training  \n",
       "11121      41.30       4.90            1.599574    training  \n",
       "11122      22.63       9.88            1.872340    training  \n",
       "11123      59.44      63.11            3.311915    training  \n",
       "11124      67.45      63.45            3.425532    training  \n",
       "\n",
       "[11125 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_directory = '/media/workstation/BackupDrive/Dataset/'\n",
    "\n",
    "# ava\n",
    "ava_images = main_directory + 'data_512x/'\n",
    "ava_multimodel_dataset = main_directory + 'multimodel_dataset/ava_multimodel_full_train_20_percent_val_test.csv'\n",
    "ava_df = pd.read_csv(ava_multimodel_dataset)\n",
    "# ava_df.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "# para\n",
    "para_images = main_directory + 'PARA_512x_resized/'\n",
    "para_multimodel_dataset = main_directory + 'multimodel_dataset/para_multimodel.csv'\n",
    "para_df = pd.read_csv(para_multimodel_dataset)\n",
    "para_df.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "# koniq \n",
    "koniq_images = main_directory + 'koniq10k_512x_image_in_csv/'\n",
    "koniq_multimodel_dataset = main_directory + 'multimodel_dataset/koniq_multimodel.csv'\n",
    "koniq_df = pd.read_csv(koniq_multimodel_dataset)\n",
    "koniq_df.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "# spaq\n",
    "spaq_images = main_directory + 'SPAQ_512x_resized/'\n",
    "spaq_multimodel_dataset = main_directory + 'multimodel_dataset/spaq_multimodel.csv'\n",
    "spaq_df = pd.read_csv(spaq_multimodel_dataset)\n",
    "spaq_df.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "display(ava_df)\n",
    "display(para_df)\n",
    "display(koniq_df)\n",
    "display(spaq_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Image name</th>\n",
       "      <th>MOS</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Colorfulness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noisiness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>scaled_MOS_quality</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spaq</td>\n",
       "      <td>07515.jpg</td>\n",
       "      <td>28.00</td>\n",
       "      <td>50.75</td>\n",
       "      <td>47.25</td>\n",
       "      <td>43.88</td>\n",
       "      <td>50.63</td>\n",
       "      <td>25.88</td>\n",
       "      <td>2.106383</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spaq</td>\n",
       "      <td>10558.jpg</td>\n",
       "      <td>73.17</td>\n",
       "      <td>69.33</td>\n",
       "      <td>76.50</td>\n",
       "      <td>71.33</td>\n",
       "      <td>67.00</td>\n",
       "      <td>75.67</td>\n",
       "      <td>4.028511</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spaq</td>\n",
       "      <td>01972.jpg</td>\n",
       "      <td>63.40</td>\n",
       "      <td>55.70</td>\n",
       "      <td>69.50</td>\n",
       "      <td>67.80</td>\n",
       "      <td>57.09</td>\n",
       "      <td>69.40</td>\n",
       "      <td>3.612766</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spaq</td>\n",
       "      <td>08532.jpg</td>\n",
       "      <td>80.20</td>\n",
       "      <td>79.20</td>\n",
       "      <td>82.90</td>\n",
       "      <td>78.30</td>\n",
       "      <td>81.80</td>\n",
       "      <td>79.50</td>\n",
       "      <td>4.327660</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spaq</td>\n",
       "      <td>09365.jpg</td>\n",
       "      <td>25.00</td>\n",
       "      <td>43.78</td>\n",
       "      <td>26.22</td>\n",
       "      <td>16.44</td>\n",
       "      <td>32.44</td>\n",
       "      <td>13.44</td>\n",
       "      <td>1.978723</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11120</th>\n",
       "      <td>spaq</td>\n",
       "      <td>09138.jpg</td>\n",
       "      <td>53.40</td>\n",
       "      <td>66.60</td>\n",
       "      <td>63.60</td>\n",
       "      <td>58.20</td>\n",
       "      <td>31.20</td>\n",
       "      <td>46.60</td>\n",
       "      <td>3.187234</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11121</th>\n",
       "      <td>spaq</td>\n",
       "      <td>02544.jpg</td>\n",
       "      <td>16.09</td>\n",
       "      <td>28.36</td>\n",
       "      <td>30.45</td>\n",
       "      <td>32.09</td>\n",
       "      <td>41.30</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1.599574</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11122</th>\n",
       "      <td>spaq</td>\n",
       "      <td>06378.jpg</td>\n",
       "      <td>22.50</td>\n",
       "      <td>52.38</td>\n",
       "      <td>56.63</td>\n",
       "      <td>51.00</td>\n",
       "      <td>22.63</td>\n",
       "      <td>9.88</td>\n",
       "      <td>1.872340</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11123</th>\n",
       "      <td>spaq</td>\n",
       "      <td>09206.jpg</td>\n",
       "      <td>56.33</td>\n",
       "      <td>46.56</td>\n",
       "      <td>57.56</td>\n",
       "      <td>55.00</td>\n",
       "      <td>59.44</td>\n",
       "      <td>63.11</td>\n",
       "      <td>3.311915</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11124</th>\n",
       "      <td>spaq</td>\n",
       "      <td>08966.jpg</td>\n",
       "      <td>59.00</td>\n",
       "      <td>34.73</td>\n",
       "      <td>61.73</td>\n",
       "      <td>52.36</td>\n",
       "      <td>67.45</td>\n",
       "      <td>63.45</td>\n",
       "      <td>3.425532</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8110 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset Image name    MOS  Brightness  Colorfulness  Contrast  \\\n",
       "1        spaq  07515.jpg  28.00       50.75         47.25     43.88   \n",
       "3        spaq  10558.jpg  73.17       69.33         76.50     71.33   \n",
       "4        spaq  01972.jpg  63.40       55.70         69.50     67.80   \n",
       "6        spaq  08532.jpg  80.20       79.20         82.90     78.30   \n",
       "7        spaq  09365.jpg  25.00       43.78         26.22     16.44   \n",
       "...       ...        ...    ...         ...           ...       ...   \n",
       "11120    spaq  09138.jpg  53.40       66.60         63.60     58.20   \n",
       "11121    spaq  02544.jpg  16.09       28.36         30.45     32.09   \n",
       "11122    spaq  06378.jpg  22.50       52.38         56.63     51.00   \n",
       "11123    spaq  09206.jpg  56.33       46.56         57.56     55.00   \n",
       "11124    spaq  08966.jpg  59.00       34.73         61.73     52.36   \n",
       "\n",
       "       Noisiness  Sharpness  scaled_MOS_quality       set  \n",
       "1          50.63      25.88            2.106383  training  \n",
       "3          67.00      75.67            4.028511  training  \n",
       "4          57.09      69.40            3.612766  training  \n",
       "6          81.80      79.50            4.327660  training  \n",
       "7          32.44      13.44            1.978723  training  \n",
       "...          ...        ...                 ...       ...  \n",
       "11120      31.20      46.60            3.187234  training  \n",
       "11121      41.30       4.90            1.599574  training  \n",
       "11122      22.63       9.88            1.872340  training  \n",
       "11123      59.44      63.11            3.311915  training  \n",
       "11124      67.45      63.45            3.425532  training  \n",
       "\n",
       "[8110 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Image name</th>\n",
       "      <th>MOS</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Colorfulness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noisiness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>scaled_MOS_quality</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spaq</td>\n",
       "      <td>07976.jpg</td>\n",
       "      <td>66.67</td>\n",
       "      <td>72.50</td>\n",
       "      <td>70.17</td>\n",
       "      <td>71.33</td>\n",
       "      <td>65.17</td>\n",
       "      <td>63.67</td>\n",
       "      <td>3.751915</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spaq</td>\n",
       "      <td>02522.jpg</td>\n",
       "      <td>56.00</td>\n",
       "      <td>56.18</td>\n",
       "      <td>57.45</td>\n",
       "      <td>60.45</td>\n",
       "      <td>57.30</td>\n",
       "      <td>52.09</td>\n",
       "      <td>3.297872</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>spaq</td>\n",
       "      <td>08558.jpg</td>\n",
       "      <td>69.50</td>\n",
       "      <td>65.00</td>\n",
       "      <td>70.50</td>\n",
       "      <td>64.75</td>\n",
       "      <td>74.75</td>\n",
       "      <td>65.25</td>\n",
       "      <td>3.872340</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>spaq</td>\n",
       "      <td>05088.jpg</td>\n",
       "      <td>31.83</td>\n",
       "      <td>42.30</td>\n",
       "      <td>55.91</td>\n",
       "      <td>51.91</td>\n",
       "      <td>40.75</td>\n",
       "      <td>14.64</td>\n",
       "      <td>2.269362</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>spaq</td>\n",
       "      <td>02628.jpg</td>\n",
       "      <td>48.70</td>\n",
       "      <td>45.50</td>\n",
       "      <td>56.50</td>\n",
       "      <td>44.67</td>\n",
       "      <td>46.30</td>\n",
       "      <td>40.90</td>\n",
       "      <td>2.987234</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11079</th>\n",
       "      <td>spaq</td>\n",
       "      <td>03607.jpg</td>\n",
       "      <td>69.91</td>\n",
       "      <td>70.64</td>\n",
       "      <td>73.45</td>\n",
       "      <td>71.10</td>\n",
       "      <td>66.64</td>\n",
       "      <td>70.91</td>\n",
       "      <td>3.889787</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11080</th>\n",
       "      <td>spaq</td>\n",
       "      <td>05174.jpg</td>\n",
       "      <td>10.40</td>\n",
       "      <td>5.89</td>\n",
       "      <td>37.50</td>\n",
       "      <td>23.56</td>\n",
       "      <td>33.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.357447</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11081</th>\n",
       "      <td>spaq</td>\n",
       "      <td>02446.jpg</td>\n",
       "      <td>51.70</td>\n",
       "      <td>57.44</td>\n",
       "      <td>47.00</td>\n",
       "      <td>54.33</td>\n",
       "      <td>48.10</td>\n",
       "      <td>52.30</td>\n",
       "      <td>3.114894</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>spaq</td>\n",
       "      <td>03969.jpg</td>\n",
       "      <td>47.25</td>\n",
       "      <td>41.25</td>\n",
       "      <td>51.83</td>\n",
       "      <td>51.42</td>\n",
       "      <td>54.08</td>\n",
       "      <td>52.83</td>\n",
       "      <td>2.925532</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11098</th>\n",
       "      <td>spaq</td>\n",
       "      <td>03719.jpg</td>\n",
       "      <td>54.08</td>\n",
       "      <td>46.50</td>\n",
       "      <td>44.18</td>\n",
       "      <td>51.67</td>\n",
       "      <td>57.17</td>\n",
       "      <td>49.08</td>\n",
       "      <td>3.216170</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset Image name    MOS  Brightness  Colorfulness  Contrast  \\\n",
       "0        spaq  07976.jpg  66.67       72.50         70.17     71.33   \n",
       "11       spaq  02522.jpg  56.00       56.18         57.45     60.45   \n",
       "21       spaq  08558.jpg  69.50       65.00         70.50     64.75   \n",
       "26       spaq  05088.jpg  31.83       42.30         55.91     51.91   \n",
       "27       spaq  02628.jpg  48.70       45.50         56.50     44.67   \n",
       "...       ...        ...    ...         ...           ...       ...   \n",
       "11079    spaq  03607.jpg  69.91       70.64         73.45     71.10   \n",
       "11080    spaq  05174.jpg  10.40        5.89         37.50     23.56   \n",
       "11081    spaq  02446.jpg  51.70       57.44         47.00     54.33   \n",
       "11089    spaq  03969.jpg  47.25       41.25         51.83     51.42   \n",
       "11098    spaq  03719.jpg  54.08       46.50         44.18     51.67   \n",
       "\n",
       "       Noisiness  Sharpness  scaled_MOS_quality         set  \n",
       "0          65.17      63.67            3.751915  validation  \n",
       "11         57.30      52.09            3.297872  validation  \n",
       "21         74.75      65.25            3.872340  validation  \n",
       "26         40.75      14.64            2.269362  validation  \n",
       "27         46.30      40.90            2.987234  validation  \n",
       "...          ...        ...                 ...         ...  \n",
       "11079      66.64      70.91            3.889787  validation  \n",
       "11080      33.00       3.80            1.357447  validation  \n",
       "11081      48.10      52.30            3.114894  validation  \n",
       "11089      54.08      52.83            2.925532  validation  \n",
       "11098      57.17      49.08            3.216170  validation  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Image name</th>\n",
       "      <th>MOS</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Colorfulness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noisiness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>scaled_MOS_quality</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spaq</td>\n",
       "      <td>10664.jpg</td>\n",
       "      <td>31.00</td>\n",
       "      <td>51.71</td>\n",
       "      <td>38.14</td>\n",
       "      <td>44.14</td>\n",
       "      <td>33.86</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.234043</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spaq</td>\n",
       "      <td>02979.jpg</td>\n",
       "      <td>30.89</td>\n",
       "      <td>38.10</td>\n",
       "      <td>57.22</td>\n",
       "      <td>50.11</td>\n",
       "      <td>49.10</td>\n",
       "      <td>16.60</td>\n",
       "      <td>2.229362</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spaq</td>\n",
       "      <td>06700.jpg</td>\n",
       "      <td>53.17</td>\n",
       "      <td>55.00</td>\n",
       "      <td>47.67</td>\n",
       "      <td>50.67</td>\n",
       "      <td>57.33</td>\n",
       "      <td>52.83</td>\n",
       "      <td>3.177447</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spaq</td>\n",
       "      <td>08568.jpg</td>\n",
       "      <td>65.50</td>\n",
       "      <td>61.25</td>\n",
       "      <td>65.00</td>\n",
       "      <td>68.25</td>\n",
       "      <td>69.00</td>\n",
       "      <td>67.25</td>\n",
       "      <td>3.702128</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>spaq</td>\n",
       "      <td>09323.jpg</td>\n",
       "      <td>69.13</td>\n",
       "      <td>70.75</td>\n",
       "      <td>75.38</td>\n",
       "      <td>65.13</td>\n",
       "      <td>59.13</td>\n",
       "      <td>66.25</td>\n",
       "      <td>3.856596</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11086</th>\n",
       "      <td>spaq</td>\n",
       "      <td>06062.jpg</td>\n",
       "      <td>33.89</td>\n",
       "      <td>57.00</td>\n",
       "      <td>53.67</td>\n",
       "      <td>57.89</td>\n",
       "      <td>47.22</td>\n",
       "      <td>20.78</td>\n",
       "      <td>2.357021</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11092</th>\n",
       "      <td>spaq</td>\n",
       "      <td>10571.jpg</td>\n",
       "      <td>28.29</td>\n",
       "      <td>52.57</td>\n",
       "      <td>54.57</td>\n",
       "      <td>48.86</td>\n",
       "      <td>27.14</td>\n",
       "      <td>8.20</td>\n",
       "      <td>2.118723</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11093</th>\n",
       "      <td>spaq</td>\n",
       "      <td>05861.jpg</td>\n",
       "      <td>59.80</td>\n",
       "      <td>52.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>56.60</td>\n",
       "      <td>56.80</td>\n",
       "      <td>3.459574</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11117</th>\n",
       "      <td>spaq</td>\n",
       "      <td>05853.jpg</td>\n",
       "      <td>58.67</td>\n",
       "      <td>65.50</td>\n",
       "      <td>64.17</td>\n",
       "      <td>56.50</td>\n",
       "      <td>53.00</td>\n",
       "      <td>61.17</td>\n",
       "      <td>3.411489</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11118</th>\n",
       "      <td>spaq</td>\n",
       "      <td>07627.jpg</td>\n",
       "      <td>41.50</td>\n",
       "      <td>47.00</td>\n",
       "      <td>46.83</td>\n",
       "      <td>45.50</td>\n",
       "      <td>32.50</td>\n",
       "      <td>34.17</td>\n",
       "      <td>2.680851</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2015 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset Image name    MOS  Brightness  Colorfulness  Contrast  \\\n",
       "2        spaq  10664.jpg  31.00       51.71         38.14     44.14   \n",
       "5        spaq  02979.jpg  30.89       38.10         57.22     50.11   \n",
       "9        spaq  06700.jpg  53.17       55.00         47.67     50.67   \n",
       "14       spaq  08568.jpg  65.50       61.25         65.00     68.25   \n",
       "20       spaq  09323.jpg  69.13       70.75         75.38     65.13   \n",
       "...       ...        ...    ...         ...           ...       ...   \n",
       "11086    spaq  06062.jpg  33.89       57.00         53.67     57.89   \n",
       "11092    spaq  10571.jpg  28.29       52.57         54.57     48.86   \n",
       "11093    spaq  05861.jpg  59.80       52.00         65.00     55.00   \n",
       "11117    spaq  05853.jpg  58.67       65.50         64.17     56.50   \n",
       "11118    spaq  07627.jpg  41.50       47.00         46.83     45.50   \n",
       "\n",
       "       Noisiness  Sharpness  scaled_MOS_quality   set  \n",
       "2          33.86      13.17            2.234043  test  \n",
       "5          49.10      16.60            2.229362  test  \n",
       "9          57.33      52.83            3.177447  test  \n",
       "14         69.00      67.25            3.702128  test  \n",
       "20         59.13      66.25            3.856596  test  \n",
       "...          ...        ...                 ...   ...  \n",
       "11086      47.22      20.78            2.357021  test  \n",
       "11092      27.14       8.20            2.118723  test  \n",
       "11093      56.60      56.80            3.459574  test  \n",
       "11117      53.00      61.17            3.411489  test  \n",
       "11118      32.50      34.17            2.680851  test  \n",
       "\n",
       "[2015 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ava_train_df = ava_df[ava_df['set']=='training']\n",
    "ava_val_df = ava_df[ava_df['set']=='validation']\n",
    "ava_test_df = ava_df[ava_df['set']=='test']\n",
    "\n",
    "para_train_df = para_df[para_df['set']=='training']\n",
    "para_val_df = para_df[para_df['set']=='validation']\n",
    "para_test_df = para_df[para_df['set']=='test']\n",
    "\n",
    "koniq_train_df = koniq_df[koniq_df['set']=='training']\n",
    "koniq_val_df = koniq_df[koniq_df['set']=='validation']\n",
    "koniq_test_df = koniq_df[koniq_df['set']=='test']\n",
    "\n",
    "spaq_train_df = spaq_df[spaq_df['set']=='training']\n",
    "spaq_val_df = spaq_df[spaq_df['set']=='validation']\n",
    "spaq_test_df = spaq_df[spaq_df['set']=='test']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split images into train-validation-test ImageDataGenerator, for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19924 validated image filenames.\n",
      "Found 2492 validated image filenames.\n",
      "Found 2015 validated image filenames.\n",
      "AVA generators complete\n",
      "\n",
      "Found 8156 validated image filenames.\n",
      "Found 1000 validated image filenames.\n",
      "Found 2015 validated image filenames.\n",
      "PARA generators complete\n",
      "\n",
      "Found 7058 validated image filenames.\n",
      "Found 1000 validated image filenames.\n",
      "Found 2015 validated image filenames.\n",
      "KoNIQ generators complete\n",
      "\n",
      "Found 8110 validated image filenames.\n",
      "Found 1000 validated image filenames.\n",
      "Found 2015 validated image filenames.\n",
      "SPAQ generators complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the directory where you want to save the split datasets\n",
    "ava_images = main_directory + 'AVA/data_512x/'\n",
    "para_images = main_directory + 'PARA/PARA_512x_resized/'\n",
    "koniq_images = main_directory + 'koniq10k/koniq10k_512x_image_in_csv/'\n",
    "spaq_images = main_directory + 'SPAQ dataset-20230407T121509Z-008/SPAQ_512x_resized/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# ava\n",
    "ava_train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=ava_train_df,\n",
    "    directory=ava_images, \n",
    "    x_col=\"ID\", \n",
    "    y_col=\"scaled_MOS_aesthetic\", \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "ava_val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=ava_val_df, \n",
    "    directory=ava_images, \n",
    "    x_col=\"ID\", \n",
    "    y_col=\"scaled_MOS_aesthetic\", \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "ava_test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=ava_test_df, \n",
    "    directory=ava_images, \n",
    "    x_col=\"ID\", \n",
    "    y_col=\"scaled_MOS_aesthetic\", \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16\n",
    ")\n",
    "print('AVA generators complete\\n')\n",
    "\n",
    "# para\n",
    "para_train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=para_train_df,\n",
    "    directory=para_images, \n",
    "    x_col=\"sessionId_imageName\", \n",
    "    y_col=\"scaled_MOS_aesthetic\", \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "para_val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=para_val_df, \n",
    "    directory=para_images, \n",
    "    x_col=\"sessionId_imageName\", \n",
    "    y_col=\"scaled_MOS_aesthetic\", \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "para_test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=para_test_df, \n",
    "    directory=para_images, \n",
    "    x_col=\"sessionId_imageName\", \n",
    "    y_col=\"scaled_MOS_aesthetic\", \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16\n",
    ")\n",
    "print('PARA generators complete\\n')\n",
    "\n",
    "# koniq\n",
    "koniq_train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=koniq_train_df,\n",
    "    directory=koniq_images, \n",
    "    x_col=\"image_name\", \n",
    "    y_col=\"scaled_MOS_quality\", \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "koniq_val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=koniq_val_df, \n",
    "    directory=koniq_images, \n",
    "    x_col=\"image_name\", \n",
    "    y_col=\"scaled_MOS_quality\", \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "koniq_test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=koniq_test_df, \n",
    "    directory=koniq_images, \n",
    "    x_col=\"image_name\", \n",
    "    y_col=\"scaled_MOS_quality\", \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16\n",
    ")\n",
    "print('KoNIQ generators complete\\n')\n",
    "\n",
    "# spaq\n",
    "spaq_train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=spaq_train_df,\n",
    "    directory=spaq_images, \n",
    "    x_col=\"Image name\", \n",
    "    y_col=\"scaled_MOS_quality\", \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "spaq_val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=spaq_val_df, \n",
    "    directory=spaq_images, \n",
    "    x_col=\"Image name\", \n",
    "    y_col=\"scaled_MOS_quality\", \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "spaq_test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=spaq_test_df, \n",
    "    directory=spaq_images, \n",
    "    x_col=\"Image name\", \n",
    "    y_col=\"scaled_MOS_quality\", \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16\n",
    ")\n",
    "print('SPAQ generators complete\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training (InceptionResNetV2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wandb configs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the PLCC custom metric first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plcc_tf(x, y):\n",
    "    \"\"\"PLCC metric\"\"\"\n",
    "    xc = x - K.mean(x)\n",
    "    yc = y - K.mean(y)\n",
    "    return K.mean(xc*yc)/(K.std(x)*K.std(y) + K.epsilon())\n",
    "\n",
    "def pearson_correlation(y_true, y_pred):\n",
    "    # Subtract the mean from true and predicted values\n",
    "    y_true_mean = K.mean(y_true)\n",
    "    y_pred_mean = K.mean(y_pred)\n",
    "    y_true_centered = y_true - y_true_mean\n",
    "    y_pred_centered = y_pred - y_pred_mean\n",
    "\n",
    "    # Calculate covariance and standard deviation\n",
    "    covariance = K.mean(y_true_centered * y_pred_centered)\n",
    "    y_true_std = K.std(y_true)\n",
    "    y_pred_std = K.std(y_pred)\n",
    "\n",
    "    # Calculate Pearson correlation coefficient\n",
    "    pearson_coefficient = covariance / (y_true_std * y_pred_std + K.epsilon())\n",
    "\n",
    "    return pearson_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMetricCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Calculate the custom metric\n",
    "        y_true = self.validation_data[1]\n",
    "        y_pred = self.model.predict(self.validation_data[0])\n",
    "        pearson_coefficient = pearson_correlation(y_true, y_pred)\n",
    "\n",
    "        # Log the custom metric using wandb\n",
    "        wandb.log({\"val_pearson_coefficient\": pearson_coefficient})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:g7scrnqr) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Output_AVA_aesthetic_loss</td><td>█▂▂▁▁▁▁</td></tr><tr><td>Output_AVA_aesthetic_pearson_correlation</td><td>▁▁▆█▇█▃</td></tr><tr><td>Output_AVA_aesthetic_root_mean_squared_error</td><td>█▃▂▂▁▁▁</td></tr><tr><td>Output_KonIQ_quality_loss</td><td>█▂▂▁▁▁▁</td></tr><tr><td>Output_KonIQ_quality_pearson_correlation</td><td>▁▃▄▅▇██</td></tr><tr><td>Output_KonIQ_quality_root_mean_squared_error</td><td>█▃▂▁▁▁▁</td></tr><tr><td>Output_PARA_aesthetic_loss</td><td>█▂▂▁▁▁▁</td></tr><tr><td>Output_PARA_aesthetic_pearson_correlation</td><td>▁▃▅▅▆██</td></tr><tr><td>Output_PARA_aesthetic_root_mean_squared_error</td><td>█▃▂▂▁▁▁</td></tr><tr><td>Output_SPAQ_quality_loss</td><td>█▂▂▁▁▁▁</td></tr><tr><td>Output_SPAQ_quality_pearson_correlation</td><td>▁▃▅▆▇██</td></tr><tr><td>Output_SPAQ_quality_root_mean_squared_error</td><td>█▃▂▁▁▁▁</td></tr><tr><td>batch/Output_AVA_aesthetic_loss</td><td>█▅▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_AVA_aesthetic_pearson_correlation</td><td>▆▅▅▅▅▂▃▄▄▅▇▆▆▆▅▆▅▆▆▆▁▇▇▇▆▇▆▇▆▆▆▅▅▆▅▇█▇▇▇</td></tr><tr><td>batch/Output_AVA_aesthetic_root_mean_squared_error</td><td>█▆▅▅▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_KonIQ_quality_loss</td><td>█▅▄▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_KonIQ_quality_pearson_correlation</td><td>▁▁▂▂▂▃▃▃▃▃▄▄▄▄▅▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>batch/Output_KonIQ_quality_root_mean_squared_error</td><td>█▆▅▅▄▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_PARA_aesthetic_loss</td><td>█▅▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_PARA_aesthetic_pearson_correlation</td><td>▃▃▃▂▃▁▄▄▄▄▄▅▅▅▅▃▅▆▅▅▅▆▆▆▆▄▇▆▇▇█▇▇▇▇▇▇███</td></tr><tr><td>batch/Output_PARA_aesthetic_root_mean_squared_error</td><td>█▆▅▅▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_SPAQ_quality_loss</td><td>█▅▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_SPAQ_quality_pearson_correlation</td><td>▁▂▂▂▂▄▄▄▄▄▆▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇██▇▇▇▇████</td></tr><tr><td>batch/Output_SPAQ_quality_root_mean_squared_error</td><td>█▆▅▄▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/learning_rate</td><td>███████████████████████████████████▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>█▅▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>epoch/Output_AVA_aesthetic_loss</td><td>█▂▂▁▁▁▁</td></tr><tr><td>epoch/Output_AVA_aesthetic_pearson_correlation</td><td>▁▁▆█▇█▃</td></tr><tr><td>epoch/Output_AVA_aesthetic_root_mean_squared_error</td><td>█▃▂▂▁▁▁</td></tr><tr><td>epoch/Output_KonIQ_quality_loss</td><td>█▂▂▁▁▁▁</td></tr><tr><td>epoch/Output_KonIQ_quality_pearson_correlation</td><td>▁▃▄▅▇██</td></tr><tr><td>epoch/Output_KonIQ_quality_root_mean_squared_error</td><td>█▃▂▁▁▁▁</td></tr><tr><td>epoch/Output_PARA_aesthetic_loss</td><td>█▂▂▁▁▁▁</td></tr><tr><td>epoch/Output_PARA_aesthetic_pearson_correlation</td><td>▁▃▅▅▆██</td></tr><tr><td>epoch/Output_PARA_aesthetic_root_mean_squared_error</td><td>█▃▂▂▁▁▁</td></tr><tr><td>epoch/Output_SPAQ_quality_loss</td><td>█▂▂▁▁▁▁</td></tr><tr><td>epoch/Output_SPAQ_quality_pearson_correlation</td><td>▁▃▅▆▇██</td></tr><tr><td>epoch/Output_SPAQ_quality_root_mean_squared_error</td><td>█▃▂▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▂▂▁▁▁▁</td></tr><tr><td>epoch/val_Output_AVA_aesthetic_loss</td><td>▆█▂▁▁▁▂</td></tr><tr><td>epoch/val_Output_AVA_aesthetic_pearson_correlation</td><td>▄▃█▅██▁</td></tr><tr><td>epoch/val_Output_AVA_aesthetic_root_mean_squared_error</td><td>▆█▂▁▁▁▂</td></tr><tr><td>epoch/val_Output_KonIQ_quality_loss</td><td>█▂▃▂▁▁▂</td></tr><tr><td>epoch/val_Output_KonIQ_quality_pearson_correlation</td><td>▁█▄█▇█▇</td></tr><tr><td>epoch/val_Output_KonIQ_quality_root_mean_squared_error</td><td>█▂▃▂▁▁▃</td></tr><tr><td>epoch/val_Output_PARA_aesthetic_loss</td><td>█▃▁▁▂▂▁</td></tr><tr><td>epoch/val_Output_PARA_aesthetic_pearson_correlation</td><td>▁▄█▇▇▅█</td></tr><tr><td>epoch/val_Output_PARA_aesthetic_root_mean_squared_error</td><td>█▃▁▁▂▂▁</td></tr><tr><td>epoch/val_Output_SPAQ_quality_loss</td><td>█▇▃▁▂▂▂</td></tr><tr><td>epoch/val_Output_SPAQ_quality_pearson_correlation</td><td>▆▂▅█▆▃▁</td></tr><tr><td>epoch/val_Output_SPAQ_quality_root_mean_squared_error</td><td>█▇▃▁▂▂▂</td></tr><tr><td>epoch/val_loss</td><td>█▅▂▁▁▁▂</td></tr><tr><td>loss</td><td>█▂▂▁▁▁▁</td></tr><tr><td>val_Output_AVA_aesthetic_loss</td><td>▆█▂▁▁▁▂</td></tr><tr><td>val_Output_AVA_aesthetic_pearson_correlation</td><td>▄▃█▅██▁</td></tr><tr><td>val_Output_AVA_aesthetic_root_mean_squared_error</td><td>▆█▂▁▁▁▂</td></tr><tr><td>val_Output_KonIQ_quality_loss</td><td>█▂▃▂▁▁▂</td></tr><tr><td>val_Output_KonIQ_quality_pearson_correlation</td><td>▁█▄█▇█▇</td></tr><tr><td>val_Output_KonIQ_quality_root_mean_squared_error</td><td>█▂▃▂▁▁▃</td></tr><tr><td>val_Output_PARA_aesthetic_loss</td><td>█▃▁▁▂▂▁</td></tr><tr><td>val_Output_PARA_aesthetic_pearson_correlation</td><td>▁▄█▇▇▅█</td></tr><tr><td>val_Output_PARA_aesthetic_root_mean_squared_error</td><td>█▃▁▁▂▂▁</td></tr><tr><td>val_Output_SPAQ_quality_loss</td><td>█▇▃▁▂▂▂</td></tr><tr><td>val_Output_SPAQ_quality_pearson_correlation</td><td>▆▂▅█▆▃▁</td></tr><tr><td>val_Output_SPAQ_quality_root_mean_squared_error</td><td>█▇▃▁▂▂▂</td></tr><tr><td>val_loss</td><td>█▅▂▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Output_AVA_aesthetic_loss</td><td>0.26909</td></tr><tr><td>Output_AVA_aesthetic_pearson_correlation</td><td>0.00564</td></tr><tr><td>Output_AVA_aesthetic_root_mean_squared_error</td><td>0.51873</td></tr><tr><td>Output_KonIQ_quality_loss</td><td>0.32675</td></tr><tr><td>Output_KonIQ_quality_pearson_correlation</td><td>0.29771</td></tr><tr><td>Output_KonIQ_quality_root_mean_squared_error</td><td>0.57075</td></tr><tr><td>Output_PARA_aesthetic_loss</td><td>0.33469</td></tr><tr><td>Output_PARA_aesthetic_pearson_correlation</td><td>0.09214</td></tr><tr><td>Output_PARA_aesthetic_root_mean_squared_error</td><td>0.57857</td></tr><tr><td>Output_SPAQ_quality_loss</td><td>0.87449</td></tr><tr><td>Output_SPAQ_quality_pearson_correlation</td><td>0.32263</td></tr><tr><td>Output_SPAQ_quality_root_mean_squared_error</td><td>0.93519</td></tr><tr><td>batch/Output_AVA_aesthetic_loss</td><td>0.24664</td></tr><tr><td>batch/Output_AVA_aesthetic_pearson_correlation</td><td>0.02719</td></tr><tr><td>batch/Output_AVA_aesthetic_root_mean_squared_error</td><td>0.49663</td></tr><tr><td>batch/Output_KonIQ_quality_loss</td><td>0.30424</td></tr><tr><td>batch/Output_KonIQ_quality_pearson_correlation</td><td>0.33025</td></tr><tr><td>batch/Output_KonIQ_quality_root_mean_squared_error</td><td>0.55115</td></tr><tr><td>batch/Output_PARA_aesthetic_loss</td><td>0.31737</td></tr><tr><td>batch/Output_PARA_aesthetic_pearson_correlation</td><td>0.10318</td></tr><tr><td>batch/Output_PARA_aesthetic_root_mean_squared_error</td><td>0.56328</td></tr><tr><td>batch/Output_SPAQ_quality_loss</td><td>0.85677</td></tr><tr><td>batch/Output_SPAQ_quality_pearson_correlation</td><td>0.33734</td></tr><tr><td>batch/Output_SPAQ_quality_root_mean_squared_error</td><td>0.92575</td></tr><tr><td>batch/batch_step</td><td>9995</td></tr><tr><td>batch/learning_rate</td><td>0.0001</td></tr><tr><td>batch/loss</td><td>1.72502</td></tr><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_Output_KonIQ_quality_pearson_correlation</td><td>0.42474</td></tr><tr><td>epoch</td><td>6</td></tr><tr><td>epoch/Output_AVA_aesthetic_loss</td><td>0.26909</td></tr><tr><td>epoch/Output_AVA_aesthetic_pearson_correlation</td><td>0.00564</td></tr><tr><td>epoch/Output_AVA_aesthetic_root_mean_squared_error</td><td>0.51873</td></tr><tr><td>epoch/Output_KonIQ_quality_loss</td><td>0.32675</td></tr><tr><td>epoch/Output_KonIQ_quality_pearson_correlation</td><td>0.29771</td></tr><tr><td>epoch/Output_KonIQ_quality_root_mean_squared_error</td><td>0.57075</td></tr><tr><td>epoch/Output_PARA_aesthetic_loss</td><td>0.33469</td></tr><tr><td>epoch/Output_PARA_aesthetic_pearson_correlation</td><td>0.09214</td></tr><tr><td>epoch/Output_PARA_aesthetic_root_mean_squared_error</td><td>0.57857</td></tr><tr><td>epoch/Output_SPAQ_quality_loss</td><td>0.87449</td></tr><tr><td>epoch/Output_SPAQ_quality_pearson_correlation</td><td>0.32263</td></tr><tr><td>epoch/Output_SPAQ_quality_root_mean_squared_error</td><td>0.93519</td></tr><tr><td>epoch/epoch</td><td>6</td></tr><tr><td>epoch/learning_rate</td><td>0.0005</td></tr><tr><td>epoch/loss</td><td>1.80501</td></tr><tr><td>epoch/val_Output_AVA_aesthetic_loss</td><td>0.21297</td></tr><tr><td>epoch/val_Output_AVA_aesthetic_pearson_correlation</td><td>0.01493</td></tr><tr><td>epoch/val_Output_AVA_aesthetic_root_mean_squared_error</td><td>0.46149</td></tr><tr><td>epoch/val_Output_KonIQ_quality_loss</td><td>0.26827</td></tr><tr><td>epoch/val_Output_KonIQ_quality_pearson_correlation</td><td>0.40439</td></tr><tr><td>epoch/val_Output_KonIQ_quality_root_mean_squared_error</td><td>0.51874</td></tr><tr><td>epoch/val_Output_PARA_aesthetic_loss</td><td>0.25193</td></tr><tr><td>epoch/val_Output_PARA_aesthetic_pearson_correlation</td><td>0.25103</td></tr><tr><td>epoch/val_Output_PARA_aesthetic_root_mean_squared_error</td><td>0.502</td></tr><tr><td>epoch/val_Output_SPAQ_quality_loss</td><td>0.43886</td></tr><tr><td>epoch/val_Output_SPAQ_quality_pearson_correlation</td><td>0.22131</td></tr><tr><td>epoch/val_Output_SPAQ_quality_root_mean_squared_error</td><td>0.66092</td></tr><tr><td>epoch/val_loss</td><td>1.17204</td></tr><tr><td>loss</td><td>1.80501</td></tr><tr><td>val_Output_AVA_aesthetic_loss</td><td>0.21297</td></tr><tr><td>val_Output_AVA_aesthetic_pearson_correlation</td><td>0.01493</td></tr><tr><td>val_Output_AVA_aesthetic_root_mean_squared_error</td><td>0.46149</td></tr><tr><td>val_Output_KonIQ_quality_loss</td><td>0.26827</td></tr><tr><td>val_Output_KonIQ_quality_pearson_correlation</td><td>0.40439</td></tr><tr><td>val_Output_KonIQ_quality_root_mean_squared_error</td><td>0.51874</td></tr><tr><td>val_Output_PARA_aesthetic_loss</td><td>0.25193</td></tr><tr><td>val_Output_PARA_aesthetic_pearson_correlation</td><td>0.25103</td></tr><tr><td>val_Output_PARA_aesthetic_root_mean_squared_error</td><td>0.502</td></tr><tr><td>val_Output_SPAQ_quality_loss</td><td>0.43886</td></tr><tr><td>val_Output_SPAQ_quality_pearson_correlation</td><td>0.22131</td></tr><tr><td>val_Output_SPAQ_quality_root_mean_squared_error</td><td>0.66092</td></tr><tr><td>val_loss</td><td>1.17204</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">easy-glade-8</strong> at: <a href='https://wandb.ai/ianchoo2000/multimodel_irnv2/runs/g7scrnqr' target=\"_blank\">https://wandb.ai/ianchoo2000/multimodel_irnv2/runs/g7scrnqr</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/media/workstation/BackupDrive/wandb_files/logs/wandb/run-20230709_032444-g7scrnqr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:g7scrnqr). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/workstation/BackupDrive/wandb_files/logs/wandb/run-20230709_040340-796hbia7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ianchoo2000/multimodel_irnv2/runs/796hbia7' target=\"_blank\">easy-flower-9</a></strong> to <a href='https://wandb.ai/ianchoo2000/multimodel_irnv2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ianchoo2000/multimodel_irnv2' target=\"_blank\">https://wandb.ai/ianchoo2000/multimodel_irnv2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ianchoo2000/multimodel_irnv2/runs/796hbia7' target=\"_blank\">https://wandb.ai/ianchoo2000/multimodel_irnv2/runs/796hbia7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"multimodel_irnv2\",\n",
    "    dir = \"/media/workstation/BackupDrive/wandb_files/logs\",\n",
    "\n",
    "    # track hyperparameters and run metadata with wandb.config\n",
    "    config={\n",
    "        \"fc1\" : 2048,\n",
    "        \"activation1\" : 'relu',\n",
    "        \"dropout1\": 0.25,\n",
    "        \"fc2\" : 1024,\n",
    "        \"activation2\" : 'relu',\n",
    "        \"dropout2\": 0.25,\n",
    "        \"fc3\" : 256,\n",
    "        \"activation3\" : 'relu',\n",
    "        \"dropout3\": 0.5,\n",
    "        \"fc4\" : 1,\n",
    "        \"activation4\" : 'linear',\n",
    "        \"dropout4\": 0,\n",
    "        \"learning_rate\" : 0.0005,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"loss\": \"mean_squared_error\",\n",
    "        \"metric\": \"root_mean_squared_error\",\n",
    "        \"epoch\": 100,\n",
    "        \"batch_size\": 16,\n",
    "        \"metric2\" : \"val_Output_KonIQ_quality_pearson_correlation\",\n",
    "        \"early_patience\" : 10,\n",
    "        \"early_mode\" : 'max',\n",
    "        \"early_min_delta\" : 0.001,\n",
    "        \"plateau_patience\" : 5,\n",
    "        \"plateau_mode\" : \"max\",\n",
    "        \"plateau_factor\" : 0.2,\n",
    "        \"plateau_min_lr\" : 0.000004,\n",
    "        \"plateau_min_delta\" : 0.01\n",
    "    }\n",
    ")\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# function to create outputs\n",
    "def configure_layers(input, name='Output normal'):\n",
    "    x = GlobalAveragePooling2D()(input)\n",
    "    x = Dense(config.fc1, activation=config.activation1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(config.dropout1)(x)\n",
    "\n",
    "    x = Dense(config.fc2, activation=config.activation2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(config.dropout2)(x)\n",
    "\n",
    "    x = Dense(config.fc3, activation=config.activation3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(config.dropout3)(x)\n",
    "\n",
    "    predictions = Dense(config.fc4, activation=config.activation4, name=name)(x)\n",
    "    return predictions\n",
    "\n",
    "# Create the input layers\n",
    "input_ava = Input(shape=(224, 224, 3), name='Input_AVA')\n",
    "input_para = Input(shape=(224, 224, 3), name='Input_PARA')\n",
    "input_koniq = Input(shape=(224, 224, 3), name='Input_KonIQ')\n",
    "input_spaq = Input(shape=(224, 224, 3), name='Input_SPAQ')\n",
    "\n",
    "# Create the output layers, include the input layers \n",
    "output_ava = configure_layers(base_model(input_ava), name='Output_AVA_aesthetic')\n",
    "output_para = configure_layers(base_model(input_para), name='Output_PARA_aesthetic')\n",
    "output_koniq = configure_layers(base_model(input_koniq), name='Output_KonIQ_quality')\n",
    "output_spaq = configure_layers(base_model(input_spaq), name='Output_SPAQ_quality')\n",
    "\n",
    "# Create the final model, include the multi-output\n",
    "model = Model(inputs=[input_ava, input_para, input_koniq, input_spaq], \n",
    "              outputs=[output_ava, output_para, output_koniq, output_spaq])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=config.learning_rate)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=config.loss,\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(), pearson_correlation]\n",
    "              )\n",
    "\n",
    "checkpoint_filepath = main_directory + 'multimodel_dataset/multimodel_checkpoint/'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor='val_Output_KonIQ_quality_pearson_correlation',\n",
    "    mode='min'\n",
    "    )\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor= config.metric2, \n",
    "    patience=config.early_patience,\n",
    "    mode=config.early_mode,\n",
    "    min_delta = config.early_min_delta\n",
    "    )\n",
    "\n",
    "reduce_lr_callback = ReduceLROnPlateau(\n",
    "    monitor = config.metric2,\n",
    "    factor = config.plateau_factor,\n",
    "    patience = config.plateau_patience,\n",
    "    mode = config.plateau_mode,\n",
    "    min_lr = config.plateau_min_lr\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 04:06:44.860312: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n",
      "2023-07-09 04:06:46.209174: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-07-09 04:06:46.226598: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-07-09 04:06:46.230055: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1246/1246 [==============================] - 1082s 827ms/step - loss: 11.8184 - Output_AVA_aesthetic_loss: 2.9066 - Output_PARA_aesthetic_loss: 2.9776 - Output_KonIQ_quality_loss: 2.9212 - Output_SPAQ_quality_loss: 3.0129 - Output_AVA_aesthetic_root_mean_squared_error: 1.7049 - Output_AVA_aesthetic_pearson_correlation: 0.0049 - Output_PARA_aesthetic_root_mean_squared_error: 1.7253 - Output_PARA_aesthetic_pearson_correlation: 0.0928 - Output_KonIQ_quality_root_mean_squared_error: 1.7100 - Output_KonIQ_quality_pearson_correlation: 0.1778 - Output_SPAQ_quality_root_mean_squared_error: 1.7354 - Output_SPAQ_quality_pearson_correlation: 0.3881 - val_loss: 1.2698 - val_Output_AVA_aesthetic_loss: 0.2507 - val_Output_PARA_aesthetic_loss: 0.2941 - val_Output_KonIQ_quality_loss: 0.2680 - val_Output_SPAQ_quality_loss: 0.4570 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.5007 - val_Output_AVA_aesthetic_pearson_correlation: 0.1054 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.5438 - val_Output_PARA_aesthetic_pearson_correlation: 0.3783 - val_Output_KonIQ_quality_root_mean_squared_error: 0.5165 - val_Output_KonIQ_quality_pearson_correlation: 0.5119 - val_Output_SPAQ_quality_root_mean_squared_error: 0.6757 - val_Output_SPAQ_quality_pearson_correlation: 0.7060 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "1246/1246 [==============================] - 1018s 817ms/step - loss: 3.2259 - Output_AVA_aesthetic_loss: 0.7791 - Output_PARA_aesthetic_loss: 0.7771 - Output_KonIQ_quality_loss: 0.7528 - Output_SPAQ_quality_loss: 0.9168 - Output_AVA_aesthetic_root_mean_squared_error: 0.8827 - Output_AVA_aesthetic_pearson_correlation: 0.0577 - Output_PARA_aesthetic_root_mean_squared_error: 0.8813 - Output_PARA_aesthetic_pearson_correlation: 0.2669 - Output_KonIQ_quality_root_mean_squared_error: 0.8667 - Output_KonIQ_quality_pearson_correlation: 0.3410 - Output_SPAQ_quality_root_mean_squared_error: 0.9573 - Output_SPAQ_quality_pearson_correlation: 0.6354 - val_loss: 0.9402 - val_Output_AVA_aesthetic_loss: 0.2227 - val_Output_PARA_aesthetic_loss: 0.1440 - val_Output_KonIQ_quality_loss: 0.1353 - val_Output_SPAQ_quality_loss: 0.4383 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4719 - val_Output_AVA_aesthetic_pearson_correlation: 0.2304 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.3794 - val_Output_PARA_aesthetic_pearson_correlation: 0.6504 - val_Output_KonIQ_quality_root_mean_squared_error: 0.3678 - val_Output_KonIQ_quality_pearson_correlation: 0.7435 - val_Output_SPAQ_quality_root_mean_squared_error: 0.6619 - val_Output_SPAQ_quality_pearson_correlation: 0.7181 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "1246/1246 [==============================] - 1021s 820ms/step - loss: 1.9810 - Output_AVA_aesthetic_loss: 0.4784 - Output_PARA_aesthetic_loss: 0.4480 - Output_KonIQ_quality_loss: 0.4485 - Output_SPAQ_quality_loss: 0.6062 - Output_AVA_aesthetic_root_mean_squared_error: 0.6916 - Output_AVA_aesthetic_pearson_correlation: 0.0916 - Output_PARA_aesthetic_root_mean_squared_error: 0.6693 - Output_PARA_aesthetic_pearson_correlation: 0.3877 - Output_KonIQ_quality_root_mean_squared_error: 0.6696 - Output_KonIQ_quality_pearson_correlation: 0.4634 - Output_SPAQ_quality_root_mean_squared_error: 0.7785 - Output_SPAQ_quality_pearson_correlation: 0.7248 - val_loss: 1.3883 - val_Output_AVA_aesthetic_loss: 0.1965 - val_Output_PARA_aesthetic_loss: 0.2707 - val_Output_KonIQ_quality_loss: 0.4958 - val_Output_SPAQ_quality_loss: 0.4252 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4432 - val_Output_AVA_aesthetic_pearson_correlation: 0.3484 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.5221 - val_Output_PARA_aesthetic_pearson_correlation: 0.5757 - val_Output_KonIQ_quality_root_mean_squared_error: 0.7041 - val_Output_KonIQ_quality_pearson_correlation: 0.4736 - val_Output_SPAQ_quality_root_mean_squared_error: 0.6520 - val_Output_SPAQ_quality_pearson_correlation: 0.7170 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "1246/1246 [==============================] - 1025s 823ms/step - loss: 1.4864 - Output_AVA_aesthetic_loss: 0.3541 - Output_PARA_aesthetic_loss: 0.3326 - Output_KonIQ_quality_loss: 0.3241 - Output_SPAQ_quality_loss: 0.4755 - Output_AVA_aesthetic_root_mean_squared_error: 0.5951 - Output_AVA_aesthetic_pearson_correlation: 0.1460 - Output_PARA_aesthetic_root_mean_squared_error: 0.5768 - Output_PARA_aesthetic_pearson_correlation: 0.4443 - Output_KonIQ_quality_root_mean_squared_error: 0.5696 - Output_KonIQ_quality_pearson_correlation: 0.5382 - Output_SPAQ_quality_root_mean_squared_error: 0.6895 - Output_SPAQ_quality_pearson_correlation: 0.7756 - val_loss: 1.0631 - val_Output_AVA_aesthetic_loss: 0.1788 - val_Output_PARA_aesthetic_loss: 0.1405 - val_Output_KonIQ_quality_loss: 0.1686 - val_Output_SPAQ_quality_loss: 0.5752 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4229 - val_Output_AVA_aesthetic_pearson_correlation: 0.3414 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.3752 - val_Output_PARA_aesthetic_pearson_correlation: 0.6952 - val_Output_KonIQ_quality_root_mean_squared_error: 0.4100 - val_Output_KonIQ_quality_pearson_correlation: 0.7478 - val_Output_SPAQ_quality_root_mean_squared_error: 0.7575 - val_Output_SPAQ_quality_pearson_correlation: 0.7061 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "1246/1246 [==============================] - 1015s 815ms/step - loss: 1.3307 - Output_AVA_aesthetic_loss: 0.3052 - Output_PARA_aesthetic_loss: 0.2934 - Output_KonIQ_quality_loss: 0.2920 - Output_SPAQ_quality_loss: 0.4401 - Output_AVA_aesthetic_root_mean_squared_error: 0.5525 - Output_AVA_aesthetic_pearson_correlation: 0.1127 - Output_PARA_aesthetic_root_mean_squared_error: 0.5417 - Output_PARA_aesthetic_pearson_correlation: 0.4186 - Output_KonIQ_quality_root_mean_squared_error: 0.5401 - Output_KonIQ_quality_pearson_correlation: 0.5226 - Output_SPAQ_quality_root_mean_squared_error: 0.6634 - Output_SPAQ_quality_pearson_correlation: 0.7794 - val_loss: 0.9889 - val_Output_AVA_aesthetic_loss: 0.1836 - val_Output_PARA_aesthetic_loss: 0.1698 - val_Output_KonIQ_quality_loss: 0.2388 - val_Output_SPAQ_quality_loss: 0.3968 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4285 - val_Output_AVA_aesthetic_pearson_correlation: 0.3166 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.4118 - val_Output_PARA_aesthetic_pearson_correlation: 0.5935 - val_Output_KonIQ_quality_root_mean_squared_error: 0.4891 - val_Output_KonIQ_quality_pearson_correlation: 0.6326 - val_Output_SPAQ_quality_root_mean_squared_error: 0.6291 - val_Output_SPAQ_quality_pearson_correlation: 0.7233 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "1246/1246 [==============================] - 1015s 815ms/step - loss: 1.1066 - Output_AVA_aesthetic_loss: 0.2592 - Output_PARA_aesthetic_loss: 0.2415 - Output_KonIQ_quality_loss: 0.2403 - Output_SPAQ_quality_loss: 0.3656 - Output_AVA_aesthetic_root_mean_squared_error: 0.5091 - Output_AVA_aesthetic_pearson_correlation: 0.1902 - Output_PARA_aesthetic_root_mean_squared_error: 0.4913 - Output_PARA_aesthetic_pearson_correlation: 0.5281 - Output_KonIQ_quality_root_mean_squared_error: 0.4904 - Output_KonIQ_quality_pearson_correlation: 0.6126 - Output_SPAQ_quality_root_mean_squared_error: 0.6046 - Output_SPAQ_quality_pearson_correlation: 0.8274 - val_loss: 0.8934 - val_Output_AVA_aesthetic_loss: 0.1696 - val_Output_PARA_aesthetic_loss: 0.1418 - val_Output_KonIQ_quality_loss: 0.1383 - val_Output_SPAQ_quality_loss: 0.4436 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4119 - val_Output_AVA_aesthetic_pearson_correlation: 0.3935 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.3759 - val_Output_PARA_aesthetic_pearson_correlation: 0.7053 - val_Output_KonIQ_quality_root_mean_squared_error: 0.3722 - val_Output_KonIQ_quality_pearson_correlation: 0.7534 - val_Output_SPAQ_quality_root_mean_squared_error: 0.6630 - val_Output_SPAQ_quality_pearson_correlation: 0.6847 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "1246/1246 [==============================] - 1015s 815ms/step - loss: 0.9717 - Output_AVA_aesthetic_loss: 0.2396 - Output_PARA_aesthetic_loss: 0.2003 - Output_KonIQ_quality_loss: 0.2075 - Output_SPAQ_quality_loss: 0.3244 - Output_AVA_aesthetic_root_mean_squared_error: 0.4895 - Output_AVA_aesthetic_pearson_correlation: 0.2258 - Output_PARA_aesthetic_root_mean_squared_error: 0.4475 - Output_PARA_aesthetic_pearson_correlation: 0.6063 - Output_KonIQ_quality_root_mean_squared_error: 0.4540 - Output_KonIQ_quality_pearson_correlation: 0.6680 - Output_SPAQ_quality_root_mean_squared_error: 0.5696 - Output_SPAQ_quality_pearson_correlation: 0.8518 - val_loss: 0.7494 - val_Output_AVA_aesthetic_loss: 0.2051 - val_Output_PARA_aesthetic_loss: 0.1020 - val_Output_KonIQ_quality_loss: 0.1105 - val_Output_SPAQ_quality_loss: 0.3318 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4529 - val_Output_AVA_aesthetic_pearson_correlation: 0.4213 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.3195 - val_Output_PARA_aesthetic_pearson_correlation: 0.7707 - val_Output_KonIQ_quality_root_mean_squared_error: 0.3334 - val_Output_KonIQ_quality_pearson_correlation: 0.7827 - val_Output_SPAQ_quality_root_mean_squared_error: 0.5764 - val_Output_SPAQ_quality_pearson_correlation: 0.7536 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "1246/1246 [==============================] - 1016s 815ms/step - loss: 0.8542 - Output_AVA_aesthetic_loss: 0.2152 - Output_PARA_aesthetic_loss: 0.1737 - Output_KonIQ_quality_loss: 0.1761 - Output_SPAQ_quality_loss: 0.2892 - Output_AVA_aesthetic_root_mean_squared_error: 0.4639 - Output_AVA_aesthetic_pearson_correlation: 0.2999 - Output_PARA_aesthetic_root_mean_squared_error: 0.4168 - Output_PARA_aesthetic_pearson_correlation: 0.6613 - Output_KonIQ_quality_root_mean_squared_error: 0.4196 - Output_KonIQ_quality_pearson_correlation: 0.7207 - Output_SPAQ_quality_root_mean_squared_error: 0.5377 - Output_SPAQ_quality_pearson_correlation: 0.8712 - val_loss: 1.0404 - val_Output_AVA_aesthetic_loss: 0.1987 - val_Output_PARA_aesthetic_loss: 0.1148 - val_Output_KonIQ_quality_loss: 0.1744 - val_Output_SPAQ_quality_loss: 0.5525 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4458 - val_Output_AVA_aesthetic_pearson_correlation: 0.4116 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.3385 - val_Output_PARA_aesthetic_pearson_correlation: 0.7350 - val_Output_KonIQ_quality_root_mean_squared_error: 0.4180 - val_Output_KonIQ_quality_pearson_correlation: 0.6906 - val_Output_SPAQ_quality_root_mean_squared_error: 0.7438 - val_Output_SPAQ_quality_pearson_correlation: 0.7440 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "1246/1246 [==============================] - 1016s 816ms/step - loss: 0.7958 - Output_AVA_aesthetic_loss: 0.2045 - Output_PARA_aesthetic_loss: 0.1577 - Output_KonIQ_quality_loss: 0.1620 - Output_SPAQ_quality_loss: 0.2716 - Output_AVA_aesthetic_root_mean_squared_error: 0.4522 - Output_AVA_aesthetic_pearson_correlation: 0.3225 - Output_PARA_aesthetic_root_mean_squared_error: 0.3972 - Output_PARA_aesthetic_pearson_correlation: 0.6904 - Output_KonIQ_quality_root_mean_squared_error: 0.4026 - Output_KonIQ_quality_pearson_correlation: 0.7457 - Output_SPAQ_quality_root_mean_squared_error: 0.5211 - Output_SPAQ_quality_pearson_correlation: 0.8809 - val_loss: 0.7834 - val_Output_AVA_aesthetic_loss: 0.1852 - val_Output_PARA_aesthetic_loss: 0.1134 - val_Output_KonIQ_quality_loss: 0.1607 - val_Output_SPAQ_quality_loss: 0.3240 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4304 - val_Output_AVA_aesthetic_pearson_correlation: 0.3835 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.3372 - val_Output_PARA_aesthetic_pearson_correlation: 0.7369 - val_Output_KonIQ_quality_root_mean_squared_error: 0.4018 - val_Output_KonIQ_quality_pearson_correlation: 0.7589 - val_Output_SPAQ_quality_root_mean_squared_error: 0.5691 - val_Output_SPAQ_quality_pearson_correlation: 0.7731 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "1246/1246 [==============================] - 1015s 815ms/step - loss: 0.7551 - Output_AVA_aesthetic_loss: 0.1965 - Output_PARA_aesthetic_loss: 0.1487 - Output_KonIQ_quality_loss: 0.1520 - Output_SPAQ_quality_loss: 0.2579 - Output_AVA_aesthetic_root_mean_squared_error: 0.4433 - Output_AVA_aesthetic_pearson_correlation: 0.3425 - Output_PARA_aesthetic_root_mean_squared_error: 0.3856 - Output_PARA_aesthetic_pearson_correlation: 0.7105 - Output_KonIQ_quality_root_mean_squared_error: 0.3894 - Output_KonIQ_quality_pearson_correlation: 0.7661 - Output_SPAQ_quality_root_mean_squared_error: 0.5079 - Output_SPAQ_quality_pearson_correlation: 0.8916 - val_loss: 0.8432 - val_Output_AVA_aesthetic_loss: 0.3222 - val_Output_PARA_aesthetic_loss: 0.1012 - val_Output_KonIQ_quality_loss: 0.1048 - val_Output_SPAQ_quality_loss: 0.3150 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.5676 - val_Output_AVA_aesthetic_pearson_correlation: 0.4035 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.3181 - val_Output_PARA_aesthetic_pearson_correlation: 0.7701 - val_Output_KonIQ_quality_root_mean_squared_error: 0.3237 - val_Output_KonIQ_quality_pearson_correlation: 0.8081 - val_Output_SPAQ_quality_root_mean_squared_error: 0.5623 - val_Output_SPAQ_quality_pearson_correlation: 0.7074 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "1246/1246 [==============================] - 1015s 815ms/step - loss: 0.6766 - Output_AVA_aesthetic_loss: 0.1820 - Output_PARA_aesthetic_loss: 0.1306 - Output_KonIQ_quality_loss: 0.1353 - Output_SPAQ_quality_loss: 0.2287 - Output_AVA_aesthetic_root_mean_squared_error: 0.4267 - Output_AVA_aesthetic_pearson_correlation: 0.4026 - Output_PARA_aesthetic_root_mean_squared_error: 0.3615 - Output_PARA_aesthetic_pearson_correlation: 0.7592 - Output_KonIQ_quality_root_mean_squared_error: 0.3677 - Output_KonIQ_quality_pearson_correlation: 0.7978 - Output_SPAQ_quality_root_mean_squared_error: 0.4783 - Output_SPAQ_quality_pearson_correlation: 0.9062 - val_loss: 0.6666 - val_Output_AVA_aesthetic_loss: 0.2162 - val_Output_PARA_aesthetic_loss: 0.0962 - val_Output_KonIQ_quality_loss: 0.0864 - val_Output_SPAQ_quality_loss: 0.2677 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4650 - val_Output_AVA_aesthetic_pearson_correlation: 0.4822 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.3105 - val_Output_PARA_aesthetic_pearson_correlation: 0.7889 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2944 - val_Output_KonIQ_quality_pearson_correlation: 0.8452 - val_Output_SPAQ_quality_root_mean_squared_error: 0.5171 - val_Output_SPAQ_quality_pearson_correlation: 0.7786 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "1246/1246 [==============================] - 1015s 814ms/step - loss: 0.6313 - Output_AVA_aesthetic_loss: 0.1759 - Output_PARA_aesthetic_loss: 0.1168 - Output_KonIQ_quality_loss: 0.1211 - Output_SPAQ_quality_loss: 0.2175 - Output_AVA_aesthetic_root_mean_squared_error: 0.4194 - Output_AVA_aesthetic_pearson_correlation: 0.4308 - Output_PARA_aesthetic_root_mean_squared_error: 0.3417 - Output_PARA_aesthetic_pearson_correlation: 0.7841 - Output_KonIQ_quality_root_mean_squared_error: 0.3481 - Output_KonIQ_quality_pearson_correlation: 0.8233 - Output_SPAQ_quality_root_mean_squared_error: 0.4664 - Output_SPAQ_quality_pearson_correlation: 0.9154 - val_loss: 0.7370 - val_Output_AVA_aesthetic_loss: 0.1625 - val_Output_PARA_aesthetic_loss: 0.0886 - val_Output_KonIQ_quality_loss: 0.0937 - val_Output_SPAQ_quality_loss: 0.3921 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4031 - val_Output_AVA_aesthetic_pearson_correlation: 0.4594 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2980 - val_Output_PARA_aesthetic_pearson_correlation: 0.7805 - val_Output_KonIQ_quality_root_mean_squared_error: 0.3060 - val_Output_KonIQ_quality_pearson_correlation: 0.8392 - val_Output_SPAQ_quality_root_mean_squared_error: 0.6256 - val_Output_SPAQ_quality_pearson_correlation: 0.7471 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "1246/1246 [==============================] - 1015s 815ms/step - loss: 0.5839 - Output_AVA_aesthetic_loss: 0.1679 - Output_PARA_aesthetic_loss: 0.1092 - Output_KonIQ_quality_loss: 0.1094 - Output_SPAQ_quality_loss: 0.1974 - Output_AVA_aesthetic_root_mean_squared_error: 0.4097 - Output_AVA_aesthetic_pearson_correlation: 0.4662 - Output_PARA_aesthetic_root_mean_squared_error: 0.3305 - Output_PARA_aesthetic_pearson_correlation: 0.8115 - Output_KonIQ_quality_root_mean_squared_error: 0.3305 - Output_KonIQ_quality_pearson_correlation: 0.8492 - Output_SPAQ_quality_root_mean_squared_error: 0.4443 - Output_SPAQ_quality_pearson_correlation: 0.9277 - val_loss: 0.6357 - val_Output_AVA_aesthetic_loss: 0.1623 - val_Output_PARA_aesthetic_loss: 0.0859 - val_Output_KonIQ_quality_loss: 0.0960 - val_Output_SPAQ_quality_loss: 0.2915 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4029 - val_Output_AVA_aesthetic_pearson_correlation: 0.4492 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2935 - val_Output_PARA_aesthetic_pearson_correlation: 0.7980 - val_Output_KonIQ_quality_root_mean_squared_error: 0.3092 - val_Output_KonIQ_quality_pearson_correlation: 0.8329 - val_Output_SPAQ_quality_root_mean_squared_error: 0.5390 - val_Output_SPAQ_quality_pearson_correlation: 0.7680 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "1246/1246 [==============================] - 1016s 815ms/step - loss: 0.5435 - Output_AVA_aesthetic_loss: 0.1623 - Output_PARA_aesthetic_loss: 0.0966 - Output_KonIQ_quality_loss: 0.0992 - Output_SPAQ_quality_loss: 0.1854 - Output_AVA_aesthetic_root_mean_squared_error: 0.4028 - Output_AVA_aesthetic_pearson_correlation: 0.4924 - Output_PARA_aesthetic_root_mean_squared_error: 0.3108 - Output_PARA_aesthetic_pearson_correlation: 0.8305 - Output_KonIQ_quality_root_mean_squared_error: 0.3135 - Output_KonIQ_quality_pearson_correlation: 0.8651 - Output_SPAQ_quality_root_mean_squared_error: 0.4306 - Output_SPAQ_quality_pearson_correlation: 0.9356 - val_loss: 0.7236 - val_Output_AVA_aesthetic_loss: 0.2121 - val_Output_PARA_aesthetic_loss: 0.1005 - val_Output_KonIQ_quality_loss: 0.0954 - val_Output_SPAQ_quality_loss: 0.3157 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4605 - val_Output_AVA_aesthetic_pearson_correlation: 0.4733 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.3171 - val_Output_PARA_aesthetic_pearson_correlation: 0.7923 - val_Output_KonIQ_quality_root_mean_squared_error: 0.3090 - val_Output_KonIQ_quality_pearson_correlation: 0.8084 - val_Output_SPAQ_quality_root_mean_squared_error: 0.5623 - val_Output_SPAQ_quality_pearson_correlation: 0.7596 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "1246/1246 [==============================] - 1014s 814ms/step - loss: 0.4794 - Output_AVA_aesthetic_loss: 0.1498 - Output_PARA_aesthetic_loss: 0.0836 - Output_KonIQ_quality_loss: 0.0826 - Output_SPAQ_quality_loss: 0.1634 - Output_AVA_aesthetic_root_mean_squared_error: 0.3870 - Output_AVA_aesthetic_pearson_correlation: 0.5495 - Output_PARA_aesthetic_root_mean_squared_error: 0.2891 - Output_PARA_aesthetic_pearson_correlation: 0.8681 - Output_KonIQ_quality_root_mean_squared_error: 0.2872 - Output_KonIQ_quality_pearson_correlation: 0.8923 - Output_SPAQ_quality_root_mean_squared_error: 0.4043 - Output_SPAQ_quality_pearson_correlation: 0.9467 - val_loss: 0.6831 - val_Output_AVA_aesthetic_loss: 0.1768 - val_Output_PARA_aesthetic_loss: 0.0917 - val_Output_KonIQ_quality_loss: 0.0960 - val_Output_SPAQ_quality_loss: 0.3186 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4205 - val_Output_AVA_aesthetic_pearson_correlation: 0.5180 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.3026 - val_Output_PARA_aesthetic_pearson_correlation: 0.7856 - val_Output_KonIQ_quality_root_mean_squared_error: 0.3102 - val_Output_KonIQ_quality_pearson_correlation: 0.8409 - val_Output_SPAQ_quality_root_mean_squared_error: 0.5648 - val_Output_SPAQ_quality_pearson_correlation: 0.7731 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "1246/1246 [==============================] - 1015s 815ms/step - loss: 0.4509 - Output_AVA_aesthetic_loss: 0.1376 - Output_PARA_aesthetic_loss: 0.0748 - Output_KonIQ_quality_loss: 0.0794 - Output_SPAQ_quality_loss: 0.1591 - Output_AVA_aesthetic_root_mean_squared_error: 0.3710 - Output_AVA_aesthetic_pearson_correlation: 0.5975 - Output_PARA_aesthetic_root_mean_squared_error: 0.2734 - Output_PARA_aesthetic_pearson_correlation: 0.8848 - Output_KonIQ_quality_root_mean_squared_error: 0.2807 - Output_KonIQ_quality_pearson_correlation: 0.9056 - Output_SPAQ_quality_root_mean_squared_error: 0.3990 - Output_SPAQ_quality_pearson_correlation: 0.9523 - val_loss: 0.8014 - val_Output_AVA_aesthetic_loss: 0.2064 - val_Output_PARA_aesthetic_loss: 0.1238 - val_Output_KonIQ_quality_loss: 0.0861 - val_Output_SPAQ_quality_loss: 0.3850 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4543 - val_Output_AVA_aesthetic_pearson_correlation: 0.4815 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.3512 - val_Output_PARA_aesthetic_pearson_correlation: 0.7871 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2933 - val_Output_KonIQ_quality_pearson_correlation: 0.8271 - val_Output_SPAQ_quality_root_mean_squared_error: 0.6201 - val_Output_SPAQ_quality_pearson_correlation: 0.7711 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "1246/1246 [==============================] - 1015s 814ms/step - loss: 0.3400 - Output_AVA_aesthetic_loss: 0.1032 - Output_PARA_aesthetic_loss: 0.0572 - Output_KonIQ_quality_loss: 0.0593 - Output_SPAQ_quality_loss: 0.1203 - Output_AVA_aesthetic_root_mean_squared_error: 0.3213 - Output_AVA_aesthetic_pearson_correlation: 0.7262 - Output_PARA_aesthetic_root_mean_squared_error: 0.2392 - Output_PARA_aesthetic_pearson_correlation: 0.9200 - Output_KonIQ_quality_root_mean_squared_error: 0.2425 - Output_KonIQ_quality_pearson_correlation: 0.9343 - Output_SPAQ_quality_root_mean_squared_error: 0.3468 - Output_SPAQ_quality_pearson_correlation: 0.9666 - val_loss: 0.5918 - val_Output_AVA_aesthetic_loss: 0.1773 - val_Output_PARA_aesthetic_loss: 0.0803 - val_Output_KonIQ_quality_loss: 0.0802 - val_Output_SPAQ_quality_loss: 0.2540 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4211 - val_Output_AVA_aesthetic_pearson_correlation: 0.5220 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2831 - val_Output_PARA_aesthetic_pearson_correlation: 0.7999 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2833 - val_Output_KonIQ_quality_pearson_correlation: 0.8501 - val_Output_SPAQ_quality_root_mean_squared_error: 0.5041 - val_Output_SPAQ_quality_pearson_correlation: 0.7751 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "1246/1246 [==============================] - 1013s 813ms/step - loss: 0.3052 - Output_AVA_aesthetic_loss: 0.0871 - Output_PARA_aesthetic_loss: 0.0494 - Output_KonIQ_quality_loss: 0.0543 - Output_SPAQ_quality_loss: 0.1144 - Output_AVA_aesthetic_root_mean_squared_error: 0.2952 - Output_AVA_aesthetic_pearson_correlation: 0.7900 - Output_PARA_aesthetic_root_mean_squared_error: 0.2223 - Output_PARA_aesthetic_pearson_correlation: 0.9355 - Output_KonIQ_quality_root_mean_squared_error: 0.2311 - Output_KonIQ_quality_pearson_correlation: 0.9426 - Output_SPAQ_quality_root_mean_squared_error: 0.3381 - Output_SPAQ_quality_pearson_correlation: 0.9720 - val_loss: 0.5921 - val_Output_AVA_aesthetic_loss: 0.2227 - val_Output_PARA_aesthetic_loss: 0.0767 - val_Output_KonIQ_quality_loss: 0.0791 - val_Output_SPAQ_quality_loss: 0.2136 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4719 - val_Output_AVA_aesthetic_pearson_correlation: 0.5165 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2770 - val_Output_PARA_aesthetic_pearson_correlation: 0.8152 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2813 - val_Output_KonIQ_quality_pearson_correlation: 0.8458 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4621 - val_Output_SPAQ_quality_pearson_correlation: 0.8075 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "1246/1246 [==============================] - 1013s 813ms/step - loss: 0.2810 - Output_AVA_aesthetic_loss: 0.0762 - Output_PARA_aesthetic_loss: 0.0484 - Output_KonIQ_quality_loss: 0.0499 - Output_SPAQ_quality_loss: 0.1065 - Output_AVA_aesthetic_root_mean_squared_error: 0.2760 - Output_AVA_aesthetic_pearson_correlation: 0.8254 - Output_PARA_aesthetic_root_mean_squared_error: 0.2198 - Output_PARA_aesthetic_pearson_correlation: 0.9404 - Output_KonIQ_quality_root_mean_squared_error: 0.2225 - Output_KonIQ_quality_pearson_correlation: 0.9485 - Output_SPAQ_quality_root_mean_squared_error: 0.3263 - Output_SPAQ_quality_pearson_correlation: 0.9759 - val_loss: 0.5533 - val_Output_AVA_aesthetic_loss: 0.2038 - val_Output_PARA_aesthetic_loss: 0.0858 - val_Output_KonIQ_quality_loss: 0.0750 - val_Output_SPAQ_quality_loss: 0.1888 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4514 - val_Output_AVA_aesthetic_pearson_correlation: 0.4805 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2929 - val_Output_PARA_aesthetic_pearson_correlation: 0.7981 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2737 - val_Output_KonIQ_quality_pearson_correlation: 0.8566 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4347 - val_Output_SPAQ_quality_pearson_correlation: 0.7920 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "1246/1246 [==============================] - 1012s 813ms/step - loss: 0.2684 - Output_AVA_aesthetic_loss: 0.0654 - Output_PARA_aesthetic_loss: 0.0451 - Output_KonIQ_quality_loss: 0.0495 - Output_SPAQ_quality_loss: 0.1083 - Output_AVA_aesthetic_root_mean_squared_error: 0.2558 - Output_AVA_aesthetic_pearson_correlation: 0.8579 - Output_PARA_aesthetic_root_mean_squared_error: 0.2124 - Output_PARA_aesthetic_pearson_correlation: 0.9461 - Output_KonIQ_quality_root_mean_squared_error: 0.2224 - Output_KonIQ_quality_pearson_correlation: 0.9496 - Output_SPAQ_quality_root_mean_squared_error: 0.3291 - Output_SPAQ_quality_pearson_correlation: 0.9765 - val_loss: 0.5964 - val_Output_AVA_aesthetic_loss: 0.1987 - val_Output_PARA_aesthetic_loss: 0.0849 - val_Output_KonIQ_quality_loss: 0.0779 - val_Output_SPAQ_quality_loss: 0.2349 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4458 - val_Output_AVA_aesthetic_pearson_correlation: 0.4940 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2915 - val_Output_PARA_aesthetic_pearson_correlation: 0.8136 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2793 - val_Output_KonIQ_quality_pearson_correlation: 0.8519 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4844 - val_Output_SPAQ_quality_pearson_correlation: 0.7922 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "1246/1246 [==============================] - 1013s 813ms/step - loss: 0.2563 - Output_AVA_aesthetic_loss: 0.0607 - Output_PARA_aesthetic_loss: 0.0429 - Output_KonIQ_quality_loss: 0.0469 - Output_SPAQ_quality_loss: 0.1058 - Output_AVA_aesthetic_root_mean_squared_error: 0.2463 - Output_AVA_aesthetic_pearson_correlation: 0.8768 - Output_PARA_aesthetic_root_mean_squared_error: 0.2072 - Output_PARA_aesthetic_pearson_correlation: 0.9488 - Output_KonIQ_quality_root_mean_squared_error: 0.2150 - Output_KonIQ_quality_pearson_correlation: 0.9527 - Output_SPAQ_quality_root_mean_squared_error: 0.3252 - Output_SPAQ_quality_pearson_correlation: 0.9778 - val_loss: 0.6374 - val_Output_AVA_aesthetic_loss: 0.2447 - val_Output_PARA_aesthetic_loss: 0.0805 - val_Output_KonIQ_quality_loss: 0.0821 - val_Output_SPAQ_quality_loss: 0.2301 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4947 - val_Output_AVA_aesthetic_pearson_correlation: 0.4730 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2841 - val_Output_PARA_aesthetic_pearson_correlation: 0.8160 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2866 - val_Output_KonIQ_quality_pearson_correlation: 0.8541 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4796 - val_Output_SPAQ_quality_pearson_correlation: 0.7807 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "1246/1246 [==============================] - 1013s 813ms/step - loss: 0.2468 - Output_AVA_aesthetic_loss: 0.0541 - Output_PARA_aesthetic_loss: 0.0446 - Output_KonIQ_quality_loss: 0.0478 - Output_SPAQ_quality_loss: 0.1003 - Output_AVA_aesthetic_root_mean_squared_error: 0.2326 - Output_AVA_aesthetic_pearson_correlation: 0.8921 - Output_PARA_aesthetic_root_mean_squared_error: 0.2112 - Output_PARA_aesthetic_pearson_correlation: 0.9489 - Output_KonIQ_quality_root_mean_squared_error: 0.2177 - Output_KonIQ_quality_pearson_correlation: 0.9546 - Output_SPAQ_quality_root_mean_squared_error: 0.3166 - Output_SPAQ_quality_pearson_correlation: 0.9790 - val_loss: 0.5933 - val_Output_AVA_aesthetic_loss: 0.2267 - val_Output_PARA_aesthetic_loss: 0.0840 - val_Output_KonIQ_quality_loss: 0.0800 - val_Output_SPAQ_quality_loss: 0.2027 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4761 - val_Output_AVA_aesthetic_pearson_correlation: 0.5001 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2894 - val_Output_PARA_aesthetic_pearson_correlation: 0.8009 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2833 - val_Output_KonIQ_quality_pearson_correlation: 0.8561 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4508 - val_Output_SPAQ_quality_pearson_correlation: 0.7762 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "1246/1246 [==============================] - 1013s 813ms/step - loss: 0.2369 - Output_AVA_aesthetic_loss: 0.0506 - Output_PARA_aesthetic_loss: 0.0411 - Output_KonIQ_quality_loss: 0.0457 - Output_SPAQ_quality_loss: 0.0994 - Output_AVA_aesthetic_root_mean_squared_error: 0.2249 - Output_AVA_aesthetic_pearson_correlation: 0.9054 - Output_PARA_aesthetic_root_mean_squared_error: 0.2028 - Output_PARA_aesthetic_pearson_correlation: 0.9522 - Output_KonIQ_quality_root_mean_squared_error: 0.2136 - Output_KonIQ_quality_pearson_correlation: 0.9580 - Output_SPAQ_quality_root_mean_squared_error: 0.3153 - Output_SPAQ_quality_pearson_correlation: 0.9798 - val_loss: 0.5756 - val_Output_AVA_aesthetic_loss: 0.1937 - val_Output_PARA_aesthetic_loss: 0.0906 - val_Output_KonIQ_quality_loss: 0.0809 - val_Output_SPAQ_quality_loss: 0.2104 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4401 - val_Output_AVA_aesthetic_pearson_correlation: 0.5010 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.3002 - val_Output_PARA_aesthetic_pearson_correlation: 0.7858 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2840 - val_Output_KonIQ_quality_pearson_correlation: 0.8545 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4593 - val_Output_SPAQ_quality_pearson_correlation: 0.7884 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "1246/1246 [==============================] - 1006s 808ms/step - loss: 0.2361 - Output_AVA_aesthetic_loss: 0.0496 - Output_PARA_aesthetic_loss: 0.0417 - Output_KonIQ_quality_loss: 0.0447 - Output_SPAQ_quality_loss: 0.1003 - Output_AVA_aesthetic_root_mean_squared_error: 0.2226 - Output_AVA_aesthetic_pearson_correlation: 0.9104 - Output_PARA_aesthetic_root_mean_squared_error: 0.2041 - Output_PARA_aesthetic_pearson_correlation: 0.9539 - Output_KonIQ_quality_root_mean_squared_error: 0.2108 - Output_KonIQ_quality_pearson_correlation: 0.9605 - Output_SPAQ_quality_root_mean_squared_error: 0.3166 - Output_SPAQ_quality_pearson_correlation: 0.9802 - val_loss: 0.5898 - val_Output_AVA_aesthetic_loss: 0.2076 - val_Output_PARA_aesthetic_loss: 0.0801 - val_Output_KonIQ_quality_loss: 0.0767 - val_Output_SPAQ_quality_loss: 0.2254 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4556 - val_Output_AVA_aesthetic_pearson_correlation: 0.4926 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2828 - val_Output_PARA_aesthetic_pearson_correlation: 0.8191 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2771 - val_Output_KonIQ_quality_pearson_correlation: 0.8595 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4744 - val_Output_SPAQ_quality_pearson_correlation: 0.7874 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "1246/1246 [==============================] - 1004s 806ms/step - loss: 0.2316 - Output_AVA_aesthetic_loss: 0.0474 - Output_PARA_aesthetic_loss: 0.0415 - Output_KonIQ_quality_loss: 0.0440 - Output_SPAQ_quality_loss: 0.0987 - Output_AVA_aesthetic_root_mean_squared_error: 0.2178 - Output_AVA_aesthetic_pearson_correlation: 0.9145 - Output_PARA_aesthetic_root_mean_squared_error: 0.2037 - Output_PARA_aesthetic_pearson_correlation: 0.9541 - Output_KonIQ_quality_root_mean_squared_error: 0.2085 - Output_KonIQ_quality_pearson_correlation: 0.9585 - Output_SPAQ_quality_root_mean_squared_error: 0.3142 - Output_SPAQ_quality_pearson_correlation: 0.9805 - val_loss: 0.5552 - val_Output_AVA_aesthetic_loss: 0.2201 - val_Output_PARA_aesthetic_loss: 0.0777 - val_Output_KonIQ_quality_loss: 0.0847 - val_Output_SPAQ_quality_loss: 0.1727 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4692 - val_Output_AVA_aesthetic_pearson_correlation: 0.4916 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2784 - val_Output_PARA_aesthetic_pearson_correlation: 0.7991 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2912 - val_Output_KonIQ_quality_pearson_correlation: 0.8456 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4143 - val_Output_SPAQ_quality_pearson_correlation: 0.7774 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "1246/1246 [==============================] - 1004s 806ms/step - loss: 0.2292 - Output_AVA_aesthetic_loss: 0.0449 - Output_PARA_aesthetic_loss: 0.0417 - Output_KonIQ_quality_loss: 0.0436 - Output_SPAQ_quality_loss: 0.0989 - Output_AVA_aesthetic_root_mean_squared_error: 0.2120 - Output_AVA_aesthetic_pearson_correlation: 0.9196 - Output_PARA_aesthetic_root_mean_squared_error: 0.2043 - Output_PARA_aesthetic_pearson_correlation: 0.9548 - Output_KonIQ_quality_root_mean_squared_error: 0.2084 - Output_KonIQ_quality_pearson_correlation: 0.9588 - Output_SPAQ_quality_root_mean_squared_error: 0.3145 - Output_SPAQ_quality_pearson_correlation: 0.9804 - val_loss: 0.6021 - val_Output_AVA_aesthetic_loss: 0.2214 - val_Output_PARA_aesthetic_loss: 0.0772 - val_Output_KonIQ_quality_loss: 0.0813 - val_Output_SPAQ_quality_loss: 0.2221 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4705 - val_Output_AVA_aesthetic_pearson_correlation: 0.4759 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2777 - val_Output_PARA_aesthetic_pearson_correlation: 0.8181 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2849 - val_Output_KonIQ_quality_pearson_correlation: 0.8416 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4711 - val_Output_SPAQ_quality_pearson_correlation: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "1246/1246 [==============================] - 1011s 811ms/step - loss: 0.2302 - Output_AVA_aesthetic_loss: 0.0454 - Output_PARA_aesthetic_loss: 0.0402 - Output_KonIQ_quality_loss: 0.0435 - Output_SPAQ_quality_loss: 0.1010 - Output_AVA_aesthetic_root_mean_squared_error: 0.2131 - Output_AVA_aesthetic_pearson_correlation: 0.9189 - Output_PARA_aesthetic_root_mean_squared_error: 0.2005 - Output_PARA_aesthetic_pearson_correlation: 0.9552 - Output_KonIQ_quality_root_mean_squared_error: 0.2072 - Output_KonIQ_quality_pearson_correlation: 0.9606 - Output_SPAQ_quality_root_mean_squared_error: 0.3178 - Output_SPAQ_quality_pearson_correlation: 0.9809 - val_loss: 0.5635 - val_Output_AVA_aesthetic_loss: 0.2052 - val_Output_PARA_aesthetic_loss: 0.0783 - val_Output_KonIQ_quality_loss: 0.0798 - val_Output_SPAQ_quality_loss: 0.2003 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4530 - val_Output_AVA_aesthetic_pearson_correlation: 0.4790 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2794 - val_Output_PARA_aesthetic_pearson_correlation: 0.8104 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2827 - val_Output_KonIQ_quality_pearson_correlation: 0.8526 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4479 - val_Output_SPAQ_quality_pearson_correlation: 0.7734 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "1246/1246 [==============================] - 1014s 814ms/step - loss: 0.2243 - Output_AVA_aesthetic_loss: 0.0435 - Output_PARA_aesthetic_loss: 0.0385 - Output_KonIQ_quality_loss: 0.0435 - Output_SPAQ_quality_loss: 0.0987 - Output_AVA_aesthetic_root_mean_squared_error: 0.2087 - Output_AVA_aesthetic_pearson_correlation: 0.9245 - Output_PARA_aesthetic_root_mean_squared_error: 0.1963 - Output_PARA_aesthetic_pearson_correlation: 0.9573 - Output_KonIQ_quality_root_mean_squared_error: 0.2075 - Output_KonIQ_quality_pearson_correlation: 0.9630 - Output_SPAQ_quality_root_mean_squared_error: 0.3141 - Output_SPAQ_quality_pearson_correlation: 0.9814 - val_loss: 0.5599 - val_Output_AVA_aesthetic_loss: 0.2031 - val_Output_PARA_aesthetic_loss: 0.0802 - val_Output_KonIQ_quality_loss: 0.0853 - val_Output_SPAQ_quality_loss: 0.1913 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4507 - val_Output_AVA_aesthetic_pearson_correlation: 0.4878 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2832 - val_Output_PARA_aesthetic_pearson_correlation: 0.8117 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2917 - val_Output_KonIQ_quality_pearson_correlation: 0.8534 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4375 - val_Output_SPAQ_quality_pearson_correlation: 0.8017 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "1246/1246 [==============================] - 1014s 813ms/step - loss: 0.2188 - Output_AVA_aesthetic_loss: 0.0412 - Output_PARA_aesthetic_loss: 0.0390 - Output_KonIQ_quality_loss: 0.0423 - Output_SPAQ_quality_loss: 0.0963 - Output_AVA_aesthetic_root_mean_squared_error: 0.2030 - Output_AVA_aesthetic_pearson_correlation: 0.9271 - Output_PARA_aesthetic_root_mean_squared_error: 0.1976 - Output_PARA_aesthetic_pearson_correlation: 0.9578 - Output_KonIQ_quality_root_mean_squared_error: 0.2054 - Output_KonIQ_quality_pearson_correlation: 0.9629 - Output_SPAQ_quality_root_mean_squared_error: 0.3102 - Output_SPAQ_quality_pearson_correlation: 0.9817 - val_loss: 0.5918 - val_Output_AVA_aesthetic_loss: 0.2528 - val_Output_PARA_aesthetic_loss: 0.0784 - val_Output_KonIQ_quality_loss: 0.0812 - val_Output_SPAQ_quality_loss: 0.1794 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.5027 - val_Output_AVA_aesthetic_pearson_correlation: 0.4965 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2808 - val_Output_PARA_aesthetic_pearson_correlation: 0.8187 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2856 - val_Output_KonIQ_quality_pearson_correlation: 0.8460 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4239 - val_Output_SPAQ_quality_pearson_correlation: 0.7901 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "1246/1246 [==============================] - 1013s 813ms/step - loss: 0.2098 - Output_AVA_aesthetic_loss: 0.0371 - Output_PARA_aesthetic_loss: 0.0385 - Output_KonIQ_quality_loss: 0.0405 - Output_SPAQ_quality_loss: 0.0937 - Output_AVA_aesthetic_root_mean_squared_error: 0.1926 - Output_AVA_aesthetic_pearson_correlation: 0.9358 - Output_PARA_aesthetic_root_mean_squared_error: 0.1962 - Output_PARA_aesthetic_pearson_correlation: 0.9599 - Output_KonIQ_quality_root_mean_squared_error: 0.2010 - Output_KonIQ_quality_pearson_correlation: 0.9629 - Output_SPAQ_quality_root_mean_squared_error: 0.3062 - Output_SPAQ_quality_pearson_correlation: 0.9827 - val_loss: 0.5566 - val_Output_AVA_aesthetic_loss: 0.1986 - val_Output_PARA_aesthetic_loss: 0.0794 - val_Output_KonIQ_quality_loss: 0.0826 - val_Output_SPAQ_quality_loss: 0.1960 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4457 - val_Output_AVA_aesthetic_pearson_correlation: 0.5012 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2817 - val_Output_PARA_aesthetic_pearson_correlation: 0.8048 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2874 - val_Output_KonIQ_quality_pearson_correlation: 0.8503 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4430 - val_Output_SPAQ_quality_pearson_correlation: 0.7898 - lr: 2.0000e-05\n",
      "Epoch 31/100\n",
      "1246/1246 [==============================] - 1005s 807ms/step - loss: 0.2041 - Output_AVA_aesthetic_loss: 0.0374 - Output_PARA_aesthetic_loss: 0.0353 - Output_KonIQ_quality_loss: 0.0401 - Output_SPAQ_quality_loss: 0.0913 - Output_AVA_aesthetic_root_mean_squared_error: 0.1933 - Output_AVA_aesthetic_pearson_correlation: 0.9382 - Output_PARA_aesthetic_root_mean_squared_error: 0.1877 - Output_PARA_aesthetic_pearson_correlation: 0.9620 - Output_KonIQ_quality_root_mean_squared_error: 0.1987 - Output_KonIQ_quality_pearson_correlation: 0.9639 - Output_SPAQ_quality_root_mean_squared_error: 0.3023 - Output_SPAQ_quality_pearson_correlation: 0.9835 - val_loss: 0.5742 - val_Output_AVA_aesthetic_loss: 0.2259 - val_Output_PARA_aesthetic_loss: 0.0762 - val_Output_KonIQ_quality_loss: 0.0794 - val_Output_SPAQ_quality_loss: 0.1927 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4753 - val_Output_AVA_aesthetic_pearson_correlation: 0.5110 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2767 - val_Output_PARA_aesthetic_pearson_correlation: 0.8150 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2819 - val_Output_KonIQ_quality_pearson_correlation: 0.8562 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4390 - val_Output_SPAQ_quality_pearson_correlation: 0.7907 - lr: 2.0000e-05\n",
      "Epoch 32/100\n",
      "1246/1246 [==============================] - 1006s 807ms/step - loss: 0.2058 - Output_AVA_aesthetic_loss: 0.0360 - Output_PARA_aesthetic_loss: 0.0364 - Output_KonIQ_quality_loss: 0.0402 - Output_SPAQ_quality_loss: 0.0931 - Output_AVA_aesthetic_root_mean_squared_error: 0.1898 - Output_AVA_aesthetic_pearson_correlation: 0.9420 - Output_PARA_aesthetic_root_mean_squared_error: 0.1908 - Output_PARA_aesthetic_pearson_correlation: 0.9622 - Output_KonIQ_quality_root_mean_squared_error: 0.1988 - Output_KonIQ_quality_pearson_correlation: 0.9669 - Output_SPAQ_quality_root_mean_squared_error: 0.3050 - Output_SPAQ_quality_pearson_correlation: 0.9837 - val_loss: 0.5510 - val_Output_AVA_aesthetic_loss: 0.2106 - val_Output_PARA_aesthetic_loss: 0.0788 - val_Output_KonIQ_quality_loss: 0.0779 - val_Output_SPAQ_quality_loss: 0.1837 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4589 - val_Output_AVA_aesthetic_pearson_correlation: 0.4869 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2807 - val_Output_PARA_aesthetic_pearson_correlation: 0.8089 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2785 - val_Output_KonIQ_quality_pearson_correlation: 0.8486 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4273 - val_Output_SPAQ_quality_pearson_correlation: 0.7961 - lr: 2.0000e-05\n",
      "Epoch 33/100\n",
      "1246/1246 [==============================] - 1005s 807ms/step - loss: 0.2032 - Output_AVA_aesthetic_loss: 0.0353 - Output_PARA_aesthetic_loss: 0.0364 - Output_KonIQ_quality_loss: 0.0396 - Output_SPAQ_quality_loss: 0.0918 - Output_AVA_aesthetic_root_mean_squared_error: 0.1880 - Output_AVA_aesthetic_pearson_correlation: 0.9432 - Output_PARA_aesthetic_root_mean_squared_error: 0.1906 - Output_PARA_aesthetic_pearson_correlation: 0.9624 - Output_KonIQ_quality_root_mean_squared_error: 0.1979 - Output_KonIQ_quality_pearson_correlation: 0.9647 - Output_SPAQ_quality_root_mean_squared_error: 0.3030 - Output_SPAQ_quality_pearson_correlation: 0.9840 - val_loss: 0.5629 - val_Output_AVA_aesthetic_loss: 0.2083 - val_Output_PARA_aesthetic_loss: 0.0784 - val_Output_KonIQ_quality_loss: 0.0794 - val_Output_SPAQ_quality_loss: 0.1967 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4564 - val_Output_AVA_aesthetic_pearson_correlation: 0.5088 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2803 - val_Output_PARA_aesthetic_pearson_correlation: 0.8203 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2817 - val_Output_KonIQ_quality_pearson_correlation: 0.8524 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4429 - val_Output_SPAQ_quality_pearson_correlation: 0.7803 - lr: 2.0000e-05\n",
      "Epoch 34/100\n",
      "1246/1246 [==============================] - 1012s 812ms/step - loss: 0.2029 - Output_AVA_aesthetic_loss: 0.0351 - Output_PARA_aesthetic_loss: 0.0366 - Output_KonIQ_quality_loss: 0.0379 - Output_SPAQ_quality_loss: 0.0934 - Output_AVA_aesthetic_root_mean_squared_error: 0.1873 - Output_AVA_aesthetic_pearson_correlation: 0.9449 - Output_PARA_aesthetic_root_mean_squared_error: 0.1912 - Output_PARA_aesthetic_pearson_correlation: 0.9623 - Output_KonIQ_quality_root_mean_squared_error: 0.1932 - Output_KonIQ_quality_pearson_correlation: 0.9679 - Output_SPAQ_quality_root_mean_squared_error: 0.3056 - Output_SPAQ_quality_pearson_correlation: 0.9840 - val_loss: 0.5773 - val_Output_AVA_aesthetic_loss: 0.2176 - val_Output_PARA_aesthetic_loss: 0.0815 - val_Output_KonIQ_quality_loss: 0.0820 - val_Output_SPAQ_quality_loss: 0.1961 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4665 - val_Output_AVA_aesthetic_pearson_correlation: 0.4969 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2855 - val_Output_PARA_aesthetic_pearson_correlation: 0.8085 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2866 - val_Output_KonIQ_quality_pearson_correlation: 0.8559 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4431 - val_Output_SPAQ_quality_pearson_correlation: 0.7879 - lr: 2.0000e-05\n",
      "Epoch 35/100\n",
      "1246/1246 [==============================] - 1014s 814ms/step - loss: 0.2010 - Output_AVA_aesthetic_loss: 0.0338 - Output_PARA_aesthetic_loss: 0.0371 - Output_KonIQ_quality_loss: 0.0393 - Output_SPAQ_quality_loss: 0.0908 - Output_AVA_aesthetic_root_mean_squared_error: 0.1838 - Output_AVA_aesthetic_pearson_correlation: 0.9473 - Output_PARA_aesthetic_root_mean_squared_error: 0.1926 - Output_PARA_aesthetic_pearson_correlation: 0.9628 - Output_KonIQ_quality_root_mean_squared_error: 0.1964 - Output_KonIQ_quality_pearson_correlation: 0.9662 - Output_SPAQ_quality_root_mean_squared_error: 0.3013 - Output_SPAQ_quality_pearson_correlation: 0.9844 - val_loss: 0.5473 - val_Output_AVA_aesthetic_loss: 0.2067 - val_Output_PARA_aesthetic_loss: 0.0785 - val_Output_KonIQ_quality_loss: 0.0787 - val_Output_SPAQ_quality_loss: 0.1834 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4547 - val_Output_AVA_aesthetic_pearson_correlation: 0.5113 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2807 - val_Output_PARA_aesthetic_pearson_correlation: 0.8166 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2798 - val_Output_KonIQ_quality_pearson_correlation: 0.8586 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4287 - val_Output_SPAQ_quality_pearson_correlation: 0.7905 - lr: 4.0000e-06\n",
      "Epoch 36/100\n",
      "1246/1246 [==============================] - 1013s 813ms/step - loss: 0.1957 - Output_AVA_aesthetic_loss: 0.0335 - Output_PARA_aesthetic_loss: 0.0363 - Output_KonIQ_quality_loss: 0.0385 - Output_SPAQ_quality_loss: 0.0874 - Output_AVA_aesthetic_root_mean_squared_error: 0.1829 - Output_AVA_aesthetic_pearson_correlation: 0.9477 - Output_PARA_aesthetic_root_mean_squared_error: 0.1904 - Output_PARA_aesthetic_pearson_correlation: 0.9641 - Output_KonIQ_quality_root_mean_squared_error: 0.1947 - Output_KonIQ_quality_pearson_correlation: 0.9673 - Output_SPAQ_quality_root_mean_squared_error: 0.2957 - Output_SPAQ_quality_pearson_correlation: 0.9846 - val_loss: 0.5761 - val_Output_AVA_aesthetic_loss: 0.2252 - val_Output_PARA_aesthetic_loss: 0.0790 - val_Output_KonIQ_quality_loss: 0.0794 - val_Output_SPAQ_quality_loss: 0.1924 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4746 - val_Output_AVA_aesthetic_pearson_correlation: 0.4819 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2806 - val_Output_PARA_aesthetic_pearson_correlation: 0.8026 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2818 - val_Output_KonIQ_quality_pearson_correlation: 0.8579 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4389 - val_Output_SPAQ_quality_pearson_correlation: 0.7910 - lr: 4.0000e-06\n",
      "Epoch 37/100\n",
      "1246/1246 [==============================] - 1014s 814ms/step - loss: 0.1958 - Output_AVA_aesthetic_loss: 0.0342 - Output_PARA_aesthetic_loss: 0.0351 - Output_KonIQ_quality_loss: 0.0376 - Output_SPAQ_quality_loss: 0.0890 - Output_AVA_aesthetic_root_mean_squared_error: 0.1848 - Output_AVA_aesthetic_pearson_correlation: 0.9479 - Output_PARA_aesthetic_root_mean_squared_error: 0.1872 - Output_PARA_aesthetic_pearson_correlation: 0.9638 - Output_KonIQ_quality_root_mean_squared_error: 0.1918 - Output_KonIQ_quality_pearson_correlation: 0.9682 - Output_SPAQ_quality_root_mean_squared_error: 0.2988 - Output_SPAQ_quality_pearson_correlation: 0.9846 - val_loss: 0.5750 - val_Output_AVA_aesthetic_loss: 0.2151 - val_Output_PARA_aesthetic_loss: 0.0788 - val_Output_KonIQ_quality_loss: 0.0793 - val_Output_SPAQ_quality_loss: 0.2018 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4638 - val_Output_AVA_aesthetic_pearson_correlation: 0.5124 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2804 - val_Output_PARA_aesthetic_pearson_correlation: 0.8134 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2821 - val_Output_KonIQ_quality_pearson_correlation: 0.8604 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4494 - val_Output_SPAQ_quality_pearson_correlation: 0.7792 - lr: 4.0000e-06\n",
      "Epoch 38/100\n",
      "1246/1246 [==============================] - 1013s 813ms/step - loss: 0.1989 - Output_AVA_aesthetic_loss: 0.0331 - Output_PARA_aesthetic_loss: 0.0354 - Output_KonIQ_quality_loss: 0.0390 - Output_SPAQ_quality_loss: 0.0914 - Output_AVA_aesthetic_root_mean_squared_error: 0.1819 - Output_AVA_aesthetic_pearson_correlation: 0.9490 - Output_PARA_aesthetic_root_mean_squared_error: 0.1882 - Output_PARA_aesthetic_pearson_correlation: 0.9642 - Output_KonIQ_quality_root_mean_squared_error: 0.1973 - Output_KonIQ_quality_pearson_correlation: 0.9669 - Output_SPAQ_quality_root_mean_squared_error: 0.3024 - Output_SPAQ_quality_pearson_correlation: 0.9845 - val_loss: 0.5596 - val_Output_AVA_aesthetic_loss: 0.2134 - val_Output_PARA_aesthetic_loss: 0.0785 - val_Output_KonIQ_quality_loss: 0.0803 - val_Output_SPAQ_quality_loss: 0.1874 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4619 - val_Output_AVA_aesthetic_pearson_correlation: 0.4925 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2801 - val_Output_PARA_aesthetic_pearson_correlation: 0.8143 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2837 - val_Output_KonIQ_quality_pearson_correlation: 0.8456 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4333 - val_Output_SPAQ_quality_pearson_correlation: 0.7937 - lr: 4.0000e-06\n",
      "Epoch 39/100\n",
      "1246/1246 [==============================] - 1012s 813ms/step - loss: 0.1964 - Output_AVA_aesthetic_loss: 0.0323 - Output_PARA_aesthetic_loss: 0.0339 - Output_KonIQ_quality_loss: 0.0392 - Output_SPAQ_quality_loss: 0.0910 - Output_AVA_aesthetic_root_mean_squared_error: 0.1798 - Output_AVA_aesthetic_pearson_correlation: 0.9488 - Output_PARA_aesthetic_root_mean_squared_error: 0.1842 - Output_PARA_aesthetic_pearson_correlation: 0.9649 - Output_KonIQ_quality_root_mean_squared_error: 0.1967 - Output_KonIQ_quality_pearson_correlation: 0.9647 - Output_SPAQ_quality_root_mean_squared_error: 0.3016 - Output_SPAQ_quality_pearson_correlation: 0.9842 - val_loss: 0.5611 - val_Output_AVA_aesthetic_loss: 0.2096 - val_Output_PARA_aesthetic_loss: 0.0793 - val_Output_KonIQ_quality_loss: 0.0802 - val_Output_SPAQ_quality_loss: 0.1919 - val_Output_AVA_aesthetic_root_mean_squared_error: 0.4579 - val_Output_AVA_aesthetic_pearson_correlation: 0.5039 - val_Output_PARA_aesthetic_root_mean_squared_error: 0.2820 - val_Output_PARA_aesthetic_pearson_correlation: 0.8050 - val_Output_KonIQ_quality_root_mean_squared_error: 0.2833 - val_Output_KonIQ_quality_pearson_correlation: 0.8594 - val_Output_SPAQ_quality_root_mean_squared_error: 0.4392 - val_Output_SPAQ_quality_pearson_correlation: 0.7890 - lr: 4.0000e-06\n",
      "Epoch 40/100\n",
      " 753/1246 [=================>............] - ETA: 6:26 - loss: 0.1976 - Output_AVA_aesthetic_loss: 0.0330 - Output_PARA_aesthetic_loss: 0.0354 - Output_KonIQ_quality_loss: 0.0382 - Output_SPAQ_quality_loss: 0.0910 - Output_AVA_aesthetic_root_mean_squared_error: 0.1816 - Output_AVA_aesthetic_pearson_correlation: 0.9503 - Output_PARA_aesthetic_root_mean_squared_error: 0.1882 - Output_PARA_aesthetic_pearson_correlation: 0.9637 - Output_KonIQ_quality_root_mean_squared_error: 0.1953 - Output_KonIQ_quality_pearson_correlation: 0.9658 - Output_SPAQ_quality_root_mean_squared_error: 0.3016 - Output_SPAQ_quality_pearson_correlation: 0.9848"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m combined_train_gen \u001b[39m=\u001b[39m combined_generator(ava_train_generator, para_train_generator, koniq_train_generator, spaq_train_generator)\n\u001b[1;32m     25\u001b[0m combined_val_gen \u001b[39m=\u001b[39m combined_generator(ava_val_generator, para_val_generator, koniq_val_generator, spaq_val_generator)\n\u001b[0;32m---> 27\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mcombined_train_gen,\n\u001b[1;32m     28\u001b[0m                     steps_per_epoch \u001b[39m=\u001b[39;49m \u001b[39mmax\u001b[39;49m(steps_per_epoch1, steps_per_epoch2, steps_per_epoch3, steps_per_epoch4),\n\u001b[1;32m     29\u001b[0m                     epochs \u001b[39m=\u001b[39;49m config\u001b[39m.\u001b[39;49mepoch,\n\u001b[1;32m     30\u001b[0m                     validation_data \u001b[39m=\u001b[39;49m combined_val_gen,\n\u001b[1;32m     31\u001b[0m                     validation_steps \u001b[39m=\u001b[39;49m \u001b[39mmax\u001b[39;49m(val_steps1, val_steps2, val_steps3, val_steps4),\n\u001b[1;32m     32\u001b[0m                     callbacks \u001b[39m=\u001b[39;49m [\n\u001b[1;32m     33\u001b[0m                       WandbMetricsLogger(log_freq\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m),\n\u001b[1;32m     34\u001b[0m                       WandbCallback(monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_Output_KonIQ_quality_pearson_correlation\u001b[39;49m\u001b[39m'\u001b[39;49m, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m, save_model\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, save_weights_only\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m     35\u001b[0m                       model_checkpoint_callback,\n\u001b[1;32m     36\u001b[0m                       early_stopping_callback,\n\u001b[1;32m     37\u001b[0m                       reduce_lr_callback\n\u001b[1;32m     38\u001b[0m                     ])\n\u001b[1;32m     40\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "File \u001b[0;32m/media/workstation/0832621B32620DCE/Ianv2/.venv/lib/python3.9/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/media/workstation/0832621B32620DCE/Ianv2/.venv/lib/python3.9/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/media/workstation/0832621B32620DCE/Ianv2/.venv/lib/python3.9/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/media/workstation/0832621B32620DCE/Ianv2/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/media/workstation/0832621B32620DCE/Ianv2/.venv/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1385\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/media/workstation/0832621B32620DCE/Ianv2/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/media/workstation/0832621B32620DCE/Ianv2/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/media/workstation/0832621B32620DCE/Ianv2/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/media/workstation/0832621B32620DCE/Ianv2/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/media/workstation/0832621B32620DCE/Ianv2/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/media/workstation/0832621B32620DCE/Ianv2/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/media/workstation/0832621B32620DCE/Ianv2/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the number of steps per epoch for each generator\n",
    "steps_per_epoch1 = len(ava_train_generator)\n",
    "steps_per_epoch2 = len(para_train_generator)\n",
    "steps_per_epoch3 = len(koniq_train_generator)\n",
    "steps_per_epoch4 = len(spaq_train_generator)\n",
    "\n",
    "# Define the number of validation steps for each generator\n",
    "val_steps1 = len(ava_val_generator)\n",
    "val_steps2 = len(para_val_generator)\n",
    "val_steps3 = len(koniq_val_generator)\n",
    "val_steps4 = len(spaq_val_generator)\n",
    "\n",
    "def combined_generator(gen1, gen2, gen3, gen4):\n",
    "    while True:\n",
    "        batch1 = next(gen1)\n",
    "        batch2 = next(gen2)\n",
    "        batch3 = next(gen3)\n",
    "        batch4 = next(gen4)\n",
    "        inputs = [batch1[0], batch2[0], batch3[0], batch4[0]]\n",
    "        targets = [batch1[1], batch2[1], batch3[1], batch4[1]]\n",
    "        yield inputs, targets\n",
    "\n",
    "combined_train_gen = combined_generator(ava_train_generator, para_train_generator, koniq_train_generator, spaq_train_generator)\n",
    "\n",
    "combined_val_gen = combined_generator(ava_val_generator, para_val_generator, koniq_val_generator, spaq_val_generator)\n",
    "\n",
    "history = model.fit(x=combined_train_gen,\n",
    "                    steps_per_epoch = max(steps_per_epoch1, steps_per_epoch2, steps_per_epoch3, steps_per_epoch4),\n",
    "                    epochs = config.epoch,\n",
    "                    validation_data = combined_val_gen,\n",
    "                    validation_steps = max(val_steps1, val_steps2, val_steps3, val_steps4),\n",
    "                    callbacks = [\n",
    "                      WandbMetricsLogger(log_freq=5),\n",
    "                      WandbCallback(monitor='val_Output_KonIQ_quality_pearson_correlation', mode='max', save_model=False, save_weights_only=False),\n",
    "                      model_checkpoint_callback,\n",
    "                      early_stopping_callback,\n",
    "                      reduce_lr_callback\n",
    "                    ])\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Output_AVA_aesthetic_loss</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Output_AVA_aesthetic_pearson_correlation</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▇▇▇▇██████████████████</td></tr><tr><td>Output_AVA_aesthetic_root_mean_squared_error</td><td>█▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Output_KonIQ_quality_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Output_KonIQ_quality_pearson_correlation</td><td>▁▂▄▄▄▅▅▆▆▆▆▇▇▇▇▇███████████████████████</td></tr><tr><td>Output_KonIQ_quality_root_mean_squared_error</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Output_PARA_aesthetic_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Output_PARA_aesthetic_pearson_correlation</td><td>▁▂▃▄▄▄▅▆▆▆▆▇▇▇▇▇███████████████████████</td></tr><tr><td>Output_PARA_aesthetic_root_mean_squared_error</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Output_SPAQ_quality_loss</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Output_SPAQ_quality_pearson_correlation</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>Output_SPAQ_quality_root_mean_squared_error</td><td>█▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_AVA_aesthetic_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_AVA_aesthetic_pearson_correlation</td><td>▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▇▇▇▇▇██████████████████</td></tr><tr><td>batch/Output_AVA_aesthetic_root_mean_squared_error</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_KonIQ_quality_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_KonIQ_quality_pearson_correlation</td><td>▁▃▃▄▄▅▅▆▆▆▆▇▇▇▇▇████████████████████████</td></tr><tr><td>batch/Output_KonIQ_quality_root_mean_squared_error</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_PARA_aesthetic_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_PARA_aesthetic_pearson_correlation</td><td>▁▂▃▄▃▄▅▆▆▆▆▇▇▇▇▇████████████████████████</td></tr><tr><td>batch/Output_PARA_aesthetic_root_mean_squared_error</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_SPAQ_quality_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/Output_SPAQ_quality_pearson_correlation</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>batch/Output_SPAQ_quality_root_mean_squared_error</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/learning_rate</td><td>████████████████▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/Output_AVA_aesthetic_loss</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/Output_AVA_aesthetic_pearson_correlation</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▇▇▇▇██████████████████</td></tr><tr><td>epoch/Output_AVA_aesthetic_root_mean_squared_error</td><td>█▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/Output_KonIQ_quality_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/Output_KonIQ_quality_pearson_correlation</td><td>▁▂▄▄▄▅▅▆▆▆▆▇▇▇▇▇███████████████████████</td></tr><tr><td>epoch/Output_KonIQ_quality_root_mean_squared_error</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/Output_PARA_aesthetic_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/Output_PARA_aesthetic_pearson_correlation</td><td>▁▂▃▄▄▄▅▆▆▆▆▇▇▇▇▇███████████████████████</td></tr><tr><td>epoch/Output_PARA_aesthetic_root_mean_squared_error</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/Output_SPAQ_quality_loss</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/Output_SPAQ_quality_pearson_correlation</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>epoch/Output_SPAQ_quality_root_mean_squared_error</td><td>█▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>████████████████▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_Output_AVA_aesthetic_loss</td><td>▅▄▂▂▂▁▃▃▂█▃▁▁▃▂▃▂▄▃▃▅▄▂▃▄▄▃▃▅▃▄▃▃▃▃▄▃▃▃</td></tr><tr><td>epoch/val_Output_AVA_aesthetic_pearson_correlation</td><td>▁▃▅▅▅▆▆▆▆▆▇▇▇▇█▇██▇█▇███▇▇▇▇███▇███▇███</td></tr><tr><td>epoch/val_Output_AVA_aesthetic_root_mean_squared_error</td><td>▅▄▃▂▂▁▃▃▂█▄▁▁▃▂▃▂▄▃▃▅▄▃▃▄▄▃▃▅▃▄▃▃▄▃▄▄▄▃</td></tr><tr><td>epoch/val_Output_KonIQ_quality_loss</td><td>▄▂█▃▄▂▂▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_Output_KonIQ_quality_pearson_correlation</td><td>▂▆▁▆▄▆▇▅▆▇███▇█▇███████████████████████</td></tr><tr><td>epoch/val_Output_KonIQ_quality_root_mean_squared_error</td><td>▅▃█▃▅▃▂▃▃▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_Output_PARA_aesthetic_loss</td><td>█▃▇▃▄▃▂▂▂▂▂▁▁▂▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_Output_PARA_aesthetic_pearson_correlation</td><td>▁▅▄▆▄▆▇▇▇▇█▇██▇▇██████▇████████████████</td></tr><tr><td>epoch/val_Output_PARA_aesthetic_root_mean_squared_error</td><td>█▄▇▄▅▄▂▃▃▂▂▂▁▂▂▃▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_Output_SPAQ_quality_loss</td><td>▆▆▅█▅▆▄█▄▃▃▅▃▃▄▅▂▂▁▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>epoch/val_Output_SPAQ_quality_pearson_correlation</td><td>▂▃▃▂▃▁▅▄▆▂▆▅▆▅▆▆▆█▇▇▆▆▇▇▆▇▆█▇▇▇▇▆▇▇▇▆▇▇</td></tr><tr><td>epoch/val_Output_SPAQ_quality_root_mean_squared_error</td><td>▆▆▆█▅▆▄█▄▄▃▅▄▄▄▅▃▂▁▂▂▂▂▂▁▂▂▁▁▂▂▁▂▂▁▂▂▁▂</td></tr><tr><td>epoch/val_loss</td><td>▇▄█▅▅▄▃▅▃▃▂▃▂▂▂▃▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_Output_AVA_aesthetic_loss</td><td>▅▄▂▂▂▁▃▃▂█▃▁▁▃▂▃▂▄▃▃▅▄▂▃▄▄▃▃▅▃▄▃▃▃▃▄▃▃▃</td></tr><tr><td>val_Output_AVA_aesthetic_pearson_correlation</td><td>▁▃▅▅▅▆▆▆▆▆▇▇▇▇█▇██▇█▇███▇▇▇▇███▇███▇███</td></tr><tr><td>val_Output_AVA_aesthetic_root_mean_squared_error</td><td>▅▄▃▂▂▁▃▃▂█▄▁▁▃▂▃▂▄▃▃▅▄▃▃▄▄▃▃▅▃▄▃▃▄▃▄▄▄▃</td></tr><tr><td>val_Output_KonIQ_quality_loss</td><td>▄▂█▃▄▂▂▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_Output_KonIQ_quality_pearson_correlation</td><td>▂▆▁▆▄▆▇▅▆▇███▇█▇███████████████████████</td></tr><tr><td>val_Output_KonIQ_quality_root_mean_squared_error</td><td>▅▃█▃▅▃▂▃▃▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_Output_PARA_aesthetic_loss</td><td>█▃▇▃▄▃▂▂▂▂▂▁▁▂▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_Output_PARA_aesthetic_pearson_correlation</td><td>▁▅▄▆▄▆▇▇▇▇█▇██▇▇██████▇████████████████</td></tr><tr><td>val_Output_PARA_aesthetic_root_mean_squared_error</td><td>█▄▇▄▅▄▂▃▃▂▂▂▁▂▂▃▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_Output_SPAQ_quality_loss</td><td>▆▆▅█▅▆▄█▄▃▃▅▃▃▄▅▂▂▁▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>val_Output_SPAQ_quality_pearson_correlation</td><td>▂▃▃▂▃▁▅▄▆▂▆▅▆▅▆▆▆█▇▇▆▆▇▇▆▇▆█▇▇▇▇▆▇▇▇▆▇▇</td></tr><tr><td>val_Output_SPAQ_quality_root_mean_squared_error</td><td>▆▆▆█▅▆▄█▄▄▃▅▄▄▄▅▃▂▁▂▂▂▂▂▁▂▂▁▁▂▂▁▂▂▁▂▂▁▂</td></tr><tr><td>val_loss</td><td>▇▄█▅▅▄▃▅▃▃▂▃▂▂▂▃▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Output_AVA_aesthetic_loss</td><td>0.03232</td></tr><tr><td>Output_AVA_aesthetic_pearson_correlation</td><td>0.94884</td></tr><tr><td>Output_AVA_aesthetic_root_mean_squared_error</td><td>0.17977</td></tr><tr><td>Output_KonIQ_quality_loss</td><td>0.0392</td></tr><tr><td>Output_KonIQ_quality_pearson_correlation</td><td>0.96466</td></tr><tr><td>Output_KonIQ_quality_root_mean_squared_error</td><td>0.19674</td></tr><tr><td>Output_PARA_aesthetic_loss</td><td>0.03394</td></tr><tr><td>Output_PARA_aesthetic_pearson_correlation</td><td>0.96488</td></tr><tr><td>Output_PARA_aesthetic_root_mean_squared_error</td><td>0.1842</td></tr><tr><td>Output_SPAQ_quality_loss</td><td>0.09099</td></tr><tr><td>Output_SPAQ_quality_pearson_correlation</td><td>0.98422</td></tr><tr><td>Output_SPAQ_quality_root_mean_squared_error</td><td>0.30164</td></tr><tr><td>batch/Output_AVA_aesthetic_loss</td><td>0.03294</td></tr><tr><td>batch/Output_AVA_aesthetic_pearson_correlation</td><td>0.95038</td></tr><tr><td>batch/Output_AVA_aesthetic_root_mean_squared_error</td><td>0.18148</td></tr><tr><td>batch/Output_KonIQ_quality_loss</td><td>0.03826</td></tr><tr><td>batch/Output_KonIQ_quality_pearson_correlation</td><td>0.96577</td></tr><tr><td>batch/Output_KonIQ_quality_root_mean_squared_error</td><td>0.19539</td></tr><tr><td>batch/Output_PARA_aesthetic_loss</td><td>0.03546</td></tr><tr><td>batch/Output_PARA_aesthetic_pearson_correlation</td><td>0.96372</td></tr><tr><td>batch/Output_PARA_aesthetic_root_mean_squared_error</td><td>0.18827</td></tr><tr><td>batch/Output_SPAQ_quality_loss</td><td>0.0909</td></tr><tr><td>batch/Output_SPAQ_quality_pearson_correlation</td><td>0.98479</td></tr><tr><td>batch/Output_SPAQ_quality_root_mean_squared_error</td><td>0.30151</td></tr><tr><td>batch/batch_step</td><td>49500</td></tr><tr><td>batch/learning_rate</td><td>0.0</td></tr><tr><td>batch/loss</td><td>0.19756</td></tr><tr><td>best_epoch</td><td>36</td></tr><tr><td>best_val_Output_KonIQ_quality_pearson_correlation</td><td>0.86037</td></tr><tr><td>epoch</td><td>38</td></tr><tr><td>epoch/Output_AVA_aesthetic_loss</td><td>0.03232</td></tr><tr><td>epoch/Output_AVA_aesthetic_pearson_correlation</td><td>0.94884</td></tr><tr><td>epoch/Output_AVA_aesthetic_root_mean_squared_error</td><td>0.17977</td></tr><tr><td>epoch/Output_KonIQ_quality_loss</td><td>0.0392</td></tr><tr><td>epoch/Output_KonIQ_quality_pearson_correlation</td><td>0.96466</td></tr><tr><td>epoch/Output_KonIQ_quality_root_mean_squared_error</td><td>0.19674</td></tr><tr><td>epoch/Output_PARA_aesthetic_loss</td><td>0.03394</td></tr><tr><td>epoch/Output_PARA_aesthetic_pearson_correlation</td><td>0.96488</td></tr><tr><td>epoch/Output_PARA_aesthetic_root_mean_squared_error</td><td>0.1842</td></tr><tr><td>epoch/Output_SPAQ_quality_loss</td><td>0.09099</td></tr><tr><td>epoch/Output_SPAQ_quality_pearson_correlation</td><td>0.98422</td></tr><tr><td>epoch/Output_SPAQ_quality_root_mean_squared_error</td><td>0.30164</td></tr><tr><td>epoch/epoch</td><td>38</td></tr><tr><td>epoch/learning_rate</td><td>0.0</td></tr><tr><td>epoch/loss</td><td>0.19644</td></tr><tr><td>epoch/val_Output_AVA_aesthetic_loss</td><td>0.20964</td></tr><tr><td>epoch/val_Output_AVA_aesthetic_pearson_correlation</td><td>0.50395</td></tr><tr><td>epoch/val_Output_AVA_aesthetic_root_mean_squared_error</td><td>0.45787</td></tr><tr><td>epoch/val_Output_KonIQ_quality_loss</td><td>0.08024</td></tr><tr><td>epoch/val_Output_KonIQ_quality_pearson_correlation</td><td>0.85936</td></tr><tr><td>epoch/val_Output_KonIQ_quality_root_mean_squared_error</td><td>0.28329</td></tr><tr><td>epoch/val_Output_PARA_aesthetic_loss</td><td>0.0793</td></tr><tr><td>epoch/val_Output_PARA_aesthetic_pearson_correlation</td><td>0.80496</td></tr><tr><td>epoch/val_Output_PARA_aesthetic_root_mean_squared_error</td><td>0.282</td></tr><tr><td>epoch/val_Output_SPAQ_quality_loss</td><td>0.19189</td></tr><tr><td>epoch/val_Output_SPAQ_quality_pearson_correlation</td><td>0.78901</td></tr><tr><td>epoch/val_Output_SPAQ_quality_root_mean_squared_error</td><td>0.43917</td></tr><tr><td>epoch/val_loss</td><td>0.56107</td></tr><tr><td>loss</td><td>0.19644</td></tr><tr><td>val_Output_AVA_aesthetic_loss</td><td>0.20964</td></tr><tr><td>val_Output_AVA_aesthetic_pearson_correlation</td><td>0.50395</td></tr><tr><td>val_Output_AVA_aesthetic_root_mean_squared_error</td><td>0.45787</td></tr><tr><td>val_Output_KonIQ_quality_loss</td><td>0.08024</td></tr><tr><td>val_Output_KonIQ_quality_pearson_correlation</td><td>0.85936</td></tr><tr><td>val_Output_KonIQ_quality_root_mean_squared_error</td><td>0.28329</td></tr><tr><td>val_Output_PARA_aesthetic_loss</td><td>0.0793</td></tr><tr><td>val_Output_PARA_aesthetic_pearson_correlation</td><td>0.80496</td></tr><tr><td>val_Output_PARA_aesthetic_root_mean_squared_error</td><td>0.282</td></tr><tr><td>val_Output_SPAQ_quality_loss</td><td>0.19189</td></tr><tr><td>val_Output_SPAQ_quality_pearson_correlation</td><td>0.78901</td></tr><tr><td>val_Output_SPAQ_quality_root_mean_squared_error</td><td>0.43917</td></tr><tr><td>val_loss</td><td>0.56107</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">easy-flower-9</strong> at: <a href='https://wandb.ai/ianchoo2000/multimodel_irnv2/runs/796hbia7' target=\"_blank\">https://wandb.ai/ianchoo2000/multimodel_irnv2/runs/796hbia7</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/media/workstation/BackupDrive/wandb_files/logs/wandb/run-20230709_040340-796hbia7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 128s 1s/step - loss: 0.5662 - Output_AVA_aesthetic_loss: 0.2141 - Output_PARA_aesthetic_loss: 0.0822 - Output_KonIQ_quality_loss: 0.0808 - Output_SPAQ_quality_loss: 0.1891 - Output_AVA_aesthetic_root_mean_squared_error: 0.4627 - Output_AVA_aesthetic_pearson_correlation: 0.4838 - Output_PARA_aesthetic_root_mean_squared_error: 0.2867 - Output_PARA_aesthetic_pearson_correlation: 0.8101 - Output_KonIQ_quality_root_mean_squared_error: 0.2843 - Output_KonIQ_quality_pearson_correlation: 0.8553 - Output_SPAQ_quality_root_mean_squared_error: 0.4349 - Output_SPAQ_quality_pearson_correlation: 0.7916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 15:18:10.072124: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    }
   ],
   "source": [
    "combined_test_gen = combined_generator(ava_test_generator, para_test_generator, koniq_test_generator, spaq_test_generator)\n",
    "\n",
    "# Define the number of validation steps for each generator\n",
    "test_steps1 = len(ava_test_generator)\n",
    "test_steps2 = len(para_test_generator)\n",
    "test_steps3 = len(koniq_test_generator)\n",
    "test_steps4 = len(spaq_test_generator)\n",
    "\n",
    "# Evaluate the model on the preprocessed test data\n",
    "evaluation = model.evaluate(\n",
    "    combined_test_gen,\n",
    "    steps=max(test_steps1, test_steps2, test_steps3, test_steps4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = '/media/workstation/BackupDrive/model/multimodel_irnv2/'\n",
    "\n",
    "model.save(saved_model_path + 'multimodel_irnv2_easy_flower_9.h5')\n",
    "model.save_weights(saved_model_path + 'multimodel_irnv2_weights_easy_flower_9.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2015 validated image filenames.\n",
      "Found 2015 validated image filenames.\n",
      "Found 2015 validated image filenames.\n",
      "Found 2015 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "ava_test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=ava_test_df, \n",
    "    directory=ava_images, \n",
    "    x_col=\"ID\", \n",
    "    y_col=\"scaled_MOS_aesthetic\", \n",
    "    shuffle=False,\n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "para_test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=para_test_df, \n",
    "    directory=para_images, \n",
    "    x_col=\"sessionId_imageName\", \n",
    "    y_col=\"scaled_MOS_aesthetic\", \n",
    "    shuffle=False,\n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "koniq_test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=koniq_test_df, \n",
    "    directory=koniq_images, \n",
    "    x_col=\"image_name\", \n",
    "    y_col=\"scaled_MOS_quality\", \n",
    "    shuffle=False,\n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "spaq_test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=spaq_test_df, \n",
    "    directory=spaq_images, \n",
    "    x_col=\"Image name\", \n",
    "    y_col=\"scaled_MOS_quality\", \n",
    "    shuffle=False,\n",
    "    class_mode=\"raw\", \n",
    "    target_size=(224, 224), \n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "\n",
    "def plcc(x, y):\n",
    "    '''Pearson Linear Correlation Coefficient'''\n",
    "    x, y = np.float32(x), np.float32(y)\n",
    "    return scipy.stats.pearsonr(x,y)[0]\n",
    "\n",
    "def srocc(xs, ys):\n",
    "    '''Spearman Rank Order Correlation Coefficient'''\n",
    "    correlation, p_value = scipy.stats.spearmanr(xs, ys)\n",
    "    return correlation\n",
    "\n",
    "def rmse(y_test, y_pred):\n",
    "    mse = np.mean((y_test - y_pred) ** 2)\n",
    "    return np.sqrt(mse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_test_gen = combined_generator(ava_test_generator, para_test_generator, koniq_test_generator, spaq_test_generator)\n",
    "\n",
    "# Define the number of validation steps for each generator\n",
    "test_steps1 = len(ava_test_generator)\n",
    "test_steps2 = len(para_test_generator)\n",
    "test_steps3 = len(koniq_test_generator)\n",
    "test_steps4 = len(spaq_test_generator)\n",
    "\n",
    "prediction = model.predict(\n",
    "    combined_test_gen,\n",
    "    steps=max(test_steps1, test_steps2, test_steps3, test_steps4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>sem1</th>\n",
       "      <th>sem2</th>\n",
       "      <th>challegeID</th>\n",
       "      <th>sum_score</th>\n",
       "      <th>total_scorer</th>\n",
       "      <th>MOS</th>\n",
       "      <th>scaled_MOS_aesthetic</th>\n",
       "      <th>set</th>\n",
       "      <th>pred_mos_aesthetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22416</th>\n",
       "      <td>34515</td>\n",
       "      <td>ava</td>\n",
       "      <td>914050.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1281</td>\n",
       "      <td>1371</td>\n",
       "      <td>193</td>\n",
       "      <td>7.103627</td>\n",
       "      <td>4.118615</td>\n",
       "      <td>test</td>\n",
       "      <td>3.673047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22417</th>\n",
       "      <td>66231</td>\n",
       "      <td>ava</td>\n",
       "      <td>41959.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>146</td>\n",
       "      <td>844</td>\n",
       "      <td>140</td>\n",
       "      <td>6.028571</td>\n",
       "      <td>3.485393</td>\n",
       "      <td>test</td>\n",
       "      <td>3.573775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22418</th>\n",
       "      <td>173481</td>\n",
       "      <td>ava</td>\n",
       "      <td>650443.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>821</td>\n",
       "      <td>1169</td>\n",
       "      <td>202</td>\n",
       "      <td>5.787129</td>\n",
       "      <td>3.343180</td>\n",
       "      <td>test</td>\n",
       "      <td>3.686857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22419</th>\n",
       "      <td>158162</td>\n",
       "      <td>ava</td>\n",
       "      <td>220734.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>165</td>\n",
       "      <td>112</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>370</td>\n",
       "      <td>2550</td>\n",
       "      <td>487</td>\n",
       "      <td>5.236140</td>\n",
       "      <td>3.018639</td>\n",
       "      <td>test</td>\n",
       "      <td>2.880749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22420</th>\n",
       "      <td>104085</td>\n",
       "      <td>ava</td>\n",
       "      <td>444720.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>61</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>596</td>\n",
       "      <td>1020</td>\n",
       "      <td>169</td>\n",
       "      <td>6.035503</td>\n",
       "      <td>3.489476</td>\n",
       "      <td>test</td>\n",
       "      <td>3.331942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24426</th>\n",
       "      <td>123348</td>\n",
       "      <td>ava</td>\n",
       "      <td>263513.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>89</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>413</td>\n",
       "      <td>1333</td>\n",
       "      <td>254</td>\n",
       "      <td>5.248031</td>\n",
       "      <td>3.025644</td>\n",
       "      <td>test</td>\n",
       "      <td>3.543407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24427</th>\n",
       "      <td>81633</td>\n",
       "      <td>ava</td>\n",
       "      <td>577031.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>721</td>\n",
       "      <td>828</td>\n",
       "      <td>145</td>\n",
       "      <td>5.710345</td>\n",
       "      <td>3.297953</td>\n",
       "      <td>test</td>\n",
       "      <td>3.540812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24428</th>\n",
       "      <td>59759</td>\n",
       "      <td>ava</td>\n",
       "      <td>874523.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>46</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>1202</td>\n",
       "      <td>1154</td>\n",
       "      <td>226</td>\n",
       "      <td>5.106195</td>\n",
       "      <td>2.942100</td>\n",
       "      <td>test</td>\n",
       "      <td>3.342979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24429</th>\n",
       "      <td>21933</td>\n",
       "      <td>ava</td>\n",
       "      <td>932076.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1331</td>\n",
       "      <td>935</td>\n",
       "      <td>184</td>\n",
       "      <td>5.081522</td>\n",
       "      <td>2.927567</td>\n",
       "      <td>test</td>\n",
       "      <td>2.909036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24430</th>\n",
       "      <td>104312</td>\n",
       "      <td>ava</td>\n",
       "      <td>570377.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>727</td>\n",
       "      <td>834</td>\n",
       "      <td>163</td>\n",
       "      <td>5.116564</td>\n",
       "      <td>2.948208</td>\n",
       "      <td>test</td>\n",
       "      <td>3.516780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2015 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Index dataset          ID  1   2   3    4    5    6   7  ...  10  \\\n",
       "22416   34515     ava  914050.jpg  0   1   5    2   15   40  48  ...  10   \n",
       "22417   66231     ava   41959.jpg  1   0   4   14   26   52  24  ...   4   \n",
       "22418  173481     ava  650443.jpg  0   0   1   17   72   65  31  ...   0   \n",
       "22419  158162     ava  220734.jpg  0   8  29  100  165  112  46  ...   3   \n",
       "22420  104085     ava  444720.jpg  0   0   4    9   42   61  37  ...   3   \n",
       "...       ...     ...         ... ..  ..  ..  ...  ...  ...  ..  ...  ..   \n",
       "24426  123348     ava  263513.jpg  0   6  11   54   89   51  28  ...   2   \n",
       "24427   81633     ava  577031.jpg  0   0   2   11   56   48  19  ...   1   \n",
       "24428   59759     ava  874523.jpg  3  15  22   37   61   46  23  ...   2   \n",
       "24429   21933     ava  932076.jpg  4   4  10   42   57   42  17  ...   1   \n",
       "24430  104312     ava  570377.jpg  1   3   7   29   73   35   8  ...   1   \n",
       "\n",
       "       sem1  sem2  challegeID  sum_score  total_scorer       MOS  \\\n",
       "22416     2    20        1281       1371           193  7.103627   \n",
       "22417    18    22         146        844           140  6.028571   \n",
       "22418    19    21         821       1169           202  5.787129   \n",
       "22419    17    26         370       2550           487  5.236140   \n",
       "22420     2    20         596       1020           169  6.035503   \n",
       "...     ...   ...         ...        ...           ...       ...   \n",
       "24426    14    20         413       1333           254  5.248031   \n",
       "24427    14    21         721        828           145  5.710345   \n",
       "24428    18    41        1202       1154           226  5.106195   \n",
       "24429     1     2        1331        935           184  5.081522   \n",
       "24430    20    21         727        834           163  5.116564   \n",
       "\n",
       "       scaled_MOS_aesthetic   set  pred_mos_aesthetic  \n",
       "22416              4.118615  test            3.673047  \n",
       "22417              3.485393  test            3.573775  \n",
       "22418              3.343180  test            3.686857  \n",
       "22419              3.018639  test            2.880749  \n",
       "22420              3.489476  test            3.331942  \n",
       "...                     ...   ...                 ...  \n",
       "24426              3.025644  test            3.543407  \n",
       "24427              3.297953  test            3.540812  \n",
       "24428              2.942100  test            3.342979  \n",
       "24429              2.927567  test            2.909036  \n",
       "24430              2.948208  test            3.516780  \n",
       "\n",
       "[2015 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>imageName</th>\n",
       "      <th>scaled_MOS_aesthetic</th>\n",
       "      <th>qualityScore</th>\n",
       "      <th>sessionId_imageName</th>\n",
       "      <th>set</th>\n",
       "      <th>pred_mos_aesthetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>para</td>\n",
       "      <td>session254</td>\n",
       "      <td>iaa_pub17770_.jpg</td>\n",
       "      <td>1.431034</td>\n",
       "      <td>1.413793</td>\n",
       "      <td>session254_iaa_pub17770_.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>2.507247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>para</td>\n",
       "      <td>session241</td>\n",
       "      <td>iaa_pub16811_.jpg</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.995833</td>\n",
       "      <td>session241_iaa_pub16811_.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>3.869065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>para</td>\n",
       "      <td>session431</td>\n",
       "      <td>iaa_pub30170_.jpg</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>3.356000</td>\n",
       "      <td>session431_iaa_pub30170_.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>3.317594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>para</td>\n",
       "      <td>session70</td>\n",
       "      <td>iaa_pub4849_.jpg</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.856000</td>\n",
       "      <td>session70_iaa_pub4849_.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>3.592565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>para</td>\n",
       "      <td>session161</td>\n",
       "      <td>iaa_pub11239_.jpg</td>\n",
       "      <td>3.879310</td>\n",
       "      <td>4.034483</td>\n",
       "      <td>session161_iaa_pub11239_.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>3.635009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11132</th>\n",
       "      <td>para</td>\n",
       "      <td>session200</td>\n",
       "      <td>iaa_pub13994_.jpg</td>\n",
       "      <td>2.760000</td>\n",
       "      <td>2.968000</td>\n",
       "      <td>session200_iaa_pub13994_.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>2.334258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11138</th>\n",
       "      <td>para</td>\n",
       "      <td>session262</td>\n",
       "      <td>iaa_pub18288_.jpg</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.488000</td>\n",
       "      <td>session262_iaa_pub18288_.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>2.809561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11139</th>\n",
       "      <td>para</td>\n",
       "      <td>session336</td>\n",
       "      <td>iaa_pub23502_.jpg</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>3.776000</td>\n",
       "      <td>session336_iaa_pub23502_.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>3.522117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11163</th>\n",
       "      <td>para</td>\n",
       "      <td>session421</td>\n",
       "      <td>iaa_pub29421_.jpg</td>\n",
       "      <td>3.288462</td>\n",
       "      <td>3.546154</td>\n",
       "      <td>session421_iaa_pub29421_.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>3.479589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11164</th>\n",
       "      <td>para</td>\n",
       "      <td>session10</td>\n",
       "      <td>iaa_pub639_.jpg</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>3.132000</td>\n",
       "      <td>session10_iaa_pub639_.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>3.428556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2015 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset   sessionId          imageName  scaled_MOS_aesthetic  \\\n",
       "0        para  session254  iaa_pub17770_.jpg              1.431034   \n",
       "1        para  session241  iaa_pub16811_.jpg              3.833333   \n",
       "12       para  session431  iaa_pub30170_.jpg              3.280000   \n",
       "27       para   session70   iaa_pub4849_.jpg              3.800000   \n",
       "33       para  session161  iaa_pub11239_.jpg              3.879310   \n",
       "...       ...         ...                ...                   ...   \n",
       "11132    para  session200  iaa_pub13994_.jpg              2.760000   \n",
       "11138    para  session262  iaa_pub18288_.jpg              2.400000   \n",
       "11139    para  session336  iaa_pub23502_.jpg              3.540000   \n",
       "11163    para  session421  iaa_pub29421_.jpg              3.288462   \n",
       "11164    para   session10    iaa_pub639_.jpg              2.840000   \n",
       "\n",
       "       qualityScore           sessionId_imageName   set  pred_mos_aesthetic  \n",
       "0          1.413793  session254_iaa_pub17770_.jpg  test            2.507247  \n",
       "1          3.995833  session241_iaa_pub16811_.jpg  test            3.869065  \n",
       "12         3.356000  session431_iaa_pub30170_.jpg  test            3.317594  \n",
       "27         3.856000    session70_iaa_pub4849_.jpg  test            3.592565  \n",
       "33         4.034483  session161_iaa_pub11239_.jpg  test            3.635009  \n",
       "...             ...                           ...   ...                 ...  \n",
       "11132      2.968000  session200_iaa_pub13994_.jpg  test            2.334258  \n",
       "11138      2.488000  session262_iaa_pub18288_.jpg  test            2.809561  \n",
       "11139      3.776000  session336_iaa_pub23502_.jpg  test            3.522117  \n",
       "11163      3.546154  session421_iaa_pub29421_.jpg  test            3.479589  \n",
       "11164      3.132000     session10_iaa_pub639_.jpg  test            3.428556  \n",
       "\n",
       "[2015 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>image_name</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c_total</th>\n",
       "      <th>scaled_MOS_quality</th>\n",
       "      <th>SD</th>\n",
       "      <th>MOS_zscore</th>\n",
       "      <th>set</th>\n",
       "      <th>pred_mos_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>koniq</td>\n",
       "      <td>10007357496.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>3.479167</td>\n",
       "      <td>0.580003</td>\n",
       "      <td>68.728571</td>\n",
       "      <td>test</td>\n",
       "      <td>3.431759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>koniq</td>\n",
       "      <td>10020766793.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>78</td>\n",
       "      <td>20</td>\n",
       "      <td>109</td>\n",
       "      <td>4.082569</td>\n",
       "      <td>0.529298</td>\n",
       "      <td>81.506250</td>\n",
       "      <td>test</td>\n",
       "      <td>3.393662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>koniq</td>\n",
       "      <td>10020891105.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>3.137255</td>\n",
       "      <td>0.445866</td>\n",
       "      <td>56.829741</td>\n",
       "      <td>test</td>\n",
       "      <td>3.135292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>koniq</td>\n",
       "      <td>10022757465.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>3.676190</td>\n",
       "      <td>0.596387</td>\n",
       "      <td>71.015487</td>\n",
       "      <td>test</td>\n",
       "      <td>3.271204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>koniq</td>\n",
       "      <td>10039534103.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>3.691589</td>\n",
       "      <td>0.483915</td>\n",
       "      <td>76.075000</td>\n",
       "      <td>test</td>\n",
       "      <td>3.180727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10050</th>\n",
       "      <td>koniq</td>\n",
       "      <td>9936084895.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>3.255102</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>61.648649</td>\n",
       "      <td>test</td>\n",
       "      <td>3.380039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10065</th>\n",
       "      <td>koniq</td>\n",
       "      <td>9977056676.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>2.718447</td>\n",
       "      <td>0.549821</td>\n",
       "      <td>46.301339</td>\n",
       "      <td>test</td>\n",
       "      <td>2.960097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10066</th>\n",
       "      <td>koniq</td>\n",
       "      <td>9977191265.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>3.620370</td>\n",
       "      <td>0.591491</td>\n",
       "      <td>74.471698</td>\n",
       "      <td>test</td>\n",
       "      <td>3.499641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10068</th>\n",
       "      <td>koniq</td>\n",
       "      <td>9984535544.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>3.586538</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>70.020089</td>\n",
       "      <td>test</td>\n",
       "      <td>3.464988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10070</th>\n",
       "      <td>koniq</td>\n",
       "      <td>9991999836.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "      <td>101</td>\n",
       "      <td>3.920792</td>\n",
       "      <td>0.462237</td>\n",
       "      <td>78.092437</td>\n",
       "      <td>test</td>\n",
       "      <td>3.652998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2015 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset       image_name  c1  c2  c3  c4  c5  c_total  \\\n",
       "1       koniq  10007357496.jpg   0   3  45  47   1       96   \n",
       "9       koniq  10020766793.jpg   0   0  11  78  20      109   \n",
       "10      koniq  10020891105.jpg   0   4  80  18   0      102   \n",
       "11      koniq  10022757465.jpg   0   3  32  66   4      105   \n",
       "18      koniq  10039534103.jpg   0   0  34  72   1      107   \n",
       "...       ...              ...  ..  ..  ..  ..  ..      ...   \n",
       "10050   koniq   9936084895.jpg   0   5  63  30   0       98   \n",
       "10065   koniq   9977056676.jpg   0  34  64   5   0      103   \n",
       "10066   koniq   9977191265.jpg   0   1  44  58   5      108   \n",
       "10068   koniq   9984535544.jpg   0   0  46  55   3      104   \n",
       "10070   koniq   9991999836.jpg   0   0  15  79   7      101   \n",
       "\n",
       "       scaled_MOS_quality        SD  MOS_zscore   set  pred_mos_quality  \n",
       "1                3.479167  0.580003   68.728571  test          3.431759  \n",
       "9                4.082569  0.529298   81.506250  test          3.393662  \n",
       "10               3.137255  0.445866   56.829741  test          3.135292  \n",
       "11               3.676190  0.596387   71.015487  test          3.271204  \n",
       "18               3.691589  0.483915   76.075000  test          3.180727  \n",
       "...                   ...       ...         ...   ...               ...  \n",
       "10050            3.255102  0.543210   61.648649  test          3.380039  \n",
       "10065            2.718447  0.549821   46.301339  test          2.960097  \n",
       "10066            3.620370  0.591491   74.471698  test          3.499641  \n",
       "10068            3.586538  0.550562   70.020089  test          3.464988  \n",
       "10070            3.920792  0.462237   78.092437  test          3.652998  \n",
       "\n",
       "[2015 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Image name</th>\n",
       "      <th>MOS</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Colorfulness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noisiness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>scaled_MOS_quality</th>\n",
       "      <th>set</th>\n",
       "      <th>pred_mos_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spaq</td>\n",
       "      <td>10664.jpg</td>\n",
       "      <td>31.00</td>\n",
       "      <td>51.71</td>\n",
       "      <td>38.14</td>\n",
       "      <td>44.14</td>\n",
       "      <td>33.86</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.234043</td>\n",
       "      <td>test</td>\n",
       "      <td>2.588847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spaq</td>\n",
       "      <td>02979.jpg</td>\n",
       "      <td>30.89</td>\n",
       "      <td>38.10</td>\n",
       "      <td>57.22</td>\n",
       "      <td>50.11</td>\n",
       "      <td>49.10</td>\n",
       "      <td>16.60</td>\n",
       "      <td>2.229362</td>\n",
       "      <td>test</td>\n",
       "      <td>2.723767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spaq</td>\n",
       "      <td>06700.jpg</td>\n",
       "      <td>53.17</td>\n",
       "      <td>55.00</td>\n",
       "      <td>47.67</td>\n",
       "      <td>50.67</td>\n",
       "      <td>57.33</td>\n",
       "      <td>52.83</td>\n",
       "      <td>3.177447</td>\n",
       "      <td>test</td>\n",
       "      <td>3.100795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spaq</td>\n",
       "      <td>08568.jpg</td>\n",
       "      <td>65.50</td>\n",
       "      <td>61.25</td>\n",
       "      <td>65.00</td>\n",
       "      <td>68.25</td>\n",
       "      <td>69.00</td>\n",
       "      <td>67.25</td>\n",
       "      <td>3.702128</td>\n",
       "      <td>test</td>\n",
       "      <td>3.285597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>spaq</td>\n",
       "      <td>09323.jpg</td>\n",
       "      <td>69.13</td>\n",
       "      <td>70.75</td>\n",
       "      <td>75.38</td>\n",
       "      <td>65.13</td>\n",
       "      <td>59.13</td>\n",
       "      <td>66.25</td>\n",
       "      <td>3.856596</td>\n",
       "      <td>test</td>\n",
       "      <td>3.356549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11086</th>\n",
       "      <td>spaq</td>\n",
       "      <td>06062.jpg</td>\n",
       "      <td>33.89</td>\n",
       "      <td>57.00</td>\n",
       "      <td>53.67</td>\n",
       "      <td>57.89</td>\n",
       "      <td>47.22</td>\n",
       "      <td>20.78</td>\n",
       "      <td>2.357021</td>\n",
       "      <td>test</td>\n",
       "      <td>2.392219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11092</th>\n",
       "      <td>spaq</td>\n",
       "      <td>10571.jpg</td>\n",
       "      <td>28.29</td>\n",
       "      <td>52.57</td>\n",
       "      <td>54.57</td>\n",
       "      <td>48.86</td>\n",
       "      <td>27.14</td>\n",
       "      <td>8.20</td>\n",
       "      <td>2.118723</td>\n",
       "      <td>test</td>\n",
       "      <td>2.448367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11093</th>\n",
       "      <td>spaq</td>\n",
       "      <td>05861.jpg</td>\n",
       "      <td>59.80</td>\n",
       "      <td>52.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>56.60</td>\n",
       "      <td>56.80</td>\n",
       "      <td>3.459574</td>\n",
       "      <td>test</td>\n",
       "      <td>3.280375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11117</th>\n",
       "      <td>spaq</td>\n",
       "      <td>05853.jpg</td>\n",
       "      <td>58.67</td>\n",
       "      <td>65.50</td>\n",
       "      <td>64.17</td>\n",
       "      <td>56.50</td>\n",
       "      <td>53.00</td>\n",
       "      <td>61.17</td>\n",
       "      <td>3.411489</td>\n",
       "      <td>test</td>\n",
       "      <td>3.186589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11118</th>\n",
       "      <td>spaq</td>\n",
       "      <td>07627.jpg</td>\n",
       "      <td>41.50</td>\n",
       "      <td>47.00</td>\n",
       "      <td>46.83</td>\n",
       "      <td>45.50</td>\n",
       "      <td>32.50</td>\n",
       "      <td>34.17</td>\n",
       "      <td>2.680851</td>\n",
       "      <td>test</td>\n",
       "      <td>2.669466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2015 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset Image name    MOS  Brightness  Colorfulness  Contrast  \\\n",
       "2        spaq  10664.jpg  31.00       51.71         38.14     44.14   \n",
       "5        spaq  02979.jpg  30.89       38.10         57.22     50.11   \n",
       "9        spaq  06700.jpg  53.17       55.00         47.67     50.67   \n",
       "14       spaq  08568.jpg  65.50       61.25         65.00     68.25   \n",
       "20       spaq  09323.jpg  69.13       70.75         75.38     65.13   \n",
       "...       ...        ...    ...         ...           ...       ...   \n",
       "11086    spaq  06062.jpg  33.89       57.00         53.67     57.89   \n",
       "11092    spaq  10571.jpg  28.29       52.57         54.57     48.86   \n",
       "11093    spaq  05861.jpg  59.80       52.00         65.00     55.00   \n",
       "11117    spaq  05853.jpg  58.67       65.50         64.17     56.50   \n",
       "11118    spaq  07627.jpg  41.50       47.00         46.83     45.50   \n",
       "\n",
       "       Noisiness  Sharpness  scaled_MOS_quality   set  pred_mos_quality  \n",
       "2          33.86      13.17            2.234043  test          2.588847  \n",
       "5          49.10      16.60            2.229362  test          2.723767  \n",
       "9          57.33      52.83            3.177447  test          3.100795  \n",
       "14         69.00      67.25            3.702128  test          3.285597  \n",
       "20         59.13      66.25            3.856596  test          3.356549  \n",
       "...          ...        ...                 ...   ...               ...  \n",
       "11086      47.22      20.78            2.357021  test          2.392219  \n",
       "11092      27.14       8.20            2.118723  test          2.448367  \n",
       "11093      56.60      56.80            3.459574  test          3.280375  \n",
       "11117      53.00      61.17            3.411489  test          3.186589  \n",
       "11118      32.50      34.17            2.680851  test          2.669466  \n",
       "\n",
       "[2015 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_num = 0\n",
    "for prediction_list in prediction:\n",
    "    test_list = []\n",
    "    test_list = prediction_list.tolist()\n",
    "    test_list = [val[0] for val in test_list]\n",
    "    if df_num == 0:\n",
    "        ava_pred_df = ava_test_df.copy()\n",
    "        ava_pred_df['pred_mos_aesthetic'] = test_list\n",
    "        df_num += 1\n",
    "    elif df_num == 1:\n",
    "        para_pred_df = para_test_df.copy()\n",
    "        para_pred_df['pred_mos_aesthetic'] = test_list\n",
    "        df_num += 1\n",
    "    elif df_num == 2:\n",
    "        koniq_pred_df = koniq_test_df.copy()\n",
    "        koniq_pred_df['pred_mos_quality'] = test_list\n",
    "        df_num += 1\n",
    "    elif df_num == 3:\n",
    "        spaq_pred_df = spaq_test_df.copy()\n",
    "        spaq_pred_df['pred_mos_quality'] = test_list\n",
    "        df_num += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRCC/PLCC/RMSE 0.777/0.804/0.435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Quality Score Ground truth - Prediction')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test = np.array(spaq_pred_df.loc[:, 'scaled_MOS_quality'])\n",
    "y_pred = np.array(spaq_pred_df.loc[:, 'pred_mos_quality'])\n",
    "\n",
    "SRCC_test = round(srocc(y_pred, y_test), 3)\n",
    "PLCC_test = round(plcc(y_pred, y_test), 3)\n",
    "rmse_test = round(rmse(y_test, y_pred), 3)\n",
    "print('SRCC/PLCC/RMSE {}/{}/{}'.format(SRCC_test, PLCC_test, rmse_test))\n",
    "\n",
    "plt.plot(y_pred, y_test, '.', markersize=0.5)\n",
    "plt.xlabel('predicted'); plt.ylabel('ground-truth'); plt.show\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Quality Score Ground truth - Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the test_df for prediction later on\n",
    "ava_test_df.to_csv(main_directory + 'multimodel_dataset/prediction/predict_baseline_multimodel_ava.csv')\n",
    "para_test_df.to_csv(main_directory + 'multimodel_dataset/prediction/predict_baseline_multimodel_para.csv')\n",
    "koniq_test_df.to_csv(main_directory + 'multimodel_dataset/prediction/predict_baseline_multimodel_koniq.csv')\n",
    "spaq_test_df.to_csv(main_directory + 'multimodel_dataset/prediction/predict_baseline_multimodel_spaq.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27897a16debf2f318f192658ffc2082c04d3ee3ec3f369b914948f41edfc2929"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
